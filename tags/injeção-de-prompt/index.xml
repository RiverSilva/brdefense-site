<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Injeção De Prompt on BR Defense Center</title><link>https://brdefense.center/tags/inje%C3%A7%C3%A3o-de-prompt/</link><description>Recent content in Injeção De Prompt on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Mon, 27 Oct 2025 06:58:53 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/inje%C3%A7%C3%A3o-de-prompt/index.xml" rel="self" type="application/rss+xml"/><item><title>Navegador OpenAI Atlas vulnerável a ataques de injeção de prompt</title><link>https://brdefense.center/news/navegador-openai-atlas-vulneravel-a-ataques-de-inj/</link><pubDate>Mon, 27 Oct 2025 06:58:53 -0300</pubDate><guid>https://brdefense.center/news/navegador-openai-atlas-vulneravel-a-ataques-de-inj/</guid><description>&lt;p>O navegador OpenAI Atlas, recém-lançado, foi identificado como vulnerável a um ataque de injeção de prompt, onde um prompt malicioso pode ser disfarçado como um URL aparentemente inofensivo. Segundo um relatório da NeuralTrust, o omnibox do navegador, que combina a barra de endereço e de busca, interpreta entradas como URLs ou comandos em linguagem natural. Isso permite que um atacante crie um link que, ao ser inserido, faz com que o navegador execute instruções prejudiciais. Por exemplo, um URL malformado pode redirecionar o usuário para um site controlado pelo atacante, potencialmente levando a páginas de phishing ou até comandos que excluem arquivos de aplicativos conectados, como o Google Drive. A falta de distinção rigorosa entre entradas de usuário confiáveis e conteúdo não confiável no Atlas é uma falha crítica. A situação é agravada por técnicas como o &amp;lsquo;AI Sidebar Spoofing&amp;rsquo;, onde extensões maliciosas podem enganar usuários a fornecer dados ou instalar malware. Embora a OpenAI tenha implementado medidas de segurança, a injeção de prompt continua a ser um problema de segurança não resolvido, exigindo atenção contínua da indústria de cibersegurança.&lt;/p></description></item><item><title>Técnica de Injeção de Prompt Permite Bypass do Framework Guardrails da OpenAI</title><link>https://brdefense.center/news/tecnica-de-injecao-de-prompt-permite-bypass-do-fra/</link><pubDate>Tue, 14 Oct 2025 06:59:18 -0300</pubDate><guid>https://brdefense.center/news/tecnica-de-injecao-de-prompt-permite-bypass-do-fra/</guid><description>&lt;p>Pesquisadores de segurança revelaram uma vulnerabilidade crítica no framework Guardrails da OpenAI, que pode ser explorada através de métodos simples de injeção de prompt. Essa técnica permite que atacantes manipulem os modelos de linguagem que deveriam garantir a segurança do comportamento da IA, possibilitando a inserção de conteúdo malicioso sem ser detectado. O Guardrails, introduzido em 6 de outubro, utiliza modelos de linguagem como &amp;lsquo;juízes&amp;rsquo; para avaliar a segurança de entradas e saídas, mas a pesquisa mostrou que essa abordagem cria um ciclo de segurança &amp;lsquo;cega&amp;rsquo;. Os atacantes podem enganar esses juízes, manipulando os limiares de confiança e permitindo a execução de instruções perigosas. Os métodos de bypass demonstrados incluem a inserção de instruções maliciosas em templates que imitam avaliações aprovadas e a ocultação de código malicioso em comentários HTML. Essa vulnerabilidade, classificada como &amp;lsquo;composta&amp;rsquo;, sugere que os juízes baseados em LLM são tão suscetíveis à manipulação quanto os modelos que protegem. Para mitigar esses riscos, as organizações devem implementar defesas em camadas e sistemas de validação independentes, além de monitoramento contínuo.&lt;/p></description></item><item><title>Novo ataque CometJacking compromete navegadores de IA</title><link>https://brdefense.center/news/novo-ataque-cometjacking-compromete-navegadores-de/</link><pubDate>Sat, 04 Oct 2025 12:57:38 -0300</pubDate><guid>https://brdefense.center/news/novo-ataque-cometjacking-compromete-navegadores-de/</guid><description>&lt;p>Pesquisadores de cibersegurança revelaram um novo ataque denominado CometJacking, que visa o navegador de IA Comet da Perplexity. Este ataque utiliza links maliciosos que, ao serem clicados, injetam comandos ocultos no navegador, permitindo que dados sensíveis, como informações de e-mail e calendário, sejam extraídos sem o conhecimento do usuário. A técnica de injeção de prompt se aproveita de uma URL manipulada que, em vez de direcionar o usuário para um site legítimo, instrui o assistente de IA a acessar sua memória e coletar dados, que são então codificados em Base64 e enviados para um servidor controlado pelo atacante. Embora a Perplexity tenha minimizado o impacto da descoberta, o ataque destaca a vulnerabilidade de ferramentas nativas de IA, que podem contornar as proteções tradicionais de segurança. Especialistas alertam que os navegadores de IA representam um novo campo de batalha para a segurança cibernética, exigindo que as organizações implementem controles rigorosos para detectar e neutralizar esses tipos de ataques antes que se tornem comuns.&lt;/p></description></item></channel></rss>