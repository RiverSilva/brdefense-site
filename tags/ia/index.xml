<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ia on BR Defense Center</title><link>https://brdefense.center/tags/ia/</link><description>Recent content in Ia on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Thu, 12 Feb 2026 13:43:17 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/ia/index.xml" rel="self" type="application/rss+xml"/><item><title>Extensões maliciosas do Chrome se disfarçam de assistentes de IA</title><link>https://brdefense.center/news/extensoes-maliciosas-do-chrome-se-disfarcam-de-ass/</link><pubDate>Thu, 12 Feb 2026 13:43:17 -0300</pubDate><guid>https://brdefense.center/news/extensoes-maliciosas-do-chrome-se-disfarcam-de-ass/</guid><description>&lt;p>Um conjunto de 30 extensões maliciosas do Chrome, que foram instaladas por mais de 300.000 usuários, se disfarça como assistentes de IA para roubar credenciais, conteúdo de e-mails e informações de navegação. A campanha, chamada AiFrame, foi descoberta pela plataforma de segurança de navegadores LayerX, que identificou que todas as extensões analisadas compartilham a mesma infraestrutura maliciosa, comunicando-se com o domínio tapnetic[.]pro. A extensão mais popular da campanha, chamada Gemini AI Sidebar, tinha 80.000 usuários, mas já não está mais disponível na Chrome Web Store. Outras extensões, como AI Sidebar e AI Assistant, ainda estão ativas e possuem dezenas de milhares de usuários. As extensões não implementam funcionalidades de IA localmente; em vez disso, carregam conteúdo de um domínio remoto, o que permite que os operadores alterem a lógica das extensões sem necessidade de atualização. Além disso, um subconjunto de 15 extensões visa especificamente dados do Gmail, extraindo conteúdo de e-mails e até mesmo rascunhos. LayerX alerta que, ao invocar funcionalidades relacionadas ao Gmail, o conteúdo extraído é enviado para servidores controlados pelos operadores das extensões. A pesquisa destaca a necessidade de os usuários verificarem suas contas e redefinirem senhas se forem afetados.&lt;/p></description></item><item><title>Hackers apoiados por Estados usam IA do Google para ataques cibernéticos</title><link>https://brdefense.center/news/hackers-apoiados-por-estados-usam-ia-do-google-par/</link><pubDate>Thu, 12 Feb 2026 07:31:49 -0300</pubDate><guid>https://brdefense.center/news/hackers-apoiados-por-estados-usam-ia-do-google-par/</guid><description>&lt;p>Hackers apoiados por estados, incluindo grupos da China, Irã, Coreia do Norte e Rússia, estão utilizando o modelo de IA Gemini do Google para facilitar todas as etapas de ataques cibernéticos, desde a fase de reconhecimento até ações pós-comprometimento. O relatório do Google Threat Intelligence Group (GTIG) revela que esses atores maliciosos empregam a IA para criar perfis de alvos, gerar iscas de phishing, traduzir textos, realizar testes de vulnerabilidades e até desenvolver malware. Por exemplo, um ator da China simulou um cenário para automatizar a análise de vulnerabilidades, enquanto um grupo iraniano usou a IA para acelerar a criação de ferramentas maliciosas personalizadas. Além disso, a IA está sendo utilizada em campanhas de engenharia social, como as campanhas ClickFix, que distribuem malware para roubo de informações. O relatório também destaca tentativas de extração e destilação do modelo de IA, o que representa um risco significativo para a propriedade intelectual e o modelo de negócios de IA como serviço. O Google está tomando medidas para mitigar esses abusos, mas a ameaça continua crescente, especialmente com o aumento do interesse de cibercriminosos por ferramentas de IA.&lt;/p></description></item><item><title>Ameaças cibernéticas modernas abuso de confiança e novos vetores de ataque</title><link>https://brdefense.center/news/ameacas-ciberneticas-modernas-abuso-de-confianca-e/</link><pubDate>Mon, 09 Feb 2026 19:22:34 -0300</pubDate><guid>https://brdefense.center/news/ameacas-ciberneticas-modernas-abuso-de-confianca-e/</guid><description>&lt;p>As ameaças cibernéticas atuais não se limitam mais a malware ou exploits, mas estão se infiltrando nas ferramentas e plataformas que as organizações utilizam diariamente. Com a crescente interconexão de aplicativos de IA, nuvem e sistemas de comunicação, os atacantes estão explorando esses mesmos caminhos. Um padrão alarmante observado é o abuso de confiança em atualizações, marketplaces e aplicativos considerados seguros. A parceria entre a OpenClaw e o VirusTotal, por exemplo, visa melhorar a segurança de um ecossistema de IA, após a descoberta de habilidades maliciosas em sua plataforma. Além disso, um alerta conjunto das agências de segurança da Alemanha destaca campanhas de phishing direcionadas a alvos de alto nível, utilizando o aplicativo Signal. Outro ponto crítico é a botnet AISURU, que foi responsável por um ataque DDoS recorde de 31,4 Tbps. A vulnerabilidade no assistente de IA da Docker, chamada DockerDash, permite a execução remota de código, evidenciando a necessidade de um modelo de segurança baseado em Zero Trust. A Microsoft também desenvolveu um scanner para detectar backdoors em modelos de IA, ressaltando a importância de monitorar e mitigar riscos em ambientes de IA. Esses eventos demonstram que a segurança cibernética precisa evoluir para enfrentar ameaças cada vez mais sofisticadas.&lt;/p></description></item><item><title>A crescente ameaça de ataques no navegador e a segurança empresarial</title><link>https://brdefense.center/news/a-crescente-ameaca-de-ataques-no-navegador-e-a-seg/</link><pubDate>Fri, 06 Feb 2026 13:28:09 -0300</pubDate><guid>https://brdefense.center/news/a-crescente-ameaca-de-ataques-no-navegador-e-a-seg/</guid><description>&lt;p>O artigo destaca que, atualmente, a maior parte do trabalho nas empresas ocorre no navegador, com aplicações SaaS e ferramentas de IA se tornando interfaces primárias para acesso a dados. No entanto, a segurança cibernética ainda não integra adequadamente o navegador em suas arquiteturas, resultando em uma lacuna significativa na detecção de ameaças. Os ataques baseados em navegador, como engenharia social, extensões maliciosas e ataques Man-in-the-Browser, estão se tornando comuns e difíceis de rastrear, pois muitas vezes não deixam evidências tradicionais. Ferramentas de segurança, como EDR e SASE, não conseguem monitorar interações dentro do navegador, o que limita a eficácia na prevenção e resposta a incidentes. A pesquisa da Keep Aware revela que, embora existam políticas de segurança, falta visibilidade sobre o comportamento real dos usuários. Com o aumento do uso de ferramentas de IA, essa lacuna se amplia, tornando a detecção e prevenção de riscos ainda mais desafiadoras. O artigo conclui que a observabilidade das interações no navegador é crucial para melhorar a segurança e a resposta a incidentes, permitindo que as equipes de segurança ajustem suas políticas com base em dados reais.&lt;/p></description></item><item><title>Brasil é um dos países com mais servidores de IA expostos a hackers</title><link>https://brdefense.center/news/brasil-e-um-dos-paises-com-mais-servidores-de-ia-e/</link><pubDate>Wed, 04 Feb 2026 13:34:10 -0300</pubDate><guid>https://brdefense.center/news/brasil-e-um-dos-paises-com-mais-servidores-de-ia-e/</guid><description>&lt;p>Uma pesquisa realizada pela SentinelLABS e Censys, da SentinelOne, revelou que o Brasil é um dos países mais afetados pela exposição de servidores de Inteligência Artificial (IA) a hackers. A análise abrangeu 175.000 hosts Ollama em 130 países, com a maioria das instâncias expostas localizadas na China. No entanto, o Brasil se destaca entre os países com maior número de servidores vulneráveis, ao lado de nações como Alemanha, Coreia do Sul e Estados Unidos. A Ollama, um framework de código aberto, permite que usuários gerenciem modelos de linguagem localmente, mas a configuração inadequada pode expor esses servidores à internet, aumentando o risco de ataques. Aproximadamente 48% dos hosts analisados possuem capacidades que permitem a execução de código e interação com sistemas externos, o que pode ser explorado por hackers para realizar atividades maliciosas, como spam em massa e campanhas de desinformação. A pesquisa também identificou a campanha Operation Bizarre Bazaar, que monetiza o acesso a essa infraestrutura de IA clandestina. Para mitigar esses riscos, é essencial que as organizações tratem os LLMs com as mesmas medidas de segurança aplicadas a qualquer infraestrutura acessível externamente.&lt;/p></description></item><item><title>Investigação no Reino Unido sobre uso indevido de dados pela X</title><link>https://brdefense.center/news/investigacao-no-reino-unido-sobre-uso-indevido-de/</link><pubDate>Tue, 03 Feb 2026 13:38:49 -0300</pubDate><guid>https://brdefense.center/news/investigacao-no-reino-unido-sobre-uso-indevido-de/</guid><description>&lt;p>A Autoridade de Proteção de Dados do Reino Unido (ICO) iniciou uma investigação formal contra a X e sua subsidiária irlandesa, xAI, após relatos de que o assistente de IA Grok foi utilizado para gerar imagens sexuais não consensuais. A ICO busca determinar se a X Internet Unlimited Company (XIUC) e a X.AI LLC (X.AI) processaram dados pessoais de forma legal e se implementaram salvaguardas adequadas para evitar a criação de imagens prejudiciais. O órgão destacou que a perda de controle sobre dados pessoais pode causar danos imediatos e significativos, especialmente quando crianças estão envolvidas. Além disso, a investigação coincide com ações de autoridades francesas que estão apurando se o Grok gerou material de abuso sexual infantil e conteúdo de negação do Holocausto. A Comissão Europeia também lançou uma investigação para avaliar se a X cumpriu as normas do Digital Services Act antes de implementar o Grok. A ICO pode impor multas de até £17,5 milhões ou 4% do faturamento global da empresa, o que ressalta a gravidade da situação e a necessidade de conformidade com a legislação de proteção de dados.&lt;/p></description></item><item><title>Gestão de Identidade para Agentes de IA Um Novo Desafio de Segurança</title><link>https://brdefense.center/news/gestao-de-identidade-para-agentes-de-ia-um-novo-de/</link><pubDate>Tue, 03 Feb 2026 13:38:20 -0300</pubDate><guid>https://brdefense.center/news/gestao-de-identidade-para-agentes-de-ia-um-novo-de/</guid><description>&lt;p>O artigo de Ido Shlomo, CTO e cofundador da Token Security, destaca a crescente presença de agentes de IA autônomos nas empresas e os riscos associados à sua gestão de identidade. Tradicionalmente, as organizações gerenciavam identidades de humanos e máquinas, mas os agentes de IA não se encaixam perfeitamente em nenhuma dessas categorias. Eles são adaptáveis, operam em alta velocidade e podem realizar ações sem supervisão humana, o que cria lacunas significativas na governança de identidade. A falta de visibilidade sobre esses agentes leva a um crescimento descontrolado de identidades, tornando-as alvos fáceis para atacantes. O artigo sugere que a gestão do ciclo de vida das identidades dos agentes de IA deve ser contínua e em tempo real, garantindo visibilidade, responsabilidade e o princípio do menor privilégio. Além disso, enfatiza a importância de descobrir e monitorar esses agentes para evitar riscos de segurança. A gestão eficaz das identidades dos agentes de IA é apresentada como uma solução para mitigar riscos sem comprometer a inovação nas organizações.&lt;/p></description></item><item><title>Mais de 230 pacotes maliciosos afetam assistente de IA OpenClaw</title><link>https://brdefense.center/news/mais-de-230-pacotes-maliciosos-afetam-assistente-d/</link><pubDate>Tue, 03 Feb 2026 02:11:10 -0300</pubDate><guid>https://brdefense.center/news/mais-de-230-pacotes-maliciosos-afetam-assistente-d/</guid><description>&lt;p>Recentemente, mais de 230 pacotes maliciosos foram publicados no registro oficial do assistente de IA OpenClaw, anteriormente conhecido como Moltbot e ClawdBot. Esses pacotes, chamados de &amp;lsquo;skills&amp;rsquo;, se disfarçam como ferramentas legítimas, mas têm como objetivo injetar malware que rouba dados sensíveis, como chaves de API, credenciais de SSH e senhas de navegadores. O projeto, que é um assistente de IA de código aberto projetado para rodar localmente, apresenta riscos de segurança se não for configurado corretamente. Pesquisadores de segurança alertaram que muitas interfaces administrativas do OpenClaw estão mal configuradas e expostas na web pública. A infecção ocorre quando os usuários seguem instruções enganosas contidas na documentação dos pacotes, que incluem um mecanismo de entrega de malware disfarçado de uma ferramenta chamada &amp;lsquo;AuthTool&amp;rsquo;. O malware, identificado como uma variante do NovaStealer, é capaz de contornar proteções do sistema e roubar informações críticas. A situação é agravada por uma campanha em larga escala que visa usuários do OpenClaw, com a necessidade urgente de os usuários verificarem a segurança dos pacotes antes da instalação.&lt;/p></description></item><item><title>Infraestrutura de IA exposta representa risco crescente à segurança</title><link>https://brdefense.center/news/infraestrutura-de-ia-exposta-representa-risco-cres/</link><pubDate>Thu, 29 Jan 2026 19:02:04 -0300</pubDate><guid>https://brdefense.center/news/infraestrutura-de-ia-exposta-representa-risco-cres/</guid><description>&lt;p>Uma investigação conjunta da SentinelOne e Censys revelou que a implementação de inteligência artificial (IA) de código aberto criou uma vasta camada de infraestrutura de computação de IA não gerenciada, com 175.000 hosts únicos do Ollama em 130 países. A maioria das exposições está na China, seguida por países como EUA, Alemanha e Brasil. Esses sistemas operam fora dos controles de segurança padrão, apresentando riscos significativos. Quase 50% dos hosts observados possuem capacidades de chamada de ferramentas, permitindo a execução de código e acesso a APIs, o que altera o modelo de ameaça. A falta de autenticação e a exposição à rede aumentam o risco de LLMjacking, onde recursos de infraestrutura de IA são explorados por agentes maliciosos. A operação chamada &amp;lsquo;Operation Bizarre Bazaar&amp;rsquo; tem como alvo endpoints de serviços LLM expostos, comercializando o acesso a essas infraestruturas. A natureza descentralizada do ecossistema Ollama complica a governança e abre novas avenidas para injeções de prompt e tráfego malicioso. Para os defensores, é crucial tratar os LLMs com os mesmos controles de autenticação e monitoramento aplicados a outras infraestruturas acessíveis externamente.&lt;/p></description></item><item><title>Campanha maliciosa ataca serviços de IA expostos para acesso não autorizado</title><link>https://brdefense.center/news/campanha-maliciosa-ataca-servicos-de-ia-expostos-p/</link><pubDate>Wed, 28 Jan 2026 13:21:40 -0300</pubDate><guid>https://brdefense.center/news/campanha-maliciosa-ataca-servicos-de-ia-expostos-p/</guid><description>&lt;p>Uma campanha maliciosa, chamada &amp;lsquo;Bizarre Bazaar&amp;rsquo;, está visando endpoints de Modelos de Linguagem de Grande Escala (LLMs) expostos, com o objetivo de comercializar acesso não autorizado à infraestrutura de IA. Pesquisadores da Pillar Security registraram mais de 35.000 sessões de ataque em 40 dias, revelando uma operação de cibercrime em larga escala. Os atacantes exploram configurações inadequadas, como endpoints não autenticados, para roubar recursos computacionais para mineração de criptomoedas, revender acesso a APIs em mercados darknet e exfiltrar dados de conversas. Os vetores de ataque comuns incluem configurações de LLM auto-hospedadas e APIs de IA expostas. A operação é atribuída a um ator específico que utiliza os pseudônimos “Hecker”, “Sakuya” e “LiveGamer101”. Além disso, a Pillar Security está monitorando uma campanha separada focada em reconhecimento de endpoints de Model Context Protocol (MCP), que pode oferecer oportunidades adicionais de movimento lateral. A campanha &amp;lsquo;Bizarre Bazaar&amp;rsquo; continua ativa, e o serviço associado, SilverInc, ainda está operacional.&lt;/p></description></item><item><title>Grupo de hackers norte-coreano usa malware PowerShell gerado por IA</title><link>https://brdefense.center/news/grupo-de-hackers-norte-coreano-usa-malware-powersh/</link><pubDate>Sat, 24 Jan 2026 12:57:47 -0300</pubDate><guid>https://brdefense.center/news/grupo-de-hackers-norte-coreano-usa-malware-powersh/</guid><description>&lt;p>O grupo de hackers norte-coreano Konni (também conhecido como Opal Sleet ou TA406) está utilizando malware PowerShell gerado por inteligência artificial para atacar desenvolvedores e engenheiros no setor de blockchain. Ativo desde 2014, o grupo é associado a atividades de APT37 e Kimsuky, e tem como alvo organizações na Coreia do Sul, Rússia, Ucrânia e diversos países da Europa. A mais recente campanha do grupo foca na região da Ásia-Pacífico, com amostras de malware enviadas de países como Japão, Austrália e Índia.&lt;/p></description></item><item><title>Curl encerra programa de recompensas por bugs devido a relatos gerados por IA</title><link>https://brdefense.center/news/curl-encerra-programa-de-recompensas-por-bugs-devi/</link><pubDate>Fri, 23 Jan 2026 18:58:55 -0300</pubDate><guid>https://brdefense.center/news/curl-encerra-programa-de-recompensas-por-bugs-devi/</guid><description>&lt;p>O fundador do curl, Daniel Stenberg, anunciou que o projeto não participará mais do programa de recompensas por bugs da HackerOne, devido ao aumento de relatos de vulnerabilidades de baixa qualidade, muitos dos quais foram gerados por inteligência artificial. Essa decisão, que entra em vigor em 1º de fevereiro de 2026, foi motivada pela pressão sobre a pequena equipe do curl, que enfrentou um aumento significativo de relatos inválidos, afetando sua saúde mental. O curl, uma ferramenta de linha de comando amplamente utilizada para transferência de dados, tinha um programa de recompensas ativo desde 2019, mas a qualidade dos relatos se deteriorou, com Stenberg relatando que, em uma semana, foram recebidos sete relatos, todos sem identificação de vulnerabilidades reais. A partir de agora, os relatos serão aceitos apenas através do GitHub, e aqueles que enviarem informações irrelevantes poderão ser banidos e expostos publicamente. Essa mudança reflete um desafio crescente na cibersegurança, onde a automação e a IA estão impactando a qualidade das informações recebidas por projetos de segurança.&lt;/p></description></item><item><title>A vulnerabilidade da codificação assistida por IA em segurança cibernética</title><link>https://brdefense.center/news/a-vulnerabilidade-da-codificacao-assistida-por-ia/</link><pubDate>Fri, 23 Jan 2026 13:03:44 -0300</pubDate><guid>https://brdefense.center/news/a-vulnerabilidade-da-codificacao-assistida-por-ia/</guid><description>&lt;p>O uso de modelos de IA para auxiliar na escrita de código, conhecido como &amp;ldquo;vibe coding&amp;rdquo;, tem se tornado comum entre equipes de desenvolvimento, oferecendo economia de tempo, mas também introduzindo riscos de segurança. Um estudo de caso da Intruder ilustra como um código gerado por IA pode criar vulnerabilidades. Ao desenvolver um honeypot para coletar tentativas de exploração, a equipe utilizou IA para criar um protótipo. Após a implementação, logs mostraram que cabeçalhos de IP fornecidos pelo cliente estavam sendo tratados como IPs de visitantes, permitindo que atacantes injetassem cargas úteis. Essa falha, que poderia ter consequências graves, foi detectada apenas após uma revisão manual, evidenciando a limitação da análise estática de código. A experiência ressalta a necessidade de cautela ao confiar em código gerado por IA, especialmente por equipes sem formação em segurança. Com o aumento das ameaças cibernéticas, é crucial que as organizações revisitem seus processos de revisão de código e detecção de vulnerabilidades para evitar que problemas semelhantes passem despercebidos.&lt;/p></description></item><item><title>Falha no Google Gemini permite roubo de dados via Calendário</title><link>https://brdefense.center/news/falha-no-google-gemini-permite-roubo-de-dados-via/</link><pubDate>Tue, 20 Jan 2026 19:00:23 -0300</pubDate><guid>https://brdefense.center/news/falha-no-google-gemini-permite-roubo-de-dados-via/</guid><description>&lt;p>Pesquisadores da Miggo Security identificaram uma vulnerabilidade no Google Gemini que possibilita a injeção indireta de comandos maliciosos, utilizando o Calendário Google como vetor de ataque. Os criminosos criam um evento de calendário e, na descrição, inserem um prompt em linguagem natural que manipula a inteligência artificial do Gemini. Quando a vítima interage com o chatbot, fazendo perguntas sobre sua agenda, o sistema pode acabar extraindo dados privados e os repassando aos atacantes sem que o usuário perceba. Embora a Google já tenha corrigido a falha, o incidente ressalta os riscos associados ao uso de agentes de IA na automação de tarefas, especialmente quando lidam com informações sensíveis. Pesquisadores alertam que chatbots ainda não são totalmente seguros para gerenciar dados pessoais sem diretrizes rigorosas. Este caso destaca a necessidade de vigilância constante e de práticas de segurança robustas ao utilizar tecnologias de IA em ambientes corporativos.&lt;/p></description></item><item><title>Ataque ao Google Gemini vaza dados privados do Calendário</title><link>https://brdefense.center/news/ataque-ao-google-gemini-vaza-dados-privados-do-cal/</link><pubDate>Tue, 20 Jan 2026 18:58:16 -0300</pubDate><guid>https://brdefense.center/news/ataque-ao-google-gemini-vaza-dados-privados-do-cal/</guid><description>&lt;p>Pesquisadores da Miggo Security descobriram uma vulnerabilidade no assistente de IA Google Gemini, que permite a exfiltração de dados privados do Calendário através de um ataque de injeção de prompt. O ataque começa com o envio de um convite para um evento, contendo uma descrição maliciosa que atua como um payload. Quando a vítima pergunta ao assistente sobre sua agenda, o Gemini processa o evento malicioso e pode vazar informações sensíveis, como resumos de reuniões privadas. Essa técnica se aproveita da capacidade do Gemini de interpretar dados de eventos para ser útil, mas que pode ser manipulada por atacantes. Apesar de o Google ter implementado medidas de segurança após um ataque semelhante em 2025, a nova abordagem dos pesquisadores destaca a dificuldade em prever novas formas de exploração em sistemas de IA. A Miggo compartilhou suas descobertas com o Google, que já está trabalhando em novas mitigação para bloquear esses ataques, mas a complexidade da linguagem natural continua a representar um desafio significativo para a segurança.&lt;/p></description></item><item><title>Vulnerabilidades críticas no servidor Git MCP da Anthropic</title><link>https://brdefense.center/news/vulnerabilidades-criticas-no-servidor-git-mcp-da-a/</link><pubDate>Tue, 20 Jan 2026 13:16:48 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidades-criticas-no-servidor-git-mcp-da-a/</guid><description>&lt;p>Um conjunto de três vulnerabilidades de segurança foi revelado no mcp-server-git, o servidor oficial do Protocolo de Contexto de Modelo Git (MCP) mantido pela Anthropic. Essas falhas podem ser exploradas para ler ou deletar arquivos arbitrários e executar código sob certas condições. Segundo o pesquisador Yarden Porat, da Cyata, a exploração ocorre por meio de injeção de prompt, permitindo que um atacante influencie o que um assistente de IA lê, como um README malicioso ou uma descrição de problema comprometida, sem acesso direto ao sistema da vítima. As vulnerabilidades, identificadas como CVE-2025-68143, CVE-2025-68144 e CVE-2025-68145, têm pontuações CVSS que variam de 7.1 a 8.8, indicando um risco elevado. Elas foram corrigidas nas versões 2025.9.25 e 2025.12.18, após divulgação responsável em junho de 2025. A exploração bem-sucedida pode permitir que um atacante transforme qualquer diretório em um repositório Git e acesse repositórios no servidor. Em resposta, a ferramenta git_init foi removida do pacote e validações adicionais foram implementadas. Usuários são aconselhados a atualizar para as versões mais recentes para garantir proteção adequada.&lt;/p></description></item><item><title>Google testa Skills para Gemini no Chrome</title><link>https://brdefense.center/news/google-testa-skills-para-gemini-no-chrome/</link><pubDate>Sun, 18 Jan 2026 18:57:41 -0300</pubDate><guid>https://brdefense.center/news/google-testa-skills-para-gemini-no-chrome/</guid><description>&lt;p>O Google está testando uma nova funcionalidade chamada &amp;lsquo;Skills&amp;rsquo; para o Gemini, sua inteligência artificial integrada ao navegador Chrome. Essa funcionalidade permitirá que o Gemini execute tarefas automaticamente, atuando como um assistente dentro do navegador. Atualmente, o Gemini já está disponível para usuários de desktop nos Estados Unidos, onde pode ajudar a explicar partes confusas de páginas, resumir conteúdos e comparar informações entre várias abas. Por exemplo, ao pesquisar por voos, hotéis e atividades, o usuário pode solicitar que o Gemini compile as informações em um único plano claro.&lt;/p></description></item><item><title>Google Chrome permite excluir modelos de IA da proteção aprimorada</title><link>https://brdefense.center/news/google-chrome-permite-excluir-modelos-de-ia-da-pro/</link><pubDate>Sun, 18 Jan 2026 01:32:30 -0300</pubDate><guid>https://brdefense.center/news/google-chrome-permite-excluir-modelos-de-ia-da-pro/</guid><description>&lt;p>O Google Chrome agora oferece a opção de excluir modelos de inteligência artificial (IA) que alimentam sua funcionalidade de &amp;lsquo;Proteção Aprimorada&amp;rsquo;, atualizada no ano passado com capacidades de IA. Essa proteção, que já existia há alguns anos, foi aprimorada para fornecer segurança em tempo real contra sites, downloads e extensões perigosas. Embora não esteja claro como essa nova versão se diferencia da anterior, a IA pode estar sendo utilizada para identificar padrões em tempo real e alertar os usuários sobre sites potencialmente prejudiciais, mesmo aqueles que não foram previamente identificados pelo Google. Além disso, a proteção baseada em IA realiza uma varredura detalhada de downloads suspeitos. Para excluir o modelo de IA, os usuários devem acessar as configurações do Chrome e desativar a opção &amp;lsquo;On-device GenAI&amp;rsquo;. Essa funcionalidade está atualmente disponível na versão Canary do Chrome e será lançada para todos em breve. É importante notar que o modelo de IA local também pode ser utilizado para outras funcionalidades além da detecção de fraudes.&lt;/p></description></item><item><title>Extensão Copilot Studio para VS Code agora disponível para todos os usuários</title><link>https://brdefense.center/news/extensao-copilot-studio-para-vs-code-agora-disponi/</link><pubDate>Thu, 15 Jan 2026 18:58:39 -0300</pubDate><guid>https://brdefense.center/news/extensao-copilot-studio-para-vs-code-agora-disponi/</guid><description>&lt;p>A Microsoft anunciou que a extensão Copilot Studio para o Visual Studio Code (VS Code) está agora acessível a todos os desenvolvedores. Essa ferramenta permite que os usuários construam e gerenciem agentes do Copilot Studio diretamente no VS Code, utilizando fluxos de trabalho padrão de desenvolvimento de software. O VS Code, um editor de código multiplataforma amplamente utilizado, oferece integração com Git e suporte a pipelines de CI/CD, além de permitir a personalização através de extensões.&lt;/p></description></item><item><title>Novo método de ataque permite exfiltração de dados de chatbots</title><link>https://brdefense.center/news/novo-metodo-de-ataque-permite-exfiltracao-de-dados/</link><pubDate>Thu, 15 Jan 2026 13:19:07 -0300</pubDate><guid>https://brdefense.center/news/novo-metodo-de-ataque-permite-exfiltracao-de-dados/</guid><description>&lt;p>Pesquisadores de cibersegurança revelaram um novo método de ataque chamado Reprompt, que pode permitir que criminosos exfiltratem dados sensíveis de chatbots de inteligência artificial, como o Microsoft Copilot, com apenas um clique. Segundo Dolev Taler, pesquisador da Varonis, o ataque não requer interação adicional do usuário após o primeiro clique em um link legítimo. O Reprompt utiliza três técnicas principais: a injeção de instruções via parâmetro de URL, a manipulação das salvaguardas de proteção de dados e a criação de uma cadeia contínua de solicitações que permite a exfiltração dinâmica de dados. Isso significa que, após um único clique, o atacante pode controlar a sessão do Copilot e solicitar informações sensíveis, como detalhes sobre arquivos acessados ou dados pessoais do usuário. Embora a Microsoft tenha corrigido a vulnerabilidade, o ataque destaca a fragilidade das defesas atuais contra injeções de prompt, que continuam a ser uma preocupação crescente na segurança de sistemas de IA. O Reprompt exemplifica como a falta de distinção entre instruções de usuários e solicitações externas pode ser explorada, tornando-se um ponto cego na segurança das empresas.&lt;/p></description></item><item><title>ServiceNow vulnerável devido a falhas na autenticação com IA</title><link>https://brdefense.center/news/servicenow-vulneravel-devido-a-falhas-na-autentica/</link><pubDate>Wed, 14 Jan 2026 18:58:42 -0300</pubDate><guid>https://brdefense.center/news/servicenow-vulneravel-devido-a-falhas-na-autentica/</guid><description>&lt;p>A ServiceNow, uma das principais empresas de TI do mundo, enfrentou uma grave vulnerabilidade de segurança relacionada à autenticação, que a deixou exposta a ataques cibernéticos. A falha, identificada pela AppOmni, permitia que hackers acessassem a infraestrutura da empresa utilizando apenas o e-mail de um usuário, sem a necessidade de senha ou autenticação adicional. Isso se deu em parte pela implementação de um chatbot, o Virtual Agent, que foi distribuído com credenciais comuns para todos os serviços de terceiros. A situação se agravou com a atualização do agente virtual para a tecnologia Now Assist, que ampliou o potencial de exploração para outras plataformas internas, como Salesforce e Microsoft. Embora a ServiceNow tenha corrigido a vulnerabilidade em outubro de 2025, a falha representa um risco crítico para a cadeia de suprimentos, uma vez que a empresa atende 85% das companhias da Fortune 500. Especialistas recomendam que as empresas não apenas apliquem patches, mas também evitem conceder a agentes de IA a capacidade de realizar ações críticas sem supervisão adequada.&lt;/p></description></item><item><title>Botnet ataca bases de dados de criptomoedas com credenciais criadas por IA</title><link>https://brdefense.center/news/botnet-ataca-bases-de-dados-de-criptomoedas-com-cr/</link><pubDate>Tue, 13 Jan 2026 13:08:10 -0300</pubDate><guid>https://brdefense.center/news/botnet-ataca-bases-de-dados-de-criptomoedas-com-cr/</guid><description>&lt;p>Uma nova onda de ataques cibernéticos, conhecida como GoBruteforcer, está focando em bases de dados de criptomoedas e projetos de blockchain. Esses ataques utilizam botnets para realizar preenchimento de credenciais em massa, invadindo contas por meio de força bruta. Os serviços mais afetados incluem FTP, MySQL, PostgreSQL e phpMyAdmin em servidores Linux. Pesquisadores da Check Point Research identificaram que a campanha é impulsionada pelo uso de servidores gerados por inteligência artificial (IA) que propagam nomes de usuário e senhas padrão, além da presença de stacks web legados, como o XAMPP, que expõem interfaces com segurança mínima. A GoBruteforcer foi inicialmente descoberta pela Palo Alto Networks em março de 2023 e, em 2025, a equipe Black Lotus da Lumen Technologies confirmou a integração de bots da família SystemBC na botnet. Os hackers exploram servidores vulneráveis para subir web shells em PHP, permitindo o download de bots que executam scripts maliciosos. Isso possibilita ataques de força bruta, hospedagem de payloads maliciosos e controle remoto dos servidores. É crucial que as organizações verifiquem se suas implementações não utilizam credenciais padrão ou são baseadas em IA generativa para evitar invasões e a integração em botnets como a GoBruteforcer.&lt;/p></description></item><item><title>Extensões populares do Chrome roubam conversas do ChatGPT</title><link>https://brdefense.center/news/extensoes-populares-do-chrome-roubam-conversas-do/</link><pubDate>Fri, 09 Jan 2026 13:02:12 -0300</pubDate><guid>https://brdefense.center/news/extensoes-populares-do-chrome-roubam-conversas-do/</guid><description>&lt;p>Pesquisadores da Ox Security identificaram atividades maliciosas em duas extensões da Chrome Web Store, que estão coletando dados de usuários de chatbots de IA, como ChatGPT e DeepSeek. As extensões, chamadas &amp;lsquo;Chat GPT for Chrome with GPT-5, Claude Sonnet &amp;amp; DeepSeek AI&amp;rsquo; e &amp;lsquo;AI Sidebar with Deepseek, ChatGPT, Claude, and more&amp;rsquo;, possuem, respectivamente, 600 mil e 300 mil usuários. Elas enviam informações a servidores controlados por hackers a cada 30 segundos, utilizando um truque que solicita consentimento para compartilhar &amp;lsquo;dados analíticos anônimos&amp;rsquo;. Na verdade, elas coletam todo o conteúdo das conversas dos usuários. Essa prática, conhecida como &amp;lsquo;Prompt Poaching&amp;rsquo;, já foi observada em outras extensões, como a Urban VPN Proxy. As extensões maliciosas imitam uma ferramenta legítima, mas podem expor dados sensíveis, incluindo informações corporativas. Apesar de perderem o selo &amp;lsquo;Em Destaque&amp;rsquo;, continuam disponíveis na loja. A recomendação é que os usuários evitem instalar extensões de fontes desconhecidas, mesmo que pareçam confiáveis.&lt;/p></description></item><item><title>OpenAI lança ChatGPT Health com foco em saúde e privacidade</title><link>https://brdefense.center/news/openai-lanca-chatgpt-health-com-foco-em-saude-e-pr/</link><pubDate>Thu, 08 Jan 2026 07:00:08 -0300</pubDate><guid>https://brdefense.center/news/openai-lanca-chatgpt-health-com-foco-em-saude-e-pr/</guid><description>&lt;p>A OpenAI anunciou o lançamento do ChatGPT Health, uma nova funcionalidade que permite aos usuários interagir com um chatbot sobre questões de saúde. Este espaço dedicado oferece a opção de conectar de forma segura registros médicos e aplicativos de bem-estar, como Apple Health e MyFitnessPal, para fornecer respostas personalizadas, conselhos nutricionais e sugestões de exercícios. A empresa enfatiza que o ChatGPT Health foi projetado para apoiar, e não substituir, cuidados médicos, e que as conversas são protegidas por criptografia e isolamento. Além disso, as interações na plataforma não são utilizadas para treinar modelos de IA da OpenAI. A nova funcionalidade está disponível para usuários fora da Área Econômica Europeia, Suíça e Reino Unido. A OpenAI também destacou que o modelo foi avaliado com base em padrões clínicos, visando garantir que ele atenda às necessidades reais dos usuários. No entanto, a empresa enfrenta críticas e processos judiciais relacionados a informações de saúde potencialmente prejudiciais fornecidas por suas ferramentas, levantando preocupações sobre a segurança e a confiabilidade das informações médicas geradas por IA.&lt;/p></description></item><item><title>Extensão do Claude para Chrome pode expor dados de usuários</title><link>https://brdefense.center/news/extensao-do-claude-para-chrome-pode-expor-dados-de/</link><pubDate>Tue, 06 Jan 2026 18:58:22 -0300</pubDate><guid>https://brdefense.center/news/extensao-do-claude-para-chrome-pode-expor-dados-de/</guid><description>&lt;p>Especialistas da Zenity Labs alertaram sobre uma nova extensão do Claude, assistente de IA da Anthropic, que opera no Google Chrome e pode expor dados pessoais dos usuários a riscos de segurança. A extensão, que foi lançada em versão beta, permite que a ferramenta interaja com outros sites sem supervisão humana, o que significa que, uma vez instalada, ela pode navegar e realizar ações em plataformas como Google Drive e Slack como se fosse o próprio usuário. Isso levanta preocupações sobre a segurança, pois a extensão permanece conectada continuamente, sem a possibilidade de ser desativada manualmente. Os pesquisadores observaram que a extensão pode acessar informações sensíveis, como tokens de login, e realizar ações prejudiciais, como excluir e-mails ou modificar arquivos, sem o conhecimento do usuário. Além disso, a proteção básica do Claude, que solicita permissão do usuário antes de realizar ações, falha em impedir essas atividades, levando a um cenário de &amp;lsquo;fadiga de aprovação&amp;rsquo;, onde os usuários clicam em &amp;lsquo;OK&amp;rsquo; sem verificar as ações da IA. Essa situação destaca a necessidade urgente de uma revisão das práticas de segurança em relação a extensões de navegador e ferramentas de IA.&lt;/p></description></item><item><title>A Evolução da Cibersegurança em um Mundo Impulsionado por IA</title><link>https://brdefense.center/news/a-evolucao-da-ciberseguranca-em-um-mundo-impulsion/</link><pubDate>Mon, 05 Jan 2026 13:01:43 -0300</pubDate><guid>https://brdefense.center/news/a-evolucao-da-ciberseguranca-em-um-mundo-impulsion/</guid><description>&lt;p>A cibersegurança está passando por uma transformação significativa, impulsionada por mudanças nas infraestruturas de nuvem, pontos finais distribuídos e cadeias de suprimento complexas. O foco da segurança deixou de ser uma coleção de soluções pontuais e passou a ser uma questão de arquitetura, confiança e velocidade de execução. O relatório analisa como áreas centrais da cibersegurança, como autenticação, segurança de dados em SaaS, proteção da cadeia de suprimento de software e gerenciamento de riscos humanos, estão se adaptando a adversários que utilizam técnicas técnicas e sociais de forma mais rápida e integrada.&lt;/p></description></item><item><title>Deepfakes Riscos e Como se Proteger</title><link>https://brdefense.center/news/deepfakes-riscos-e-como-se-proteger/</link><pubDate>Sat, 03 Jan 2026 12:58:33 -0300</pubDate><guid>https://brdefense.center/news/deepfakes-riscos-e-como-se-proteger/</guid><description>&lt;p>Os deepfakes, conteúdos gerados por inteligência artificial que alteram vídeos e fotos de forma hiper-realista, representam um dos maiores desafios para a segurança digital atualmente. Com um aumento alarmante de 700% em fraudes relacionadas a deepfakes no Brasil, segundo a Sumsub, a manipulação de conteúdo pode ter fins ilícitos, como desinformação e golpes. Personalidades públicas são frequentemente alvo, pois há uma abundância de material audiovisual disponível para a criação desses conteúdos. O advogado Mario Cosac destaca que a desinformação pode impactar decisões importantes, como ocorreu no plebiscito do Brexit, enquanto Augusto Salomon, CEO da StarMind, alerta para a falta de preparo das empresas na adoção de ferramentas de IA. Embora não haja legislação específica no Brasil sobre deepfakes, iniciativas em outros países, como a Dinamarca, propõem que cidadãos tenham controle sobre os direitos de uso de suas imagens. Além disso, a educação digital é vista como uma solução essencial para capacitar a população a lidar com essa nova realidade tecnológica, exigindo um pensamento crítico e habilidades de checagem. O artigo enfatiza a necessidade de uma abordagem multifacetada que inclua regulamentação, tecnologia de detecção e educação para mitigar os riscos associados aos deepfakes.&lt;/p></description></item><item><title>Segurança em SaaS Desafios e Soluções com a IA</title><link>https://brdefense.center/news/seguranca-em-saas-desafios-e-solucoes-com-a-ia/</link><pubDate>Thu, 18 Dec 2025 13:00:37 -0300</pubDate><guid>https://brdefense.center/news/seguranca-em-saas-desafios-e-solucoes-com-a-ia/</guid><description>&lt;p>Nos últimos anos, a integração de assistentes de inteligência artificial (IA) em aplicações SaaS, como Zoom, Slack e Microsoft 365, trouxe uma nova dinâmica ao gerenciamento de dados e segurança. Esses assistentes, que operam em alta velocidade e com privilégios elevados, criam caminhos de integração dinâmicos entre diferentes sistemas, o que desafia os modelos tradicionais de segurança que assumem interfaces fixas e papéis de usuário estáveis. A dificuldade em rastrear as ações desses agentes de IA, que muitas vezes se misturam aos logs de usuários normais, expõe vulnerabilidades significativas. Para mitigar esses riscos, as equipes de segurança precisam adotar uma abordagem de segurança dinâmica, que monitore e adapte as políticas em tempo real, garantindo visibilidade e auditabilidade das ações dos assistentes de IA. Essa nova camada de segurança deve ser capaz de detectar desvios de acesso e comportamentos anômalos, permitindo uma resposta proativa a incidentes. À medida que as organizações adotam copilotos de IA, é crucial que os líderes de segurança reavaliem suas estratégias para garantir que a inovação não comprometa a segurança dos dados.&lt;/p></description></item><item><title>Aumenta a Necessidade de Segurança em Desenvolvimento de Software com IA</title><link>https://brdefense.center/news/aumenta-a-necessidade-de-seguranca-em-desenvolvime/</link><pubDate>Tue, 16 Dec 2025 12:59:39 -0300</pubDate><guid>https://brdefense.center/news/aumenta-a-necessidade-de-seguranca-em-desenvolvime/</guid><description>&lt;p>O crescimento acelerado no desenvolvimento de software assistido por IA traz desafios significativos para as equipes de segurança e privacidade. Com o aumento do número de aplicações e a velocidade das mudanças, as soluções tradicionais de segurança de dados se mostram reativas e ineficazes. Problemas como a exposição de dados sensíveis em logs e a falta de mapeamento preciso de dados aumentam os riscos de privacidade. O HoundDog.ai surge como uma solução proativa, oferecendo um scanner de código focado em privacidade que identifica riscos e vazamentos de dados antes que o código seja implementado. Essa ferramenta analisa rapidamente milhões de linhas de código, permitindo que as equipes detectem e previnam problemas de segurança desde as fases iniciais do desenvolvimento. Além disso, a integração com plataformas como Replit amplia a visibilidade sobre os riscos de privacidade em aplicações geradas por IA. A necessidade de controles de governança e detecção embutidos no processo de desenvolvimento é mais urgente do que nunca, especialmente em um cenário onde a conformidade com legislações como a LGPD é crítica.&lt;/p></description></item><item><title>A ofensiva impulsionada por IA contra SaaS a identidade é o elo mais fraco</title><link>https://brdefense.center/news/a-ofensiva-impulsionada-por-ia-contra-saas-a-ident/</link><pubDate>Sun, 14 Dec 2025 12:56:57 -0300</pubDate><guid>https://brdefense.center/news/a-ofensiva-impulsionada-por-ia-contra-saas-a-ident/</guid><description>&lt;p>Os ataques cibernéticos modernos estão se transformando, com a identidade se tornando o principal alvo dos criminosos. Em um cenário onde 75% das organizações enfrentaram incidentes relacionados a SaaS no último ano, a maioria envolvendo credenciais comprometidas, a segurança da identidade se torna crucial. Os atacantes utilizam inteligência artificial (IA) para imitar usuários legítimos, contornando controles de segurança e operando de forma discreta em ambientes confiáveis. A IA é empregada em várias etapas do ataque, desde a coleta de informações sobre funcionários até a geração de identidades sintéticas que dificultam a detecção. O uso de modelos de linguagem avançados permite que os criminosos criem campanhas de phishing mais sofisticadas e personalizadas. Além disso, a automação de processos de ataque, como a exploração de credenciais, torna as operações mais eficientes e direcionadas, aumentando a probabilidade de sucesso. Com a identidade se tornando a nova linha de defesa, as empresas precisam reavaliar suas estratégias de segurança para proteger dados críticos em plataformas SaaS.&lt;/p></description></item><item><title>Seis perguntas para elaborar um plano de habilitação de IA</title><link>https://brdefense.center/news/seis-perguntas-para-elaborar-um-plano-de-habilitac/</link><pubDate>Sat, 13 Dec 2025 12:57:33 -0300</pubDate><guid>https://brdefense.center/news/seis-perguntas-para-elaborar-um-plano-de-habilitac/</guid><description>&lt;p>À medida que nos aproximamos do final de 2025, dois fatos sobre a inteligência artificial (IA) são cruciais para os diretores de segurança da informação (CISOs). Primeiro, a maioria dos funcionários já utiliza ferramentas de IA generativa em suas atividades, mesmo que a empresa não forneça acesso ou proíba seu uso. Segundo, muitos desses funcionários já compartilharam informações internas e confidenciais com essas ferramentas. Um estudo da Microsoft revela que 75% dos trabalhadores do conhecimento estavam usando IA generativa em 2024, e 78% deles utilizavam ferramentas pessoais. Isso gera um aumento no &amp;lsquo;Access-Trust Gap&amp;rsquo;, que é a diferença entre aplicativos de negócios confiáveis e aqueles não gerenciados que acessam dados corporativos. Para mitigar riscos, as empresas precisam desenvolver um plano de habilitação de IA que inclua governança e controle de acesso. O artigo propõe seis perguntas essenciais para guiar essa elaboração, como quais casos de uso de IA são prioritários e quais ferramentas devem ser adotadas. A falta de governança pode resultar em violações de políticas e consequências legais. Portanto, é fundamental que as empresas adotem uma abordagem proativa e contínua para a governança da IA, garantindo que os funcionários utilizem aplicativos confiáveis e monitorados.&lt;/p></description></item><item><title>Golpistas envenenam buscas de IA com números de suporte falsos</title><link>https://brdefense.center/news/golpistas-envenenam-buscas-de-ia-com-numeros-de-su/</link><pubDate>Thu, 11 Dec 2025 18:59:17 -0300</pubDate><guid>https://brdefense.center/news/golpistas-envenenam-buscas-de-ia-com-numeros-de-su/</guid><description>&lt;p>Cibercriminosos estão utilizando técnicas de envenenamento de IA para promover números falsos de suporte ao cliente em fontes públicas acessadas por chatbots. Um estudo da Aurascape revelou que essa manipulação, chamada de &amp;ldquo;envenenamento de números de telefone de LLM&amp;rdquo;, afeta modelos de linguagem como a Visão Geral da Google e o navegador Comet da Perplexity. A técnica, que se assemelha à otimização de motores de busca (SEO), visa garantir que sites fraudulentos sejam utilizados como fontes de informação por assistentes de IA. Isso é feito ao comprometer sites legítimos, como os de instituições governamentais e universidades, e ao abusar de plataformas que permitem conteúdo gerado por usuários, como YouTube e Yelp. Os pesquisadores destacam que a dificuldade em distinguir entre informações legítimas e fraudulentas pode levar a usuários a entrarem em contato com call centers falsos, como demonstrado em casos envolvendo as companhias aéreas Emirates e British Airlines. A recomendação é que os usuários verifiquem a veracidade das informações e evitem compartilhar dados sensíveis com assistentes de IA, que ainda não foram amplamente testados em termos de segurança.&lt;/p></description></item><item><title>OpenAI admite que novos modelos podem representar alto risco cibernético</title><link>https://brdefense.center/news/openai-admite-que-novos-modelos-podem-representar/</link><pubDate>Thu, 11 Dec 2025 18:57:12 -0300</pubDate><guid>https://brdefense.center/news/openai-admite-que-novos-modelos-podem-representar/</guid><description>&lt;p>A OpenAI alertou que seus futuros Modelos de Linguagem de Grande Escala (LLMs) podem representar riscos cibernéticos significativos, potencialmente facilitando o desenvolvimento de exploits zero-day e campanhas de ciberespionagem avançadas. Em um recente comunicado, a empresa destacou que as capacidades cibernéticas de seus modelos estão evoluindo rapidamente, o que, embora possa parecer preocupante, também traz benefícios para a defesa cibernética. Para mitigar esses riscos, a OpenAI está investindo em ferramentas de defesa, controles de acesso e um programa de cibersegurança em camadas. A empresa planeja introduzir um programa que oferecerá aos usuários acesso a capacidades aprimoradas para tarefas de cibersegurança. Além disso, a OpenAI formará um conselho consultivo, o Frontier Risk Council, composto por especialistas em cibersegurança, que ajudará a definir limites entre capacidades úteis e potenciais abusos. A OpenAI também participa do Frontier Model Forum, onde compartilha conhecimentos e melhores práticas com parceiros da indústria, visando identificar como as capacidades de IA podem ser potencialmente armadas e como mitigar esses riscos.&lt;/p></description></item><item><title>A segurança na nuvem está mudando como proteger sua infraestrutura</title><link>https://brdefense.center/news/a-seguranca-na-nuvem-esta-mudando-como-proteger-su/</link><pubDate>Wed, 10 Dec 2025 12:59:44 -0300</pubDate><guid>https://brdefense.center/news/a-seguranca-na-nuvem-esta-mudando-como-proteger-su/</guid><description>&lt;p>A segurança na nuvem enfrenta novos desafios, com atacantes explorando vulnerabilidades em configurações, identidades e códigos, em vez de realizar ataques diretos. Ferramentas de segurança convencionais frequentemente falham em detectar essas ameaças, que se disfarçam como atividades normais. O time Cortex Cloud da Palo Alto Networks realizará um webinar técnico para discutir três vetores de ataque que estão contornando a segurança tradicional: erros de configuração de identidade na AWS, ocultação de arquivos maliciosos em modelos de IA e permissões excessivas em Kubernetes. Durante a sessão, especialistas mostrarão como esses ataques são realizados e como as equipes podem melhorar a visibilidade e a detecção de ameaças. O evento promete fornecer insights práticos sobre como auditar logs de nuvem, corrigir permissões arriscadas e aplicar controles voltados para IA, ajudando as organizações a se protegerem antes que vulnerabilidades sejam exploradas. A participação é essencial para fechar as lacunas de segurança e evitar surpresas desagradáveis em relatórios de violação.&lt;/p></description></item><item><title>Sua IA de programação pode estar obedecendo a hackers sem você saber</title><link>https://brdefense.center/news/sua-ia-de-programacao-pode-estar-obedecendo-a-hack/</link><pubDate>Mon, 08 Dec 2025 18:58:34 -0300</pubDate><guid>https://brdefense.center/news/sua-ia-de-programacao-pode-estar-obedecendo-a-hack/</guid><description>&lt;p>Uma pesquisa da empresa de segurança Aikido revelou que ferramentas de inteligência artificial (IA) utilizadas em desenvolvimento de software, como Claude Code, Google Gemini e Codex da OpenAI, podem ser vulneráveis a injeções de prompts maliciosos. Essa vulnerabilidade ocorre quando essas ferramentas são integradas em fluxos de trabalho automatizados, como GitHub Actions e GitLab. Agentes maliciosos podem enviar comandos disfarçados de mensagens de commit ou pedidos de pull, levando a IA a interpretá-los como instruções legítimas. Isso representa um risco significativo, pois muitos modelos de IA possuem altos privilégios em repositórios do GitHub, permitindo ações como edição de arquivos e publicação de conteúdo malicioso. Aikido já reportou a falha ao Google, que corrigiu a vulnerabilidade no Gemini CLI, mas a pesquisa indica que o problema é estrutural e afeta a maioria dos modelos de IA. A falha é considerada extremamente perigosa, pois pode resultar no vazamento de tokens privilegiados do GitHub. A situação exige atenção redobrada dos desenvolvedores e gestores de segurança da informação para evitar possíveis explorações.&lt;/p></description></item><item><title>Mais de 30 falhas em assistentes de programação com IA permitem roubo de dados</title><link>https://brdefense.center/news/mais-de-30-falhas-em-assistentes-de-programacao-co/</link><pubDate>Mon, 08 Dec 2025 18:58:20 -0300</pubDate><guid>https://brdefense.center/news/mais-de-30-falhas-em-assistentes-de-programacao-co/</guid><description>&lt;p>O pesquisador de segurança Ari Marzouk identificou mais de 30 vulnerabilidades em Ambientes Integrados de Desenvolvimento (IDEs) que utilizam inteligência artificial para assistência. Essas falhas, coletivamente chamadas de IDEsaster, permitem que atacantes realizem injeções de prompt, utilizando ferramentas legítimas do sistema para roubar dados e executar códigos remotamente. Entre as IDEs afetadas estão Cursor, GitHub Copilot e Zed.dev, com 24 das vulnerabilidades já registradas como CVEs. Marzouk destaca que as IAs de IDE ignoram o software base em suas análises de segurança, considerando as ferramentas como seguras, o que as torna vulneráveis quando um agente de IA é integrado. Os vetores de ataque incluem a manipulação de contextos e a execução de ações sem interação do usuário. Para mitigar esses riscos, recomenda-se que os usuários utilizem IDEs apenas em projetos confiáveis e monitorem constantemente as conexões com servidores. Além disso, é importante revisar manualmente as fontes adicionadas e estar atento a instruções ocultas que possam ser utilizadas para exploração maliciosa.&lt;/p></description></item><item><title>Vulnerabilidades em IDEs de IA podem levar a vazamentos de dados</title><link>https://brdefense.center/news/vulnerabilidades-em-ides-de-ia-podem-levar-a-vazam/</link><pubDate>Sat, 06 Dec 2025 18:56:49 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidades-em-ides-de-ia-podem-levar-a-vazam/</guid><description>&lt;p>Mais de 30 vulnerabilidades de segurança foram reveladas em ambientes de desenvolvimento integrados (IDEs) que utilizam inteligência artificial (IA), permitindo a exfiltração de dados e execução remota de código. Denominadas &amp;lsquo;IDEsaster&amp;rsquo; pelo pesquisador Ari Marzouk, essas falhas afetam IDEs populares como Cursor, GitHub Copilot e Kiro.dev, com 24 delas recebendo identificadores CVE. As vulnerabilidades exploram a ineficácia dos modelos de linguagem em distinguir entre comandos legítimos e maliciosos, permitindo que atacantes utilizem injeções de prompt para manipular o contexto e acionar funções legítimas das IDEs. Exemplos de ataques incluem a leitura de arquivos sensíveis e a execução de código malicioso através da edição de arquivos de configuração. Marzouk recomenda que desenvolvedores utilizem IDEs de IA apenas com projetos confiáveis e monitorem continuamente servidores de contexto. As descobertas ressaltam a necessidade de um novo paradigma de segurança, &amp;lsquo;Secure for AI&amp;rsquo;, para mitigar os riscos associados ao uso de ferramentas de IA em ambientes de desenvolvimento.&lt;/p></description></item><item><title>Navegadores com IA estão mudando as regras. Sua segurança está acompanhando?</title><link>https://brdefense.center/news/navegadores-com-ia-estao-mudando-as-regras-sua-seg/</link><pubDate>Thu, 04 Dec 2025 13:00:39 -0300</pubDate><guid>https://brdefense.center/news/navegadores-com-ia-estao-mudando-as-regras-sua-seg/</guid><description>&lt;p>Os navegadores modernos, como Microsoft Edge e Google Chrome, estão incorporando assistentes de IA que prometem facilitar a vida dos usuários, oferecendo resumos de páginas, traduções e automação de tarefas. No entanto, essa conveniência pode vir acompanhada de riscos significativos de segurança. A integração de modelos de linguagem avançados permite que esses navegadores interpretem e atuem sobre o conteúdo da web, mas também os torna vulneráveis a ataques. Um exemplo é a injeção de texto invisível em páginas da web, que pode instruir a IA a roubar credenciais ou executar comandos maliciosos sem que o usuário perceba. Isso representa uma ameaça crítica, pois não gera indicadores claros de comprometimento, dificultando a detecção por ferramentas de segurança tradicionais. À medida que essas tecnologias se tornam comuns, é essencial que as organizações adotem uma postura de segurança mais rigorosa, implementando políticas de uso de IA e monitoramento comportamental para mitigar os riscos associados. A necessidade de suporte gerenciado em centros de operações de segurança (SOCs) é cada vez mais evidente, especialmente para empresas menores que podem não ter os recursos para lidar com essas novas ameaças.&lt;/p></description></item><item><title>Pacote npm tenta manipular scanners de segurança baseados em IA</title><link>https://brdefense.center/news/pacote-npm-tenta-manipular-scanners-de-seguranca-b/</link><pubDate>Tue, 02 Dec 2025 13:00:00 -0300</pubDate><guid>https://brdefense.center/news/pacote-npm-tenta-manipular-scanners-de-seguranca-b/</guid><description>&lt;p>Pesquisadores de cibersegurança revelaram a existência de um pacote npm chamado eslint-plugin-unicorn-ts-2, que busca influenciar scanners de segurança impulsionados por inteligência artificial (IA). O pacote, que se apresenta como uma extensão do popular plugin ESLint para TypeScript, foi carregado em fevereiro de 2024 e já foi baixado quase 19 mil vezes. Uma análise da Koi Security identificou que o pacote contém um prompt que sugere que o código é legítimo e testado em um ambiente seguro, embora essa string não afete a funcionalidade do pacote. O código malicioso, introduzido na versão 1.1.3, possui um hook pós-instalação que captura variáveis de ambiente, como chaves de API e credenciais, e as exfiltra para um webhook. Essa abordagem reflete uma nova tática de cibercriminosos que buscam manipular ferramentas de análise baseadas em IA, além de explorar um mercado subterrâneo de modelos de linguagem maliciosos. Apesar das limitações desses modelos, como a geração de código incorreto, eles tornam o cibercrime mais acessível a atacantes inexperientes, permitindo ataques mais sofisticados em larga escala.&lt;/p></description></item><item><title>Novo IDE Antigravity da Google levanta preocupações de segurança</title><link>https://brdefense.center/news/novo-ide-antigravity-da-google-levanta-preocupacoe/</link><pubDate>Mon, 01 Dec 2025 18:58:55 -0300</pubDate><guid>https://brdefense.center/news/novo-ide-antigravity-da-google-levanta-preocupacoe/</guid><description>&lt;p>O novo IDE Antigravity da Google, que utiliza inteligência artificial, já enfrenta sérias críticas relacionadas à segurança. Especialistas da PromptArmor alertaram que, sob configurações padrão, o sistema permite que agentes executem comandos automaticamente, o que pode resultar em comportamentos indesejados. Quando entradas não confiáveis aparecem em arquivos de código, o agente pode ser manipulado para executar comandos não intencionais pelo usuário. Além disso, o IDE apresenta vulnerabilidades que permitem a exfiltração de dados, como credenciais e informações sensíveis, através de instruções ocultas em Markdown ou invocações de ferramentas. Embora a Google tenha implementado algumas salvaguardas, lacunas nos controles de segurança ainda permitem que ataques de injeção de comandos sejam realizados. O IDE também pode contornar restrições de acesso a arquivos sensíveis, como aqueles listados em .gitignore, utilizando comandos de terminal. A empresa reconheceu esses problemas e emitiu avisos durante o processo de integração, mas isso não é suficiente, pois os agentes podem operar sem supervisão. Essa situação destaca os riscos associados ao uso de ferramentas de IA com ampla autonomia, sem as devidas salvaguardas estruturais.&lt;/p></description></item><item><title>Navegadores de IA podem ser sequestrados com um simples hashtag</title><link>https://brdefense.center/news/navegadores-de-ia-podem-ser-sequestrados-com-um-si/</link><pubDate>Fri, 28 Nov 2025 18:58:08 -0300</pubDate><guid>https://brdefense.center/news/navegadores-de-ia-podem-ser-sequestrados-com-um-si/</guid><description>&lt;p>Pesquisadores da Cato Networks revelaram uma nova técnica chamada &amp;lsquo;HashJack&amp;rsquo;, que permite que atacantes manipulem assistentes de IA através de fragmentos ocultos em URLs. Essa vulnerabilidade ocorre quando um hashtag é inserido em um link aparentemente legítimo, permitindo que comandos maliciosos sejam executados localmente no navegador do usuário, sem que ele perceba. Os assistentes de IA podem realizar ações autônomas, como transmitir dados sensíveis para servidores controlados por atacantes, enquanto o usuário continua a ver uma página normal. A pesquisa destaca que muitos navegadores de IA estão sob escrutínio devido a essa falha, que não é detectável por ferramentas de monitoramento tradicionais, pois os fragmentos nunca deixam o dispositivo do usuário. Embora algumas empresas tenham implementado atualizações, a defesa contra essa manipulação indireta depende de como cada assistente processa as instruções ocultas. A conscientização sobre essa limitação é crucial para organizações que utilizam ferramentas de IA, pois as medidas de segurança convencionais não conseguem capturar completamente essas ameaças.&lt;/p></description></item><item><title>Modelo de IA DeepSeek-R1 gera vulnerabilidades em temas sensíveis</title><link>https://brdefense.center/news/modelo-de-ia-deepseek-r1-gera-vulnerabilidades-em/</link><pubDate>Mon, 24 Nov 2025 12:58:45 -0300</pubDate><guid>https://brdefense.center/news/modelo-de-ia-deepseek-r1-gera-vulnerabilidades-em/</guid><description>&lt;p>Uma pesquisa da CrowdStrike revelou que o modelo de inteligência artificial (IA) DeepSeek-R1, desenvolvido pela empresa chinesa DeepSeek, produz um número significativamente maior de vulnerabilidades de segurança quando recebe prompts relacionados a temas considerados politicamente sensíveis pela China. A análise indicou que a probabilidade de gerar código com vulnerabilidades graves aumenta em até 50% ao incluir tais tópicos. O modelo, que já enfrentou preocupações de segurança nacional e foi banido em vários países, também censura questões sensíveis, como a Grande Muralha da China e o status político de Taiwan. O Bureau de Segurança Nacional de Taiwan alertou os cidadãos sobre o uso de modelos de IA generativa chineses, que podem distorcer narrativas históricas e amplificar desinformação. A pesquisa da CrowdStrike destacou que, ao solicitar a criação de código para sistemas de controle industrial em regiões sensíveis, a qualidade do código gerado se deteriora, apresentando falhas de segurança significativas. Além disso, o modelo possui um &amp;lsquo;kill switch&amp;rsquo; intrínseco, recusando-se a gerar código para temas como o Falun Gong em 45% das tentativas. As descobertas ressaltam a necessidade de cautela ao utilizar ferramentas de IA que podem ser influenciadas por diretrizes políticas.&lt;/p></description></item><item><title>Vulnerabilidade em IA da ServiceNow permite ataques de injeção</title><link>https://brdefense.center/news/vulnerabilidade-em-ia-da-servicenow-permite-ataque/</link><pubDate>Wed, 19 Nov 2025 12:59:12 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-em-ia-da-servicenow-permite-ataque/</guid><description>&lt;p>Um novo alerta de segurança destaca como a plataforma de inteligência artificial Now Assist da ServiceNow pode ser explorada por agentes maliciosos. Segundo a AppOmni, configurações padrão da plataforma permitem ataques de injeção de prompt de segunda ordem, onde agentes podem descobrir e recrutar uns aos outros para realizar ações não autorizadas. Isso inclui a cópia e exfiltração de dados sensíveis, modificação de registros e escalonamento de privilégios. O problema não é um bug, mas sim um comportamento esperado devido às configurações padrão que facilitam a comunicação entre agentes. A vulnerabilidade é particularmente preocupante, pois as ações ocorrem em segundo plano, sem que a organização afetada perceba. Para mitigar esses riscos, recomenda-se configurar o modo de execução supervisionada para agentes privilegiados, desabilitar a propriedade de sobreposição autônoma e monitorar o comportamento dos agentes de IA. A ServiceNow reconheceu a questão e atualizou sua documentação, mas a situação ressalta a necessidade de uma proteção mais robusta para agentes de IA em ambientes corporativos.&lt;/p></description></item><item><title>Navegador é porta de entrada para riscos digitais às empresas, aponta pesquisa</title><link>https://brdefense.center/news/navegador-e-porta-de-entrada-para-riscos-digitais/</link><pubDate>Wed, 12 Nov 2025 18:58:55 -0300</pubDate><guid>https://brdefense.center/news/navegador-e-porta-de-entrada-para-riscos-digitais/</guid><description>&lt;p>Um novo relatório, o Browser Security Report 2025, revela que a forma como os navegadores são utilizados nas empresas pode ser a principal fonte de ataques cibernéticos. O estudo destaca que vulnerabilidades no navegador, como extensões maliciosas e prompts enganosos, são responsáveis por muitos riscos relacionados à identidade e ao uso de inteligência artificial (IA). Quase metade dos funcionários utiliza ferramentas de IA em contas não monitoradas, aumentando a exposição a ameaças. O relatório aponta que 77% dos casos analisados envolveram cópias de dados em prompts de IA, com 82% ocorrendo em contas pessoais. Além disso, 99% dos usuários utilizam extensões, e 6% delas são consideradas maliciosas. A pesquisa alerta que 60% dos logins corporativos não utilizam autenticação única, dificultando o controle de acesso. Diante desse cenário, é crucial que as empresas adotem medidas de segurança mais rigorosas, como monitoramento de dados copiados e uso de extensões seguras, para evitar vazamentos de informações e ataques cibernéticos.&lt;/p></description></item><item><title>Microsoft revela novo ataque que espiona chats de IA criptografados</title><link>https://brdefense.center/news/microsoft-revela-novo-ataque-que-espiona-chats-de/</link><pubDate>Tue, 11 Nov 2025 18:58:09 -0300</pubDate><guid>https://brdefense.center/news/microsoft-revela-novo-ataque-que-espiona-chats-de/</guid><description>&lt;p>A Microsoft anunciou a descoberta de um novo tipo de ataque cibernético denominado &amp;lsquo;Whisper Leak&amp;rsquo;, que consegue expor os tópicos discutidos em chats com chatbots de IA, mesmo quando as conversas estão totalmente criptografadas. A pesquisa da empresa indica que atacantes podem analisar o tamanho e o tempo dos pacotes criptografados trocados entre um usuário e um modelo de linguagem, permitindo inferir o conteúdo das discussões. Embora a criptografia proteja o conteúdo das mensagens, a vulnerabilidade reside na forma como os modelos de linguagem enviam respostas, transmitindo dados de forma incremental. Isso cria padrões que podem ser analisados por invasores, permitindo deduzir informações sensíveis. Após a divulgação, empresas como OpenAI e Mistral implementaram medidas para mitigar o problema, como a adição de sequências de texto aleatórias nas respostas. A Microsoft recomenda que os usuários evitem discutir assuntos sensíveis em redes Wi-Fi públicas e utilizem VPNs. Além disso, a pesquisa destaca que muitos modelos de linguagem abertos ainda são vulneráveis a manipulações, especialmente em conversas mais longas, levantando preocupações sobre a segurança das plataformas de chat de IA.&lt;/p></description></item><item><title>Aumento de 156 em ataques de cadeia de suprimentos habilitados por IA</title><link>https://brdefense.center/news/aumento-de-156-em-ataques-de-cadeia-de-suprimentos/</link><pubDate>Tue, 11 Nov 2025 12:58:00 -0300</pubDate><guid>https://brdefense.center/news/aumento-de-156-em-ataques-de-cadeia-de-suprimentos/</guid><description>&lt;p>Os ataques de cadeia de suprimentos habilitados por inteligência artificial (IA) cresceram 156% no último ano, evidenciando a falência das defesas tradicionais. O malware gerado por IA apresenta características inovadoras, como ser polimórfico, consciente do contexto e camuflado semanticamente, o que dificulta sua detecção. Casos reais, como a violação da 3CX que afetou 600 mil empresas, demonstram a gravidade da situação. O tempo médio para identificar uma violação aumentou para 276 dias, e as ferramentas de segurança tradicionais falham em responder a ameaças que se adaptam ativamente. Novas estratégias de defesa estão sendo implementadas, incluindo a segurança ciente de IA e a análise de comportamento. Além disso, a conformidade regulatória, como a Lei de IA da UE, impõe penalidades severas por violações. A situação exige ação imediata das organizações para se protegerem contra essas ameaças emergentes.&lt;/p></description></item><item><title>65 das principais empresas de IA expõem segredos no GitHub</title><link>https://brdefense.center/news/65-das-principais-empresas-de-ia-expoem-segredos-n/</link><pubDate>Tue, 11 Nov 2025 06:57:52 -0300</pubDate><guid>https://brdefense.center/news/65-das-principais-empresas-de-ia-expoem-segredos-n/</guid><description>&lt;p>Uma investigação de segurança revelou que 65% das 50 principais empresas de inteligência artificial (IA) do mundo, avaliadas em mais de 400 bilhões de dólares, expuseram credenciais sensíveis no GitHub. Essas exposições incluem chaves de API e tokens de autenticação, que podem permitir acesso direto aos sistemas das empresas. Os pesquisadores descobriram que os segredos não estavam apenas em repositórios ativos, mas também em forks deletados e contas pessoais de desenvolvedores. A pesquisa destacou que, embora algumas empresas como LangChain e ElevenLabs tenham rapidamente corrigido as vulnerabilidades, quase metade dos vazamentos não recebeu resposta. Para mitigar esses riscos, recomenda-se que as empresas implementem varreduras obrigatórias de segredos em todos os repositórios públicos e estabeleçam canais de divulgação de segurança desde o início. O gerenciamento eficaz de segredos é crucial para proteger os ativos valiosos das empresas de IA e garantir a continuidade da inovação no setor.&lt;/p></description></item><item><title>IA enfrenta desafios em compras online, revela pesquisa da Microsoft</title><link>https://brdefense.center/news/ia-enfrenta-desafios-em-compras-online-revela-pesq/</link><pubDate>Mon, 10 Nov 2025 13:02:14 -0300</pubDate><guid>https://brdefense.center/news/ia-enfrenta-desafios-em-compras-online-revela-pesq/</guid><description>&lt;p>Uma pesquisa realizada pela Microsoft testou a eficácia de várias IAs agentic em um ambiente simulado de marketplace, revelando falhas significativas na escolha de produtos e na busca por informações. Utilizando um ambiente open-source chamado Magentic Marketplace, a pesquisa envolveu agentes de IA como o Operator da OpenAI e a Business AI da Meta, além de modelos como GPT-5 e Gemini 2.5 Flash. Os agentes foram designados a encontrar o melhor preço entre 300 lojas, mas muitos falharam em realizar comparações adequadas, optando por escolhas que pareciam &amp;lsquo;boas o suficiente&amp;rsquo; sem uma análise aprofundada. O estudo também explorou a vulnerabilidade das IAs a manipulações, onde a maioria sucumbiu a táticas de marketing, exceto o Claude Sonnet 4, que se mostrou resistente. Essas falhas levantam preocupações sobre a confiabilidade das IAs como assistentes pessoais, especialmente em contextos críticos como o mercado financeiro, onde decisões automatizadas podem ter consequências significativas. A pesquisa destaca a necessidade de um treinamento mais robusto para essas tecnologias antes que possam ser confiáveis em transações importantes.&lt;/p></description></item><item><title>Relatório de Segurança de Navegadores 2025 Riscos Emergentes</title><link>https://brdefense.center/news/relatorio-de-seguranca-de-navegadores-2025-riscos/</link><pubDate>Mon, 10 Nov 2025 12:58:20 -0300</pubDate><guid>https://brdefense.center/news/relatorio-de-seguranca-de-navegadores-2025-riscos/</guid><description>&lt;p>O Relatório de Segurança de Navegadores 2025 revela que a maioria dos riscos relacionados a identidade, SaaS e inteligência artificial (IA) converge no navegador do usuário, criando uma nova superfície de ameaça. Com quase metade dos funcionários utilizando ferramentas de IA generativa (GenAI) fora da supervisão de TI, 77% deles colam dados em prompts de IA, sendo que 82% dessas colagens vêm de contas pessoais. Além disso, 99% dos usuários corporativos têm extensões instaladas, muitas das quais não são geridas adequadamente, aumentando o risco de vazamentos de dados. Os navegadores de IA, que integram modelos de linguagem diretamente na camada de navegação, também representam uma nova superfície de ataque, permitindo que dados sensíveis sejam processados sem controle. O relatório destaca que as ferramentas tradicionais de segurança, como DLP e EDR, não são suficientes para monitorar essas atividades, pois não inspecionam o que acontece dentro das sessões de navegação. Para mitigar esses riscos, é necessário adotar controles nativos de sessão que ofereçam visibilidade e proteção em tempo real, sem comprometer a experiência do usuário.&lt;/p></description></item><item><title>Atores de Ameaça Usam IA para Atacar Empresas de Manufatura</title><link>https://brdefense.center/news/atores-de-ameaca-usam-ia-para-atacar-empresas-de-m/</link><pubDate>Sat, 08 Nov 2025 06:58:07 -0300</pubDate><guid>https://brdefense.center/news/atores-de-ameaca-usam-ia-para-atacar-empresas-de-m/</guid><description>&lt;p>Um novo relatório revela que 94% das empresas do setor de manufatura estão utilizando aplicações de inteligência artificial generativa (genAI), enquanto enfrentam um aumento nas ameaças cibernéticas. A adoção acelerada de IA tem ampliado a superfície de ataque, com organizações compartilhando documentos técnicos sensíveis com plataformas de IA. Embora o uso de contas pessoais de genAI tenha diminuído, a utilização de soluções aprovadas pelas organizações aumentou, refletindo uma maior conscientização sobre os riscos de governança de dados. No entanto, 67% das empresas estão conectadas a APIs que podem ser vulneráveis a compromissos. Os canais de distribuição de malware estão se aproveitando de serviços de nuvem confiáveis, com o Microsoft OneDrive sendo a plataforma mais explorada, seguida pelo GitHub e Google Drive. As empresas estão implementando controles mais rigorosos, mas a mistura de dados corporativos e pessoais continua a representar riscos significativos. Especialistas em cibersegurança recomendam inspeção rigorosa de downloads e políticas robustas de prevenção de perda de dados para mitigar esses riscos.&lt;/p></description></item><item><title>Pesquisadores apontam falhas de segurança preocupantes no ChatGPT</title><link>https://brdefense.center/news/pesquisadores-apontam-falhas-de-seguranca-preocupa/</link><pubDate>Thu, 06 Nov 2025 18:58:43 -0300</pubDate><guid>https://brdefense.center/news/pesquisadores-apontam-falhas-de-seguranca-preocupa/</guid><description>&lt;p>Pesquisadores da Tenable identificaram sete falhas de injeção de comandos no ChatGPT-4o, denominadas &amp;lsquo;HackedGPT&amp;rsquo;. Essas vulnerabilidades permitem que atacantes insiram comandos ocultos, roubem dados sensíveis e disseminem desinformação. As falhas incluem injeção indireta de comandos através de sites confiáveis, injeção de comandos com um clique, e bypass de mecanismos de segurança utilizando links maliciosos disfarçados. Embora a OpenAI tenha corrigido algumas dessas falhas em seu modelo GPT-5, várias ainda permanecem ativas, colocando milhões de usuários em risco. Os especialistas alertam que essas vulnerabilidades não apenas expõem o ChatGPT a ataques, mas também podem transformar a ferramenta em um vetor de ataque, coletando informações de conversas cotidianas. A Tenable recomenda que os fornecedores de IA reforcem suas defesas contra injeções de comandos, garantindo que os mecanismos de segurança funcionem conforme o esperado. A situação é preocupante, especialmente considerando que ferramentas como o Google Gemini também podem ser suscetíveis a problemas semelhantes, devido à integração com serviços de e-mail.&lt;/p></description></item><item><title>Google alerta usuários sobre novo malware PROMPTFLUX com IA</title><link>https://brdefense.center/news/google-alerta-usuarios-sobre-novo-malware-promptfl/</link><pubDate>Thu, 06 Nov 2025 07:00:48 -0300</pubDate><guid>https://brdefense.center/news/google-alerta-usuarios-sobre-novo-malware-promptfl/</guid><description>&lt;p>O Google Threat Intelligence Group (GTIG) identificou um novo malware chamado PROMPTFLUX, que utiliza a API Gemini para modificar seu próprio código durante a execução. Este dropper é notável por empregar uma técnica chamada &amp;lsquo;just-in-time AI&amp;rsquo;, que permite que o malware altere dinamicamente sua estrutura e conteúdo, dificultando a detecção por métodos tradicionais. O PROMPTFLUX se comunica com a API Gemini para obter novas variantes de código VBScript, focadas em evadir antivírus. Um módulo denominado &amp;lsquo;Thinking Robot&amp;rsquo; automatiza o processo, salvando arquivos regenerados na pasta de inicialização do Windows para garantir persistência. A análise do GTIG revelou que o malware ainda está em fase de desenvolvimento e não foi amplamente implantado. No entanto, a utilização de modelos de linguagem para metamorfose em tempo de execução indica uma evolução significativa em ecossistemas de malware autônomos. Além disso, o relatório correlaciona atividades semelhantes com outros malwares habilitados por IA, como PROMPTSTEAL e PROMPTLOCK, associados a atores estatais de países como Coreia do Norte, Irã e China. O Google reforçou suas medidas de segurança para mitigar esses riscos, destacando a importância do desenvolvimento responsável de IA.&lt;/p></description></item><item><title>Modo IA do Google pode acessar seu Gmail para personalização</title><link>https://brdefense.center/news/modo-ia-do-google-pode-acessar-seu-gmail-para-pers/</link><pubDate>Tue, 04 Nov 2025 13:04:54 -0300</pubDate><guid>https://brdefense.center/news/modo-ia-do-google-pode-acessar-seu-gmail-para-pers/</guid><description>&lt;p>A Google anunciou planos para personalizar suas buscas por meio do novo &amp;lsquo;Modo IA&amp;rsquo;, que poderá acessar informações pessoais de serviços como Gmail e Drive. O vice-presidente de produtos da empresa, Robby Stein, explicou em um podcast que a ideia é que os usuários forneçam dados pessoais para que a Google possa oferecer respostas mais úteis e personalizadas. Isso inclui a possibilidade de extrair informações de e-mails e documentos para criar resumos e agendas, facilitando a organização de compromissos e viagens. Embora a funcionalidade ainda esteja em fase de testes e não tenha sido implementada, a Google já está experimentando a personalização de compras e recomendações de restaurantes. A empresa não confirmou se o acesso a dados pessoais será padrão, mas enfatizou que a participação dos usuários será voluntária. Essa abordagem levanta preocupações sobre privacidade e segurança, especialmente em relação à proteção de dados pessoais sob a Lei Geral de Proteção de Dados (LGPD) no Brasil.&lt;/p></description></item><item><title>Campanhas de desinformação médica utilizam deepfakes de profissionais de saúde</title><link>https://brdefense.center/news/campanhas-de-desinformacao-medica-utilizam-deepfak/</link><pubDate>Mon, 03 Nov 2025 18:58:22 -0300</pubDate><guid>https://brdefense.center/news/campanhas-de-desinformacao-medica-utilizam-deepfak/</guid><description>&lt;p>No Fórum Latinoamericano de Cibersegurança da ESET, a pesquisadora Martina López destacou o uso crescente de deepfakes em campanhas de desinformação médica. A tecnologia, que simula rostos e vozes de forma convincente, tem sido utilizada para criar perfis falsos de médicos, alterando suas credenciais e especializações. Essas campanhas se espalham principalmente em redes sociais menos moderadas, como TikTok e Facebook, e em grupos de aplicativos de mensagens como Telegram e Discord, visando manipular principalmente leigos e pessoas com menor nível educacional. Para combater essa desinformação, iniciativas como o Ato de Inteligência Artificial da União Europeia buscam implementar marca d&amp;rsquo;água em conteúdos gerados por IA. A especialista recomenda que os usuários verifiquem a fonte das informações e utilizem ferramentas de busca reversa para identificar conteúdos falsos. A crescente sofisticação dos deepfakes exige uma vigilância redobrada, pois a tecnologia pode impactar a percepção pública e a saúde coletiva.&lt;/p></description></item><item><title>Nova técnica de camuflagem explora ChatGPT para servir conteúdo falso</title><link>https://brdefense.center/news/nova-tecnica-de-camuflagem-explora-chatgpt-para-se/</link><pubDate>Fri, 31 Oct 2025 07:01:21 -0300</pubDate><guid>https://brdefense.center/news/nova-tecnica-de-camuflagem-explora-chatgpt-para-se/</guid><description>&lt;p>Pesquisadores de segurança revelaram uma nova técnica de ataque chamada &amp;ldquo;camuflagem consciente do agente&amp;rdquo;, que explora como ferramentas de busca baseadas em IA, como o ChatGPT e o navegador Atlas da OpenAI, recuperam conteúdo da web. Essa vulnerabilidade permite que atacantes sirvam versões diferentes de páginas da web para crawlers de IA, enquanto usuários humanos veem conteúdo legítimo. A técnica, que se destaca pela sua simplicidade, utiliza regras condicionais que detectam cabeçalhos de agentes de usuário de IA. Em experimentos controlados, foi demonstrado que, ao acessar um site, crawlers de IA recebiam informações fabricadas, enquanto visitantes humanos viam a versão verdadeira. Isso levanta preocupações sobre a falta de validação de proveniência nos sistemas de recuperação de informações de IA, que tratam o conteúdo como verdade absoluta. As implicações vão além de ataques à reputação, afetando também processos de contratação automatizados. Para mitigar esses riscos, recomenda-se a implementação de defesas em múltiplas camadas, incluindo a verificação criptográfica da autenticidade das informações e protocolos de validação para crawlers. A pesquisa destaca a necessidade urgente de monitoramento contínuo e validação de saídas geradas por IA, especialmente em decisões críticas como contratações e conformidade.&lt;/p></description></item><item><title>Extensões falsas de IA podem roubar senhas enquanto você conversa</title><link>https://brdefense.center/news/extensoes-falsas-de-ia-podem-roubar-senhas-enquant/</link><pubDate>Thu, 30 Oct 2025 01:02:14 -0300</pubDate><guid>https://brdefense.center/news/extensoes-falsas-de-ia-podem-roubar-senhas-enquant/</guid><description>&lt;p>Pesquisadores da SquareX alertam sobre um novo vetor de ataque que utiliza extensões maliciosas para criar barras laterais falsas em navegadores. Essas barras laterais imitam assistentes de IA legítimos e podem capturar informações sensíveis, como senhas e tokens de autenticação, sem que o usuário perceba. O ataque se dá através da injeção de JavaScript nas páginas da web, permitindo que a interface falsa sobreponha a verdadeira, dificultando a detecção. Os especialistas destacam que muitas extensões solicitam permissões amplas, como acesso a hosts e armazenamento, o que torna a análise de permissões uma estratégia de detecção menos eficaz. A crescente popularidade de navegadores com assistentes de IA pode aumentar a superfície de ataque, tornando a segurança mais desafiadora. Os usuários são aconselhados a tratar esses assistentes como recursos experimentais e evitar o manuseio de dados sensíveis. As equipes de segurança devem implementar controles mais rigorosos sobre extensões e monitorar atividades anômalas para mitigar riscos. O artigo enfatiza a necessidade de verificações de integridade da interface e uma melhor orientação sobre o uso aceitável dessas ferramentas.&lt;/p></description></item><item><title>Previsões de Cibersegurança A Identidade como Ponto Crítico em 2026</title><link>https://brdefense.center/news/previsoes-de-ciberseguranca-a-identidade-como-pont/</link><pubDate>Wed, 29 Oct 2025 13:02:36 -0300</pubDate><guid>https://brdefense.center/news/previsoes-de-ciberseguranca-a-identidade-como-pont/</guid><description>&lt;p>O artigo da BeyondTrust destaca que em 2026, as ameaças cibernéticas estarão fortemente ligadas à gestão de identidades. A primeira previsão é a ascensão da IA agente como vetor de ataque, onde ferramentas de IA podem ser manipuladas para executar ações maliciosas devido a permissões inadequadas. A segunda previsão é o aumento do &amp;lsquo;account poisoning&amp;rsquo;, onde fraudadores inserem pagadores e cobradores fraudulentos em contas financeiras, utilizando automação para explorar falhas nos sistemas. Por último, o artigo alerta para a presença de &amp;lsquo;identidades fantasmas&amp;rsquo; em sistemas de gerenciamento de identidade (IAM), que podem resultar em brechas de segurança não detectadas. As organizações devem adotar uma postura de segurança centrada na identidade, aplicando princípios de menor privilégio e zero trust. Além disso, o artigo menciona a obsolescência das VPNs tradicionais e o surgimento do &amp;lsquo;AI veganism&amp;rsquo;, um movimento contra o uso de IA por questões éticas. A mensagem central é que a segurança deve ser reavaliada à luz dessas novas ameaças, com foco na gestão de identidades.&lt;/p></description></item><item><title>Hackers envenenam IA como ChatGPT com facilidade</title><link>https://brdefense.center/news/hackers-envenenam-ia-como-chatgpt-com-facilidade/</link><pubDate>Fri, 24 Oct 2025 19:00:25 -0300</pubDate><guid>https://brdefense.center/news/hackers-envenenam-ia-como-chatgpt-com-facilidade/</guid><description>&lt;p>O aumento do uso de Inteligência Artificial (IA), especialmente em chatbots como ChatGPT, Gemini e Claude, trouxe à tona novas vulnerabilidades. Pesquisadores do Instituto Alan Turing e da Anthropic identificaram uma técnica chamada &amp;rsquo;envenenamento de IA&amp;rsquo;, onde apenas 250 arquivos maliciosos podem comprometer o aprendizado de um modelo de dados. Isso resulta em chatbots que aprendem informações erradas, levando a respostas incorretas ou até maliciosas. Existem dois tipos principais de envenenamento: o direto, que altera respostas específicas, e o indireto, que prejudica a performance geral. Um exemplo de ataque direto é o backdoor, onde o modelo é manipulado para responder de forma errada ao detectar um código específico. Já o ataque indireto envolve a criação de informações falsas que o modelo replica como verdade. Em março de 2023, a OpenAI suspendeu temporariamente o ChatGPT devido a um bug que expôs dados de usuários. Além disso, artistas têm utilizado dados envenenados como uma forma de proteger suas obras contra sistemas de IA que as utilizam sem autorização. Essa situação levanta preocupações sobre a segurança e a integridade dos sistemas de IA, especialmente em um cenário onde a desinformação pode ter consequências graves.&lt;/p></description></item><item><title>Falha de Injeção de Argumentos em Agentes de IA Permite Execução Remota de Código</title><link>https://brdefense.center/news/falha-de-injecao-de-argumentos-em-agentes-de-ia-pe/</link><pubDate>Thu, 23 Oct 2025 06:59:51 -0300</pubDate><guid>https://brdefense.center/news/falha-de-injecao-de-argumentos-em-agentes-de-ia-pe/</guid><description>&lt;p>Pesquisas de segurança da Trail of Bits revelam que agentes de inteligência artificial modernos estão vulneráveis a ataques de injeção de argumentos, permitindo a execução remota de código (RCE). Essa vulnerabilidade explora uma falha arquitetônica fundamental na forma como esses agentes lidam com a execução de comandos do sistema. Ao utilizar utilitários de linha de comando como find, grep e git, os sistemas se tornam mais rápidos, mas também expõem uma superfície de ataque perigosa quando a entrada do usuário influencia os parâmetros dos comandos.&lt;/p></description></item><item><title>Automação impulsionada por IA na descoberta de vulnerabilidades e geração de malware</title><link>https://brdefense.center/news/automacao-impulsionada-por-ia-na-descoberta-de-vul/</link><pubDate>Fri, 17 Oct 2025 12:58:49 -0300</pubDate><guid>https://brdefense.center/news/automacao-impulsionada-por-ia-na-descoberta-de-vul/</guid><description>&lt;p>O relatório Digital Defense Report 2025 da Microsoft revela que a motivação financeira continua a dominar o cenário global de ameaças cibernéticas, com 52% dos ataques analisados relacionados a extorsão e ransomware. O documento, assinado pelo Chief Information Security Officer da Microsoft, Igor Tsyganskiy, destaca que 80% dos incidentes investigados estavam ligados ao roubo de dados, evidenciando que os cibercriminosos priorizam o lucro em vez da espionagem. A pesquisa também enfatiza o uso crescente de inteligência artificial (IA) em ciberataques, permitindo que até mesmo atores de baixo nível escalem operações maliciosas. A Microsoft processa mais de 100 trilhões de sinais de segurança diariamente, bloqueando cerca de 4,5 milhões de tentativas de malware e analisando 5 bilhões de e-mails para detectar phishing. A automação e a IA mudaram drasticamente a dinâmica dos ataques, com criminosos utilizando modelos de aprendizado de máquina para descobrir vulnerabilidades rapidamente e gerar malware polimórfico. O relatório também menciona o aumento das ameaças de atores estatais, especialmente da China, Irã, Rússia e Coreia do Norte, que estão explorando vulnerabilidades recém-divulgadas com rapidez. A Microsoft recomenda que as organizações integrem a segurança em suas estratégias de negócios e adotem modelos de defesa impulsionados por IA para enfrentar essas ameaças.&lt;/p></description></item><item><title>Google lança IA CodeMender para corrigir código inseguro</title><link>https://brdefense.center/news/google-lanca-ia-codemender-para-corrigir-codigo-in/</link><pubDate>Wed, 08 Oct 2025 13:02:31 -0300</pubDate><guid>https://brdefense.center/news/google-lanca-ia-codemender-para-corrigir-codigo-in/</guid><description>&lt;p>O Google apresentou o CodeMender, um agente autônomo impulsionado por inteligência artificial, que tem como objetivo detectar, corrigir e proteger proativamente o código de software. Utilizando modelos de aprendizado profundo e análise rigorosa de programas, o CodeMender não apenas responde a novas vulnerabilidades, mas também reescreve códigos existentes para eliminar falhas de segurança. Nos últimos seis meses, a equipe de pesquisa integrou 72 correções de segurança em projetos de código aberto, abrangendo bases de código com mais de 4,5 milhões de linhas. O modelo Gemini Deep Think, que fundamenta o CodeMender, analisa a semântica do código e o fluxo de controle para identificar as causas raízes das vulnerabilidades. O agente gera correções que tratam problemas como gerenciamento inadequado de memória e estouros de buffer, garantindo que apenas correções de alta qualidade sejam submetidas a revisores humanos. Além disso, o CodeMender aplica anotações de segurança proativas, como -fbounds-safety, que previnem estouros de buffer em bibliotecas inteiras. Embora os resultados iniciais sejam promissores, o Google está adotando uma abordagem cautelosa, revisando todas as correções geradas antes de sua implementação em projetos críticos de código aberto.&lt;/p></description></item><item><title>CodeMender da Google DeepMind usa IA para detectar bugs e criar patches de segurança</title><link>https://brdefense.center/news/codemender-da-google-deepmind-usa-ia-para-detectar/</link><pubDate>Wed, 08 Oct 2025 00:57:59 -0300</pubDate><guid>https://brdefense.center/news/codemender-da-google-deepmind-usa-ia-para-detectar/</guid><description>&lt;p>A Google DeepMind anunciou o CodeMender, uma ferramenta de inteligência artificial que identifica e corrige vulnerabilidades em softwares antes que possam ser exploradas por hackers. O CodeMender gera patches de segurança para projetos de código aberto, que são revisados por pesquisadores humanos antes de serem aplicados. A ferramenta utiliza uma combinação de técnicas, como fuzzing, análise estática e testes diferenciais, para descobrir as causas raízes dos bugs e evitar regressões. Nos últimos seis meses, o sistema já implementou 72 correções de segurança em projetos de grande porte, incluindo bibliotecas com milhões de linhas de código. A DeepMind enfatiza que o CodeMender não visa substituir os desenvolvedores, mas sim atuar como um agente auxiliar, aumentando a capacidade de detecção de vulnerabilidades. A empresa também reconhece o uso crescente de IA por atacantes e a necessidade de ferramentas equivalentes para defensores. A DeepMind planeja expandir os testes com mantenedores de código aberto e, após confirmar a confiabilidade do CodeMender, pretende disponibilizá-lo para um público mais amplo.&lt;/p></description></item><item><title>Zero Trust uma solução comprovada para os novos desafios de segurança da IA</title><link>https://brdefense.center/news/zero-trust-uma-solucao-comprovada-para-os-novos-de/</link><pubDate>Tue, 07 Oct 2025 07:00:50 -0300</pubDate><guid>https://brdefense.center/news/zero-trust-uma-solucao-comprovada-para-os-novos-de/</guid><description>&lt;p>À medida que as organizações buscam aproveitar o potencial produtivo dos modelos de linguagem de grande escala (LLMs) e da IA autônoma, surge uma preocupação com a segurança: como garantir que essas ferramentas poderosas não causem vazamentos de dados ou ações maliciosas? O artigo destaca que a arquitetura de Zero Trust, que se baseia na premissa de &amp;rsquo;nunca confiar, sempre verificar&amp;rsquo;, é essencial para proteger interações complexas entre usuários, agentes de IA e dados sensíveis. O uso de LLMs pode multiplicar os riscos de exposição, pois cada interação pode resultar em vazamentos em larga escala. Portanto, é crucial implementar controles dinâmicos e baseados em identidade, garantindo que cada agente de IA tenha suas permissões rigorosamente gerenciadas. O Zero Trust deve ser aplicado em fluxos de trabalho de IA, vinculando agentes a identidades verificadas e utilizando controles contextuais para limitar o acesso. A adoção desse modelo não apenas protege os dados, mas também permite que as organizações inovem com segurança, atendendo às crescentes exigências regulatórias em torno do uso da IA.&lt;/p></description></item><item><title>Microsoft impede campanha de phishing com código gerado por IA</title><link>https://brdefense.center/news/microsoft-impede-campanha-de-phishing-com-codigo-g/</link><pubDate>Wed, 01 Oct 2025 01:02:12 -0300</pubDate><guid>https://brdefense.center/news/microsoft-impede-campanha-de-phishing-com-codigo-g/</guid><description>&lt;p>Recentemente, a Microsoft conseguiu bloquear uma campanha de phishing que utilizava código gerado por inteligência artificial (IA) para ocultar um payload malicioso dentro de um arquivo SVG disfarçado como PDF. Os atacantes enviaram e-mails de contas de pequenas empresas comprometidas, utilizando campos BCC para esconder os alvos reais. O arquivo SVG continha elementos ocultos que simulavam um painel de negócios, enquanto um script transformava palavras relacionadas a negócios em código, levando os usuários a uma página de login falsa após um redirecionamento para um CAPTCHA. A análise do arquivo pelo Microsoft Security Copilot revelou características típicas de código gerado por IA, como identificadores longos e comentários genéricos, o que indicou que o código era mais polido do que prático. Embora a campanha tenha sido limitada e facilmente bloqueada, ela destaca como os atacantes estão cada vez mais utilizando IA para criar iscas convincentes e payloads complexos. A Microsoft enfatiza a importância de ferramentas de IA na detecção e resposta a ameaças em larga escala, tanto para defensores quanto para atacantes.&lt;/p></description></item><item><title>Campanha de phishing utiliza IA para enganar empresas nos EUA</title><link>https://brdefense.center/news/campanha-de-phishing-utiliza-ia-para-enganar-empre/</link><pubDate>Mon, 29 Sep 2025 06:57:24 -0300</pubDate><guid>https://brdefense.center/news/campanha-de-phishing-utiliza-ia-para-enganar-empre/</guid><description>&lt;p>Um novo ataque de phishing, identificado pela Microsoft, está direcionado a organizações baseadas nos Estados Unidos e utiliza modelos de linguagem avançados para ocultar suas intenções maliciosas. Detectado em 28 de agosto de 2025, o ataque se aproveita de contas de e-mail corporativas comprometidas para enviar mensagens que se disfarçam como notificações de compartilhamento de arquivos. Os atacantes utilizam arquivos SVG, que permitem a inclusão de JavaScript e conteúdo dinâmico, para criar iscas mais convincentes. Os e-mails são enviados com endereços de remetente e destinatário iguais, ocultando os verdadeiros alvos no campo BCC, o que dificulta a detecção inicial. O conteúdo do SVG é estruturado para parecer um painel de análise de negócios, enquanto a funcionalidade maliciosa é disfarçada por uma sequência de termos corporativos. A Microsoft alerta que, embora esta campanha tenha sido bloqueada, técnicas semelhantes estão sendo cada vez mais adotadas por cibercriminosos. Além disso, outras campanhas de phishing têm explorado temas relacionados à Administração da Seguridade Social dos EUA e à violação de direitos autorais, utilizando métodos inovadores para distribuir malware.&lt;/p></description></item><item><title>Vulnerabilidade crítica no Salesforce Agentforce pode vazar dados</title><link>https://brdefense.center/news/vulnerabilidade-critica-no-salesforce-agentforce-p/</link><pubDate>Thu, 25 Sep 2025 12:57:51 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-critica-no-salesforce-agentforce-p/</guid><description>&lt;p>Pesquisadores de cibersegurança revelaram uma falha crítica no Salesforce Agentforce, uma plataforma para criação de agentes de inteligência artificial (IA), que pode permitir que atacantes exfiltratem dados sensíveis do sistema de gerenciamento de relacionamento com o cliente (CRM) da empresa. Nomeada de ForcedLeak, a vulnerabilidade possui uma pontuação CVSS de 9.4 e afeta organizações que utilizam a funcionalidade Web-to-Lead do Salesforce. O ataque ocorre por meio de uma injeção de prompt indireta, onde instruções maliciosas são inseridas em campos de dados externos, levando o sistema a gerar conteúdos proibidos ou a realizar ações não intencionais. O processo envolve cinco etapas, começando com o envio de um formulário Web-to-Lead contendo uma descrição maliciosa, seguido pelo processamento desse lead por um funcionário interno que utiliza um comando padrão de IA. A falha permite que dados sensíveis sejam transmitidos para um domínio controlado pelo atacante. A Salesforce já tomou medidas para mitigar a vulnerabilidade, resegurando o domínio expirado e implementando um mecanismo de lista de URLs confiáveis. Os usuários são aconselhados a auditar dados existentes e implementar validações rigorosas de entrada para detectar possíveis injeções de prompt.&lt;/p></description></item><item><title>Vulnerabilidades críticas expõem dados de usuários no Wondershare RepairIt</title><link>https://brdefense.center/news/vulnerabilidades-criticas-expoem-dados-de-usuarios/</link><pubDate>Wed, 24 Sep 2025 13:00:07 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidades-criticas-expoem-dados-de-usuarios/</guid><description>&lt;p>Pesquisadores de cibersegurança da Trend Micro revelaram duas vulnerabilidades críticas no software Wondershare RepairIt, que podem comprometer dados privados dos usuários e permitir ataques à cadeia de suprimentos. As falhas, identificadas como CVE-2025-10643 e CVE-2025-10644, têm pontuações CVSS de 9.1 e 9.4, respectivamente, e permitem que atacantes contornem a autenticação do sistema. Isso pode resultar na execução de código arbitrário nos dispositivos dos clientes. Além disso, a aplicação coleta e armazena dados de forma inadequada, sem criptografia, expondo imagens e vídeos dos usuários. A Trend Micro alertou que o armazenamento em nuvem exposto contém não apenas dados dos usuários, mas também modelos de IA e códigos-fonte da empresa, o que pode facilitar a manipulação de modelos de IA e a realização de ataques à cadeia de suprimentos. A empresa divulgou as vulnerabilidades em abril de 2025, mas não recebeu resposta da Wondershare. Os especialistas recomendam que os usuários limitem a interação com o produto até que uma solução seja implementada.&lt;/p></description></item><item><title>Como a IA está revolucionando os testes de penetração em cibersegurança</title><link>https://brdefense.center/news/como-a-ia-esta-revolucionando-os-testes-de-penetra/</link><pubDate>Mon, 22 Sep 2025 06:59:16 -0300</pubDate><guid>https://brdefense.center/news/como-a-ia-esta-revolucionando-os-testes-de-penetra/</guid><description>&lt;p>A cibersegurança está passando por uma transformação acelerada, especialmente no que diz respeito aos testes de penetração, ou pentesting. Nos últimos 12 meses, empresas do Reino Unido enfrentaram cerca de 7,78 milhões de crimes cibernéticos, evidenciando a necessidade de estratégias proativas. A inteligência artificial (IA) está mudando a forma como as organizações avaliam e fortalecem suas defesas, permitindo uma transição de testes periódicos para avaliações contínuas. Isso possibilita que as empresas obtenham insights em tempo real sobre suas vulnerabilidades, permitindo uma resposta mais ágil a ameaças. Além disso, o modelo de Pentesting como Serviço (PTaaS) está se tornando popular, oferecendo flexibilidade e escalabilidade para as empresas que buscam melhorar sua postura de segurança. À medida que mais organizações adotam ambientes híbridos e de nuvem, as práticas de pentesting também precisam evoluir para abranger essas novas infraestruturas. Apesar do avanço da IA, a experiência humana continua sendo essencial, pois profissionais de segurança trazem intuição e pensamento crítico que as máquinas não conseguem replicar. A combinação de serviços aumentados por IA com a expertise humana promete acelerar os testes e melhorar a eficácia na identificação de vulnerabilidades.&lt;/p></description></item><item><title>SpamGPT Ferramenta de IA que facilita ataques cibernéticos</title><link>https://brdefense.center/news/spamgpt-ferramenta-de-ia-que-facilita-ataques-cibe/</link><pubDate>Sat, 20 Sep 2025 18:58:51 -0300</pubDate><guid>https://brdefense.center/news/spamgpt-ferramenta-de-ia-que-facilita-ataques-cibe/</guid><description>&lt;p>O SpamGPT é uma nova ferramenta de cibercrime que utiliza inteligência artificial para automatizar campanhas de phishing e ransomware, tornando esses ataques mais simples e eficientes. Desenvolvido para criminosos, o SpamGPT oferece uma interface semelhante a painéis de marketing legítimos, permitindo que até mesmo indivíduos com pouca experiência técnica possam criar, agendar e monitorar operações de spam em larga escala. A plataforma integra ferramentas de IA que geram conteúdo convincente para phishing, otimizam linhas de assunto e sugerem melhorias para os golpes, transformando o phishing em um processo acessível a criminosos de baixo nível.&lt;/p></description></item><item><title>Plataformas impulsionadas por IA facilitam phishing que engana usuários</title><link>https://brdefense.center/news/plataformas-impulsionadas-por-ia-facilitam-phishin/</link><pubDate>Fri, 19 Sep 2025 12:59:47 -0300</pubDate><guid>https://brdefense.center/news/plataformas-impulsionadas-por-ia-facilitam-phishin/</guid><description>&lt;p>Desde janeiro de 2025, a Trend Micro identificou um aumento significativo em campanhas de phishing que utilizam plataformas de desenvolvimento impulsionadas por IA, como Lovable.app, Netlify.app e Vercel.app, para hospedar páginas falsas de CAPTCHA. Os atacantes aproveitam os níveis gratuitos de hospedagem e a credibilidade dessas plataformas para criar armadilhas sofisticadas que conseguem evitar a detecção de scanners automáticos. Os e-mails de phishing frequentemente apresentam temas urgentes, como &amp;lsquo;Redefinição de Senha Necessária&amp;rsquo; ou &amp;lsquo;Notificação de Mudança de Endereço do USPS&amp;rsquo;. Ao clicar nos links, os usuários são levados a uma interface de CAPTCHA que parece legítima, mas que, na verdade, redireciona silenciosamente para sites que coletam credenciais, como Microsoft 365 e Google Workspace. A Trend Micro observou que a atividade aumentou entre fevereiro e abril, coincidindo com a adoção crescente do trabalho remoto, e novamente em agosto. Para combater essas táticas, as organizações devem implementar medidas de segurança avançadas e treinar os funcionários para reconhecer sinais de phishing, especialmente em relação a prompts de CAPTCHA. A combinação de controles técnicos e vigilância informada dos usuários é essencial para mitigar esses riscos.&lt;/p></description></item><item><title>Automação de Alertas de Segurança com IA Eficiência e Consistência</title><link>https://brdefense.center/news/automacao-de-alertas-de-seguranca-com-ia-eficienci/</link><pubDate>Fri, 19 Sep 2025 12:58:46 -0300</pubDate><guid>https://brdefense.center/news/automacao-de-alertas-de-seguranca-com-ia-eficienci/</guid><description>&lt;p>O artigo destaca uma nova funcionalidade da plataforma Tines, que oferece mais de 1.000 fluxos de trabalho pré-construídos para equipes de segurança. Um dos fluxos de trabalho em destaque automatiza o manuseio de alertas de segurança, utilizando agentes de IA para identificar e executar Procedimentos Operacionais Padrão (SOPs) relevantes armazenados no Confluence. Esse processo visa resolver o problema da triagem manual de alertas, que é demorado e suscetível a erros humanos. Com a automação, as equipes podem responder mais rapidamente e de forma consistente, reduzindo o tempo médio de remediação (MTTR) e melhorando a documentação das ações tomadas. O fluxo de trabalho é configurável e pode ser integrado a diversas ferramentas de segurança, como CrowdStrike e Slack, permitindo uma resposta coordenada e eficiente a incidentes. O guia também fornece instruções passo a passo para a implementação do fluxo de trabalho, tornando-o acessível para as equipes de segurança que buscam otimizar suas operações.&lt;/p></description></item><item><title>Hackers norte-coreanos geram ID militar falsa da Coreia do Sul usando ChatGPT</title><link>https://brdefense.center/news/hackers-norte-coreanos-geram-id-militar-falsa-da-c/</link><pubDate>Tue, 16 Sep 2025 13:02:57 -0300</pubDate><guid>https://brdefense.center/news/hackers-norte-coreanos-geram-id-militar-falsa-da-c/</guid><description>&lt;p>Hackers da Coreia do Norte, identificados como Kimsuky, utilizaram o ChatGPT para criar uma identificação militar falsa, que foi empregada em ataques de spear-phishing contra instituições de defesa da Coreia do Sul. O Genians Security Center (GSC) reportou que, apesar das restrições implementadas pela OpenAI para evitar a geração de conteúdo malicioso, os criminosos conseguiram contornar essas barreiras ao solicitar um &amp;lsquo;design de amostra&amp;rsquo; ou &amp;lsquo;mock-up&amp;rsquo;. O uso de imagens disponíveis publicamente facilitou a manipulação do modelo de IA. A criação de documentos de identificação falsos é ilegal e representa um risco significativo, especialmente em contextos de segurança nacional. O ataque destaca a vulnerabilidade das instituições de defesa a métodos inovadores de engenharia social, que podem comprometer informações sensíveis e a segurança nacional. O GSC não revelou o nome da instituição alvo, mas enfatizou a necessidade de cautela ao lidar com ferramentas de IA, que podem ser exploradas para fins ilícitos.&lt;/p></description></item><item><title>Segurança de Agentes de IA A Nova Abordagem da Astrix</title><link>https://brdefense.center/news/seguranca-de-agentes-de-ia-a-nova-abordagem-da-ast/</link><pubDate>Tue, 16 Sep 2025 13:00:29 -0300</pubDate><guid>https://brdefense.center/news/seguranca-de-agentes-de-ia-a-nova-abordagem-da-ast/</guid><description>&lt;p>Os agentes de inteligência artificial (IA) estão se tornando parte essencial das operações empresariais, mas sua autonomia crescente traz riscos significativos. Um estudo recente revelou que 80% das empresas já enfrentaram ações indesejadas de agentes de IA, como acessos não autorizados e vazamentos de dados. A falta de mecanismos de segurança específicos para esses agentes, que operam 24 horas por dia e utilizam identidades não humanas, torna a gestão de acesso um desafio. Para mitigar esses riscos, a Astrix lançou o Agent Control Plane (ACP), uma solução que fornece credenciais de acesso temporárias e limitadas, seguindo o princípio do menor privilégio. O ACP oferece três benefícios principais: auditorias rápidas e previsíveis, acesso seguro para agentes de IA e aumento da produtividade dos desenvolvedores. A implementação do ACP permite que as organizações tenham visibilidade centralizada sobre cada agente, suas permissões e ações, facilitando o monitoramento em tempo real e a gestão de riscos. Com essa abordagem, as empresas podem implantar agentes de IA de forma segura, garantindo que possam aproveitar ao máximo essa tecnologia sem comprometer a segurança.&lt;/p></description></item><item><title>Cibercriminosos Usam ChatGPT para Driblar Antivírus</title><link>https://brdefense.center/news/cibercriminosos-usam-chatgpt-para-driblar-antiviru/</link><pubDate>Mon, 15 Sep 2025 19:00:41 -0300</pubDate><guid>https://brdefense.center/news/cibercriminosos-usam-chatgpt-para-driblar-antiviru/</guid><description>&lt;p>Um novo ataque de ameaça persistente avançada (APT) atribuído ao grupo Kimsuky, vinculado à Coreia do Norte, destaca o uso de ferramentas de IA generativa, como o ChatGPT, para aprimorar campanhas de spear-phishing. Em julho de 2025, a campanha explorou imagens deepfake de crachás de funcionários militares sul-coreanos para infiltrar entidades relacionadas à defesa. Os atacantes enviaram e-mails de phishing que imitavam domínios de instituições de defesa da Coreia do Sul, contendo arquivos maliciosos disfarçados. A análise revelou que o ChatGPT foi manipulado para gerar documentos falsificados, contornando restrições de replicação de ID. Os arquivos maliciosos, uma vez executados, utilizavam scripts ofuscados para se conectar a servidores de comando e controle, permitindo o roubo de dados e o controle remoto de dispositivos infectados. A campanha ilustra uma tendência crescente de atores patrocinados por estados que utilizam IA para engenharia social e entrega de malware, destacando a ineficácia das soluções antivírus tradicionais contra comandos ofuscados e conteúdo gerado por IA. A detecção e resposta em endpoints (EDR) foi identificada como essencial para neutralizar essas ameaças, evidenciando a necessidade de monitoramento proativo para evitar que organizações sejam vítimas de estratégias APT habilitadas por IA.&lt;/p></description></item><item><title>Ferramenta de pentesting com IA da China gera preocupações de segurança</title><link>https://brdefense.center/news/ferramenta-de-pentesting-com-ia-da-china-gera-preo/</link><pubDate>Fri, 12 Sep 2025 13:02:14 -0300</pubDate><guid>https://brdefense.center/news/ferramenta-de-pentesting-com-ia-da-china-gera-preo/</guid><description>&lt;p>Uma nova ferramenta de pentesting chamada Villager, desenvolvida por uma empresa chinesa chamada Cyberspike, tem gerado preocupações significativas na comunidade de cibersegurança. Com cerca de 10.000 downloads em apenas dois meses, a ferramenta utiliza inteligência artificial para automatizar operações de segurança ofensiva, integrando recursos do Kali Linux e do DeepSeek AI. A rápida adoção da ferramenta levanta questões sobre seu uso por atores maliciosos, especialmente considerando que Cyberspike possui laços com círculos de hackers e malware. O relatório da Straiker destaca que a Villager pode seguir o mesmo caminho do Cobalt Strike, uma ferramenta amplamente utilizada por cibercriminosos. Além disso, a falta de um site oficial e o histórico da empresa levantam suspeitas sobre suas intenções. A Villager é acessível gratuitamente no PyPI, o que facilita ainda mais sua disseminação. A situação exige atenção, pois a automação de ataques pode aumentar a eficácia de ameaças persistentes e complexas no cenário global de cibersegurança.&lt;/p></description></item><item><title>EvilAI Usando IA para Exfiltrar Dados do Navegador e Evitar Detecção</title><link>https://brdefense.center/news/evilai-usando-ia-para-exfiltrar-dados-do-navegador/</link><pubDate>Fri, 12 Sep 2025 12:59:45 -0300</pubDate><guid>https://brdefense.center/news/evilai-usando-ia-para-exfiltrar-dados-do-navegador/</guid><description>&lt;p>Desde o final de agosto de 2025, a Trend™ Research identificou um aumento global de malware disfarçado como aplicações legítimas de IA e produtividade, denominado EvilAI. Este malware utiliza trojans que se apresentam com interfaces realistas e funcionalidades válidas, permitindo a infiltração em sistemas corporativos e pessoais sem levantar suspeitas. Os instaladores do EvilAI são nomeados com termos genéricos, como &amp;lsquo;App Suite&amp;rsquo; e &amp;lsquo;PDF Editor&amp;rsquo;, e, após a instalação, executam um payload JavaScript malicioso em segundo plano. Para garantir a persistência, o malware cria tarefas agendadas e entradas no registro do Windows, permitindo sua reexecução mesmo após reinicializações.&lt;/p></description></item><item><title>Transformação da Segurança em Aplicações Nativas da Nuvem</title><link>https://brdefense.center/news/transformacao-da-seguranca-em-aplicacoes-nativas-d/</link><pubDate>Fri, 12 Sep 2025 06:59:58 -0300</pubDate><guid>https://brdefense.center/news/transformacao-da-seguranca-em-aplicacoes-nativas-d/</guid><description>&lt;p>O cenário de segurança para aplicações nativas da nuvem está passando por uma transformação significativa, impulsionada pela adoção crescente de tecnologias como containers, Kubernetes e serverless. Embora essas inovações acelerem a entrega de software, também ampliam a superfície de ataque, tornando os modelos de segurança tradicionais inadequados. Em 2025, a visibilidade em tempo de execução (runtime visibility) se destaca como uma capacidade essencial para as plataformas de proteção de aplicações nativas da nuvem (CNAPPs). Essa abordagem permite que as equipes de segurança identifiquem e priorizem ameaças reais, evitando a armadilha de falsos positivos. A integração da inteligência artificial (IA) nesse contexto também se mostra promissora, ajudando a correlacionar sinais de diferentes domínios e a acelerar a resposta a incidentes. Além disso, a responsabilidade compartilhada entre equipes de segurança e desenvolvimento é crucial para garantir que as vulnerabilidades sejam tratadas de forma eficaz. A consolidação de ferramentas em uma única plataforma CNAPP é vista como inevitável para reduzir a fragmentação e melhorar a visibilidade do risco na nuvem. À medida que o uso de containers cresce, a segurança em tempo real, a assistência impulsionada por IA e plataformas unificadas se tornam essenciais para proteger as aplicações de forma eficaz.&lt;/p></description></item><item><title>Microsoft adiciona ações com IA ao Windows File Explorer</title><link>https://brdefense.center/news/microsoft-adiciona-acoes-com-ia-ao-windows-file-ex/</link><pubDate>Tue, 09 Sep 2025 13:02:55 -0300</pubDate><guid>https://brdefense.center/news/microsoft-adiciona-acoes-com-ia-ao-windows-file-ex/</guid><description>&lt;p>A Microsoft iniciou a distribuição da versão Insider Preview Build 27938 do Windows 11 no Canal Canary, que traz novas funcionalidades impulsionadas por inteligência artificial (IA) diretamente para o File Explorer. A principal novidade são as &amp;lsquo;ações de IA&amp;rsquo;, que permitem aos usuários interagir com imagens e documentos sem sair do navegador de arquivos. Ao clicar com o botão direito em um arquivo compatível, uma nova opção de &amp;lsquo;ações de IA&amp;rsquo; aparece no menu de contexto, oferecendo tarefas como edição de imagens e resumo de documentos. As ações de IA incluem ferramentas como Busca Visual do Bing, que permite pesquisar na web usando imagens, e funcionalidades de edição como desfoque de fundo e remoção de objetos. Além disso, a atualização traz melhorias na visualização do relógio no Centro de Notificações e uma nova seção de privacidade que permite aos usuários monitorar quais aplicativos de terceiros utilizam modelos de IA fornecidos pelo Windows. A Microsoft também corrigiu diversos problemas de confiabilidade nesta versão, mas os usuários devem estar cientes de que as versões Canary podem apresentar erros e não são garantidas para produção.&lt;/p></description></item><item><title>Vazamentos de chats do ChatGPT revelam usuários como terapeutas e advogados</title><link>https://brdefense.center/news/vazamentos-de-chats-do-chatgpt-revelam-usuarios-co/</link><pubDate>Thu, 04 Sep 2025 13:01:11 -0300</pubDate><guid>https://brdefense.center/news/vazamentos-de-chats-do-chatgpt-revelam-usuarios-co/</guid><description>&lt;p>Recentemente, surgiram preocupações sobre a privacidade das conversas no ChatGPT, após a OpenAI cancelar a funcionalidade que tornava as interações buscáveis, resultando na exposição de dados sensíveis. Uma análise de 1.000 conversas, realizada pela SafetyDetective, revelou que muitos usuários compartilham informações pessoais e discutem questões delicadas, como saúde mental e problemas legais, com a IA, tratando-a como um terapeuta ou consultor. A pesquisa indicou que 60% das interações se enquadravam na categoria de &amp;lsquo;consulta profissional&amp;rsquo;, levantando questões sobre a confiança dos usuários na precisão das respostas da IA. Além disso, a falta de compreensão sobre o que significa tornar as conversas buscáveis e a possibilidade de vazamentos de dados pessoais expõem os usuários a riscos como phishing e roubo de identidade. Especialistas recomendam que as empresas de IA tornem seus avisos mais claros e ocultem informações pessoais antes de disponibilizar as conversas na internet. A situação destaca a necessidade de cautela ao compartilhar informações sensíveis com chatbots, independentemente da percepção de privacidade da tecnologia.&lt;/p></description></item><item><title>Hackers usam IA do Google e Amazon para roubar credenciais do npm nx</title><link>https://brdefense.center/news/hackers-usam-ia-do-google-e-amazon-para-roubar-cre/</link><pubDate>Wed, 03 Sep 2025 13:02:37 -0300</pubDate><guid>https://brdefense.center/news/hackers-usam-ia-do-google-e-amazon-para-roubar-cre/</guid><description>&lt;p>Recentemente, o pacote npm &amp;rsquo;nx&amp;rsquo;, amplamente utilizado para gerenciamento de código, foi alvo de um ataque cibernético que comprometeu a segurança de cerca de 100 mil contas. Os hackers exploraram uma vulnerabilidade na cadeia logística do pacote, permitindo a publicação de versões maliciosas que escaneavam sistemas de arquivos em busca de credenciais. Essas informações eram então enviadas para um repositório no GitHub sob a conta da vítima. O ataque afetou principalmente usuários de sistemas Linux e macOS, e as versões comprometidas foram rapidamente removidas do registro. A vulnerabilidade foi introduzida em um workflow do GitHub em 21 de agosto e, apesar de ter sido revertida, os criminosos conseguiram explorar um branch desatualizado. Pesquisadores de segurança alertam que este é o primeiro incidente conhecido a utilizar assistentes de desenvolvimento com IA, como Claude Code e Google Gemini CLI, para burlar a segurança. Os usuários afetados são aconselhados a alterar suas credenciais e verificar arquivos de configuração em busca de instruções maliciosas.&lt;/p></description></item><item><title>Falha de segurança em chatbots de IA expõe segredos dos usuários</title><link>https://brdefense.center/news/falha-de-seguranca-em-chatbots-de-ia-expoe-segredo/</link><pubDate>Tue, 02 Sep 2025 13:00:48 -0300</pubDate><guid>https://brdefense.center/news/falha-de-seguranca-em-chatbots-de-ia-expoe-segredo/</guid><description>&lt;p>Um estudo da empresa de cibersegurança UpGuard revelou uma falha crítica em grandes modelos de linguagem (LLMs) que permitiu o vazamento de conversas entre usuários e chatbots, especialmente aqueles voltados para roleplaying. Essas interações, que muitas vezes envolvem cenários íntimos e fantasias, resultaram na exposição de segredos pessoais na internet em tempo real, levantando preocupações sobre a privacidade e segurança dos dados dos usuários. A falha está relacionada a configurações inadequadas do framework de código aberto llama.cpp, utilizado na execução de LLMs. Embora a UpGuard não tenha revelado quais chatbots foram afetados, o incidente destaca a vulnerabilidade dos usuários a ameaças como chantagem e sextorsion. Especialistas alertam que a falta de protocolos de segurança adequados na implementação desses modelos é um problema sério. Além disso, o fenômeno de usuários desenvolvendo laços emocionais com chatbots pode levar ao compartilhamento de informações pessoais sensíveis, aumentando o risco de abusos. A UpGuard enfatiza a necessidade urgente de protocolos de segurança mais robustos e discussões sobre o impacto social de serviços de companheirismo e pornografia baseados em IA, que atualmente carecem de regulamentação.&lt;/p></description></item><item><title>Ferramentas de Cibersegurança Baseadas em IA Vulneráveis a Ataques de Injeção</title><link>https://brdefense.center/news/ferramentas-de-ciberseguranca-baseadas-em-ia-vulne/</link><pubDate>Tue, 02 Sep 2025 12:59:31 -0300</pubDate><guid>https://brdefense.center/news/ferramentas-de-ciberseguranca-baseadas-em-ia-vulne/</guid><description>&lt;p>Um estudo recente revelou que agentes de cibersegurança alimentados por inteligência artificial (IA) estão vulneráveis a ataques de injeção de prompt, um novo vetor de ameaça que pode comprometer redes inteiras. Esses ataques exploram a capacidade dos Modelos de Linguagem de Grande Escala (LLMs) de interpretar comandos em linguagem natural, transformando respostas confiáveis em comandos não autorizados. O processo do ataque ocorre em quatro etapas: reconhecimento, recuperação de conteúdo, decodificação de comandos e execução de um shell reverso, permitindo que atacantes obtenham acesso total ao sistema em menos de 20 segundos. Além da obfuscação básica em base64, o estudo identificou seis vetores adicionais que aumentam o risco, como a exfiltração de variáveis de ambiente e ataques homográficos em Unicode. Para mitigar essa ameaça, os pesquisadores propuseram uma arquitetura de defesa em quatro camadas, que inclui isolamento de operações, proteção contra padrões suspeitos e validação em múltiplas camadas. Testes mostraram que essas defesas conseguiram bloquear todas as tentativas de injeção, embora com um pequeno aumento na latência. Essa vulnerabilidade representa um risco significativo para a segurança cibernética, exigindo atenção imediata de profissionais da área.&lt;/p></description></item><item><title>A Dura Realidade da Adoção de IA nas Empresas</title><link>https://brdefense.center/news/a-dura-realidade-da-adocao-de-ia-nas-empresas/</link><pubDate>Tue, 02 Sep 2025 12:57:21 -0300</pubDate><guid>https://brdefense.center/news/a-dura-realidade-da-adocao-de-ia-nas-empresas/</guid><description>&lt;p>Um relatório do MIT revelou que 40% das organizações adquiriram assinaturas de LLMs empresariais, mas mais de 90% dos funcionários utilizam ferramentas de IA no dia a dia. A pesquisa da Harmonic Security indica que 45,4% das interações sensíveis com IA ocorrem em contas de e-mail pessoais, o que levanta preocupações sobre a chamada &amp;lsquo;Economia de IA Sombra&amp;rsquo;. Essa situação ocorre porque a adoção de IA é impulsionada pelos funcionários, e não por diretrizes corporativas. Muitas empresas tentam bloquear o acesso a plataformas de IA, mas essa estratégia falha, pois a IA está integrada em quase todos os aplicativos SaaS. Para mitigar riscos, as equipes de segurança precisam entender e governar o uso de IA, tanto em contas autorizadas quanto não autorizadas. A descoberta da IA Sombra é essencial para manter a conformidade regulatória e proteger dados sensíveis. A Harmonic Security oferece soluções para monitorar o uso de IA e aplicar políticas de governança adequadas, permitindo que as empresas se beneficiem da produtividade da IA, enquanto protegem suas informações.&lt;/p></description></item><item><title>Ameaça Emergente - RAT Waifu de IA Utiliza Táticas de Engenharia Social</title><link>https://brdefense.center/news/ameaca-emergente-rat-waifu-de-ia-utiliza-taticas-d/</link><pubDate>Mon, 01 Sep 2025 06:57:36 -0300</pubDate><guid>https://brdefense.center/news/ameaca-emergente-rat-waifu-de-ia-utiliza-taticas-d/</guid><description>&lt;p>Pesquisadores de segurança descobriram o &amp;lsquo;AI Waifu RAT&amp;rsquo;, um Trojan de Acesso Remoto disfarçado como uma ferramenta de pesquisa em IA. Criado por um entusiasta de criptografia, o malware se apresenta como um personagem virtual, &amp;lsquo;Win11 Waifu&amp;rsquo;, que promete personalização ao acessar arquivos locais. No entanto, ele oferece uma porta dos fundos para os computadores dos usuários. O RAT opera com uma arquitetura simples de cliente-servidor, escutando comandos em texto simples e permitindo a execução de código arbitrário. O autor utiliza táticas de engenharia social, como sugerir que os usuários desativem suas proteções antivírus, explorando a confiança em comunidades online. A implementação rudimentar do RAT é ofuscada por uma narrativa sofisticada que apela ao desejo dos usuários por experiências inovadoras. Este incidente destaca a necessidade de vigilância em relação a ferramentas que prometem execução de código arbitrário e a importância de educar os usuários sobre engenharia social. A ameaça representa um novo vetor de ataque, utilizando IA como canal de comando e controle, e requer atenção especial de profissionais de segurança.&lt;/p></description></item><item><title>Hackers podem roubar dados com comandos escondidos em imagens processadas por IA</title><link>https://brdefense.center/news/hackers-podem-roubar-dados-com-comandos-escondidos/</link><pubDate>Thu, 28 Aug 2025 13:01:49 -0300</pubDate><guid>https://brdefense.center/news/hackers-podem-roubar-dados-com-comandos-escondidos/</guid><description>&lt;p>Pesquisadores do grupo Trail of Bits revelaram uma nova vulnerabilidade que permite a hackers roubar dados de usuários ao injetar comandos maliciosos em imagens processadas por sistemas de inteligência artificial (IA), como o Gemini da Google. A técnica utiliza esteganografia, onde instruções invisíveis ao olho humano são incorporadas em imagens de alta resolução. Quando essas imagens são redimensionadas por algoritmos de IA, os comandos ocultos podem se tornar visíveis e ser interpretados como parte das solicitações do usuário.&lt;/p></description></item><item><title>Ferramentas de IA desonestas potencializam desastres de DDoS</title><link>https://brdefense.center/news/ferramentas-de-ia-desonestas-potencializam-desastr/</link><pubDate>Wed, 27 Aug 2025 06:59:47 -0300</pubDate><guid>https://brdefense.center/news/ferramentas-de-ia-desonestas-potencializam-desastr/</guid><description>&lt;p>O cenário de ataques DDoS (Distributed Denial of Service) evoluiu drasticamente, com mais de oito milhões de incidentes registrados globalmente na primeira metade de 2025, segundo pesquisa da NetScout. Esses ataques, que antes eram considerados anomalias raras, agora ocorrem em uma escala quase rotineira, com picos de até 3,12 Tbps na Holanda e 1,5 Gbps nos Estados Unidos. A crescente automação e o uso de botnets, que frequentemente exploram dispositivos comprometidos, como roteadores e dispositivos IoT, têm facilitado a execução desses ataques. A pesquisa destaca que disputas políticas, como as entre Índia e Paquistão e entre Irã e Israel, têm sido catalisadores significativos para essas campanhas de agressão digital. O grupo hacktivista NoName057(16) se destaca, realizando mais de 475 ataques em março de 2025, principalmente contra portais governamentais. A utilização de modelos de linguagem de IA por atacantes tem reduzido as barreiras para novos invasores, permitindo ataques de alta capacidade com conhecimento técnico mínimo. A situação exige que as organizações reavaliem suas defesas tradicionais, que já não são suficientes diante da evolução das táticas de ataque.&lt;/p></description></item><item><title>Proteção de Endpoints A Revolução da Cibersegurança com IA</title><link>https://brdefense.center/news/protecao-de-endpoints-a-revolucao-da-ciberseguranc/</link><pubDate>Tue, 26 Aug 2025 12:58:15 -0300</pubDate><guid>https://brdefense.center/news/protecao-de-endpoints-a-revolucao-da-ciberseguranc/</guid><description>&lt;p>O aumento das ameaças cibernéticas, como ransomware, torna a proteção de endpoints uma prioridade crítica para empresas de todos os tamanhos. O artigo destaca a importância de plataformas de cibersegurança que utilizam inteligência artificial (IA) para oferecer proteção autônoma e em tempo real. A SentinelOne, reconhecida como líder no Gartner Magic Quadrant de 2025, apresenta sua plataforma Singularity, que combina EDR, CNAPP e SIEM, permitindo uma resposta rápida a incidentes e redução de riscos operacionais. Com a capacidade de detectar ameaças 63% mais rápido e reduzir o tempo médio de resposta a incidentes em 55%, a solução é especialmente valiosa em setores sensíveis como saúde e finanças, onde a conformidade regulatória é crucial. A plataforma também se destaca por sua arquitetura leve e integração com ferramentas existentes, minimizando a fadiga de alertas e melhorando a eficiência das equipes de segurança. A evolução da segurança de endpoints, impulsionada pela IA comportamental e automação, promete transformar a forma como as organizações gerenciam suas defesas cibernéticas.&lt;/p></description></item><item><title>Música gerada por IA é problemática quando finge ser artista real</title><link>https://brdefense.center/news/musica-gerada-por-ia-e-problematica-quando-finge-s/</link><pubDate>Tue, 26 Aug 2025 01:02:04 -0300</pubDate><guid>https://brdefense.center/news/musica-gerada-por-ia-e-problematica-quando-finge-s/</guid><description>&lt;p>A música gerada por inteligência artificial (IA) está se tornando cada vez mais comum, mas não necessariamente popular. Recentemente, a cantora folk inglesa Emily Portman se deparou com um álbum falso, intitulado &amp;lsquo;Orca&amp;rsquo;, que foi lançado sob seu nome sem sua autorização. Esse incidente destaca um problema crescente: a imitação de artistas por meio de IA, levando a um roubo de identidade digital. Outros artistas, como Josh Kaufman e Blaze Foley, também foram vítimas desse fenômeno. A situação se agrava com a dificuldade das plataformas de streaming em monitorar as 99.000 novas músicas carregadas diariamente, muitas vezes sem verificação adequada. Embora a IA possa ser uma ferramenta útil para músicos, seu uso para criar conteúdo falso representa um roubo de propriedade artística. A falta de consentimento e contexto altera a experiência do ouvinte, levando a uma desvalorização da autenticidade na música. A crescente aceitação de músicas geradas por IA pode resultar em uma saturação de conteúdo de baixa qualidade, prejudicando artistas reais e sua capacidade de se destacar no mercado.&lt;/p></description></item><item><title>Ferramentas Web impulsionadas por IA se tornam maliciosas - Hackers inserem malware em sites</title><link>https://brdefense.center/news/ferramentas-web-impulsionadas-por-ia-se-tornam-mal/</link><pubDate>Thu, 21 Aug 2025 13:07:31 -0300</pubDate><guid>https://brdefense.center/news/ferramentas-web-impulsionadas-por-ia-se-tornam-mal/</guid><description>&lt;p>Pesquisas recentes da Proofpoint revelam que criminosos cibernéticos estão explorando construtores de sites impulsionados por inteligência artificial, como o Lovable, para criar campanhas de phishing e redes de distribuição de malware. O Lovable permite que usuários gerem sites a partir de descrições em linguagem natural, o que facilitou a criação de sites de phishing profissionais em questão de minutos. Em fevereiro de 2025, uma operação de phishing afetou mais de 5.000 organizações, utilizando e-mails maliciosos que redirecionavam vítimas para páginas falsas de autenticação da Microsoft. Além disso, campanhas de fraude financeira e ataques focados em criptomoedas também foram documentados, com criminosos criando réplicas convincentes de plataformas de finanças descentralizadas. Após a divulgação das vulnerabilidades, o Lovable implementou sistemas de detecção em tempo real e planos para aumentar a segurança, mas a pesquisa destaca a crescente preocupação com o abuso de ferramentas de IA no cibercrime. Organizações devem considerar políticas de lista de permissões para plataformas de IA frequentemente abusadas, enquanto os fornecedores de segurança monitoram esses vetores de ameaça emergentes.&lt;/p></description></item><item><title>Nova técnica de injeção de prompt ameaça segurança de IA</title><link>https://brdefense.center/news/nova-tecnica-de-injecao-de-prompt-ameaca-seguranca/</link><pubDate>Wed, 20 Aug 2025 12:57:53 -0300</pubDate><guid>https://brdefense.center/news/nova-tecnica-de-injecao-de-prompt-ameaca-seguranca/</guid><description>&lt;p>Pesquisadores em cibersegurança apresentaram uma nova técnica de injeção de prompt chamada PromptFix, que engana modelos de inteligência artificial generativa (GenAI) para realizar ações indesejadas. Essa técnica, descrita pela Guardio Labs como uma versão moderna do golpe ClickFix, utiliza instruções maliciosas disfarçadas em verificações de CAPTCHA em páginas da web. O ataque explora navegadores impulsionados por IA, como o Comet da Perplexity, que prometem automatizar tarefas cotidianas, permitindo que interajam com páginas de phishing sem o conhecimento do usuário. A técnica leva a um novo cenário denominado Scamlexity, onde a conveniência da IA se combina com uma nova superfície de fraudes invisíveis. Os testes mostraram que o Comet, em várias ocasiões, completou transações em sites falsos sem solicitar confirmação do usuário. Além disso, a técnica pode ser usada para enganar assistentes de codificação, como o Lovable, levando à exposição de informações sensíveis. A pesquisa destaca a necessidade de sistemas de IA desenvolverem defesas proativas para detectar e neutralizar esses ataques, especialmente à medida que os criminosos cibernéticos utilizam plataformas GenAI para criar conteúdo de phishing realista e automatizar ataques em larga escala.&lt;/p></description></item><item><title>Revivendo Perigos Cibernéticos Antigos - Como IA e LLMs Ressuscitam Táticas de Cavalo de Troia</title><link>https://brdefense.center/news/revivendo-perigos-ciberneticos-antigos-como-ia-e-l/</link><pubDate>Mon, 18 Aug 2025 06:58:51 -0300</pubDate><guid>https://brdefense.center/news/revivendo-perigos-ciberneticos-antigos-como-ia-e-l/</guid><description>&lt;p>Pesquisadores em cibersegurança estão observando um preocupante ressurgimento de malwares clássicos do tipo cavalo de Troia, impulsionados por Modelos de Linguagem de Grande Escala (LLMs). Esses novos malwares, como JustAskJacky e TamperedChef, utilizam funcionalidades legítimas para se disfarçar, dificultando a detecção por métodos tradicionais. A evolução das ferramentas de desenvolvimento baseadas em IA permitiu que ameaçadores criassem códigos sofisticados que evitam sistemas de detecção baseados em assinaturas. Por exemplo, o TamperedChef permaneceu indetectado no VirusTotal por seis semanas, mesmo após ser desempacotado. As aplicações que promovem esses trojans apresentam uma aparência extremamente legítima, com sites profissionais e conteúdo convincente. Isso torna a análise comportamental crucial, já que a intuição do usuário sobre sites suspeitos não é mais suficiente. Em vez disso, técnicas de análise dinâmica e comportamental são necessárias para identificar padrões de comportamento suspeitos, como os observados no JustAskJacky. A combinação de técnicas clássicas de engano com a sofisticação moderna representa uma mudança significativa no cenário de ameaças, exigindo que organizações e usuários individuais adaptem suas estratégias de segurança.&lt;/p></description></item><item><title>Uso de VPNs para Acesso a Transmissões de Boxe: Questões de Segurança e Privacidade</title><link>https://brdefense.center/news/uso-de-vpns-para-acesso-a-transmissoes-de-boxe-que/</link><pubDate>Fri, 08 Aug 2025 18:55:35 -0300</pubDate><guid>https://brdefense.center/news/uso-de-vpns-para-acesso-a-transmissoes-de-boxe-que/</guid><description>&lt;p>O uso de VPNs para acessar transmissões de eventos esportivos, como a luta entre Moses Itauma e Dillian Whyte, levanta preocupações significativas sobre segurança e privacidade. Embora VPNs possam ser ferramentas eficazes para contornar bloqueios regionais e garantir acesso a conteúdos restritos, é crucial escolher provedores confiáveis para evitar riscos de segurança cibernética. VPNs gratuitas, em particular, podem não oferecer a proteção necessária, expondo usuários a vulnerabilidades e possíveis interceptações de dados.Especialistas em cibersegurança alertam que VPNs de baixa qualidade podem comprometer a experiência de streaming ao introduzir problemas de buffering e falhas de conexão, além de potencialmente expor informações pessoais dos usuários. Para garantir uma navegação segura e sem interrupções, recomenda-se optar por serviços VPN pagos e bem avaliados, que oferecem criptografia robusta e servidores otimizados para streaming, como NordVPN e Surfshark. A escolha de um VPN adequado é essencial para proteger dados pessoais e garantir uma experiência de visualização segura e de alta qualidade.&lt;/p></description></item><item><title>Campanha de Phishing com IA Alvo de Alerta no Brasil</title><link>https://brdefense.center/news/campanha-de-phishing-com-ia-alvo-de-alerta-no-bras/</link><pubDate>Fri, 08 Aug 2025 16:14:00 -0300</pubDate><guid>https://brdefense.center/news/campanha-de-phishing-com-ia-alvo-de-alerta-no-bras/</guid><description>&lt;p>Pesquisadores de cibersegurança estão soando o alarme sobre uma campanha de phishing que utiliza ferramentas de inteligência artificial generativa para criar páginas falsas que imitam agências do governo brasileiro. Essas páginas enganosas, que se passam por sites do Departamento Estadual de Trânsito e do Ministério da Educação, visam coletar informações pessoais sensíveis e induzir usuários a realizar pagamentos indevidos através do sistema PIX. A campanha é impulsionada por técnicas de envenenamento de SEO, aumentando a visibilidade dos sites fraudulentos e, consequentemente, o risco de sucesso dos ataques.&lt;/p></description></item><item><title>Tentativa de Ransomware Alvo de Empresa de Petróleo no Paquistão</title><link>https://brdefense.center/news/tentativa-de-ransomware-alvo-de-empresa-de-petrole/</link><pubDate>Fri, 08 Aug 2025 14:22:41 -0300</pubDate><guid>https://brdefense.center/news/tentativa-de-ransomware-alvo-de-empresa-de-petrole/</guid><description>&lt;p>A Pakistan Petroleum Limited (PPL), uma empresa de exploração de petróleo e gás, foi alvo de um ataque de ransomware em partes de sua infraestrutura de TI, detectado em 6 de agosto de 2025. Apesar da seriedade da ameaça, a empresa conseguiu conter rapidamente o incidente, garantindo que nenhum sistema crítico ou dados sensíveis fossem comprometidos. Este evento ressalta a importância de protocolos de cibersegurança robustos e a necessidade de vigilância constante contra ameaças sofisticadas de ransomware, que continuam a evoluir e a representar riscos significativos para organizações em todo o mundo.&lt;/p></description></item><item><title>Grave Vazamento Expõe Dados Sensíveis de Quase 870 Mil Indivíduos</title><link>https://brdefense.center/news/grave-vazamento-expoe-dados-sensiveis-de-quase-870/</link><pubDate>Fri, 08 Aug 2025 13:54:13 -0300</pubDate><guid>https://brdefense.center/news/grave-vazamento-expoe-dados-sensiveis-de-quase-870/</guid><description>&lt;p>A Universidade de Columbia confirmou um vazamento de dados significativo que comprometeu informações pessoais de 868.969 indivíduos em todo o país, incluindo 2.026 residentes do Maine. Este incidente, classificado como uma violação de sistema externo, ocorreu entre 16 de maio e 6 de junho de 2025, mas só foi descoberto em 8 de julho de 2025. A violação representa um dos maiores vazamentos de dados no setor de educação superior nos últimos anos, destacando a crescente ameaça de cibercriminosos que exploram vulnerabilidades em infraestruturas de rede de instituições renomadas.Em resposta ao incidente, a Universidade de Columbia tomou medidas rápidas para conter a violação e iniciou uma investigação forense abrangente para entender o escopo completo do comprometimento. Além disso, a universidade está oferecendo 24 meses de monitoramento de crédito e serviços de proteção contra roubo de identidade para todos os indivíduos afetados, em parceria com a Kroll, LLC. Este pacote de proteção excede os padrões típicos da indústria, que geralmente oferecem períodos de proteção de 12 meses, sublinhando a gravidade do vazamento e o compromisso da universidade em mitigar os riscos para os afetados.&lt;/p></description></item><item><title>Vulnerabilidade Crítica no Windows Permite Escalonamento de Privilégios</title><link>https://brdefense.center/news/vulnerabilidade-critica-no-windows-permite-escalon/</link><pubDate>Fri, 08 Aug 2025 13:27:55 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-critica-no-windows-permite-escalon/</guid><description>&lt;p>Uma nova técnica de bypass do Controle de Conta de Usuário (UAC) no Windows foi revelada, utilizando o Editor de Caracteres Privados para permitir que atacantes obtenham privilégios elevados sem o consentimento do usuário. Esta vulnerabilidade, divulgada pelo pesquisador de segurança Matan Bahar, explora a configuração de manifesto do aplicativo eudcedit.exe, um utilitário legítimo do Windows, para contornar mecanismos de segurança críticos. A técnica é alarmante, pois utiliza um programa confiável que normalmente não levantaria suspeitas, permitindo que invasores que já tenham acesso inicial escalem seus privilégios de forma discreta e eficaz.&lt;/p></description></item><item><title>Vulnerabilidades Críticas em Sistemas de Controle Industrial Ameaçam Infraestruturas Vitais</title><link>https://brdefense.center/news/vulnerabilidades-criticas-em-sistemas-de-controle-/</link><pubDate>Fri, 08 Aug 2025 13:04:34 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidades-criticas-em-sistemas-de-controle-/</guid><description>&lt;p>A Agência de Segurança Cibernética e de Infraestrutura (CISA) emitiu, em 7 de agosto de 2025, dez novos avisos sobre vulnerabilidades em Sistemas de Controle Industrial (ICS), destacando lacunas significativas de segurança em setores como manufatura, automação predial e infraestrutura de telecomunicações. Estas vulnerabilidades representam um risco urgente, pois podem permitir acesso não autorizado a componentes críticos de infraestrutura, comprometendo a segurança e a operação de sistemas essenciais. Entre os sistemas afetados estão o DIAView da Delta Electronics, os controladores FX80 e FX90 da Johnson Controls, e os telefones IP da Yealink, todos suscetíveis a ataques de execução remota de código e negação de serviço.Os avisos também incluem atualizações para vulnerabilidades previamente identificadas, como nos sistemas de monitoramento Instantel Micromate e nas soluções digitais da Mitsubishi Electric, indicando preocupações de segurança contínuas. A presença de dispositivos orientados ao consumidor, como aplicativos móveis da Dreame Technology, ressalta a crescente superfície de ataque em ambientes industriais. Especialistas enfatizam a necessidade de medidas preventivas urgentes para mitigar esses riscos e proteger infraestruturas críticas de possíveis explorações maliciosas.&lt;/p></description></item><item><title>Cibercriminosos Desafiam Agências de Segurança com Ataques Sofisticados</title><link>https://brdefense.center/news/cibercriminosos-desafiam-agencias-de-seguranca-com/</link><pubDate>Fri, 08 Aug 2025 12:37:20 -0300</pubDate><guid>https://brdefense.center/news/cibercriminosos-desafiam-agencias-de-seguranca-com/</guid><description>&lt;p>O grupo de cibercriminosos conhecido como ShinyHunters continua a desafiar as principais agências de segurança, incluindo a NSA e o FBI, com ataques cada vez mais sofisticados. Em uma recente declaração, membros do grupo afirmaram que suas táticas avançadas, como o uso de vozes geradas por IA, tornam as tentativas de rastreamento e identificação ineficazes. Essa confiança na tecnologia de ponta para evitar a detecção representa uma ameaça crescente para empresas e governos, que precisam reforçar suas defesas cibernéticas para mitigar riscos significativos de vazamentos de dados e extorsões.Além disso, o grupo tem como alvo grandes corporações, como a LVMH, controladora de marcas de luxo como Dior e Tiffany, que já foram vítimas de suas campanhas de extorsão. A insistência do ShinyHunters em continuar suas operações, apesar da pressão de gigantes corporativos e das autoridades, destaca a urgência de medidas preventivas robustas e a necessidade de uma colaboração internacional mais eficaz para combater essas ameaças cibernéticas. As organizações devem estar em alerta máximo e investir em tecnologias de segurança avançadas para proteger seus dados e operações contra esses ataques devastadores.&lt;/p></description></item><item><title>Desmantelamento do BlackSuit Ransomware: Um Golpe Crítico Contra o Crime Cibernético</title><link>https://brdefense.center/news/desmantelamento-do-blacksuit-ransomware-um-golpe-c/</link><pubDate>Fri, 08 Aug 2025 12:09:27 -0300</pubDate><guid>https://brdefense.center/news/desmantelamento-do-blacksuit-ransomware-um-golpe-c/</guid><description>&lt;p>Em uma operação internacional coordenada, autoridades federais dos Estados Unidos, em parceria com a Europol, desmantelaram a infraestrutura crítica do grupo de ransomware BlackSuit. Este grupo, sucessor do Royal ransomware, utilizava táticas sofisticadas de dupla extorsão para atacar mais de 450 organizações, incluindo setores críticos como saúde, educação e energia. A operação resultou na apreensão de servidores, domínios e ativos digitais, marcando um avanço significativo na luta contra ameaças de ransomware, que têm causado impactos financeiros devastadores e riscos à segurança nacional.&lt;/p></description></item><item><title>Grave Vazamento de Dados Afeta Clientes da KLM e Air France</title><link>https://brdefense.center/news/grave-vazamento-de-dados-afeta-clientes-da-klm-e-a/</link><pubDate>Fri, 08 Aug 2025 11:04:07 -0300</pubDate><guid>https://brdefense.center/news/grave-vazamento-de-dados-afeta-clientes-da-klm-e-a/</guid><description>&lt;p>Um vazamento de dados impactante foi relatado pela KLM e Air France, envolvendo acesso não autorizado a informações de clientes em uma plataforma externa de atendimento ao cliente. Embora os sistemas internos das companhias aéreas não tenham sido comprometidos e dados sensíveis como senhas e informações de pagamento não tenham sido expostos, o incidente faz parte de uma onda alarmante de ataques relacionados ao Salesforce, conduzidos pelo grupo ShinyHunters.&lt;/p>
&lt;p>As companhias aéreas tomaram medidas imediatas para interromper o acesso e prevenir futuros incidentes, além de notificar as autoridades nacionais de proteção de dados na Holanda e na França. Este vazamento destaca a crescente ameaça de ataques cibernéticos sofisticados que visam plataformas externas, sublinhando a necessidade urgente de medidas preventivas robustas e governança de segurança cibernética eficaz para proteger dados de clientes.&lt;/p></description></item><item><title>Grave Aumento de Vazamento de Credenciais Ameaça Segurança Corporativa</title><link>https://brdefense.center/news/grave-aumento-de-vazamento-de-credenciais-ameaca-s/</link><pubDate>Fri, 08 Aug 2025 11:00:00 -0300</pubDate><guid>https://brdefense.center/news/grave-aumento-de-vazamento-de-credenciais-ameaca-s/</guid><description>&lt;p>O vazamento de credenciais corporativas se tornou uma ameaça crescente e alarmante, com um aumento de 160% em 2025 em comparação ao ano anterior, segundo dados da Cyberint. Este fenômeno, impulsionado por automação e acessibilidade, representa um risco significativo para as organizações, uma vez que credenciais vazadas são frequentemente utilizadas para invasões de contas, campanhas de phishing e extorsão. A facilidade com que atacantes de baixo nível podem acessar e explorar essas informações, muitas vezes vendidas em mercados clandestinos, destaca a urgência de medidas preventivas robustas para mitigar esse perigo.&lt;/p></description></item><item><title>Pacotes Maliciosos no RubyGems: Perigo de Roubo de Credenciais</title><link>https://brdefense.center/news/pacotes-maliciosos-no-rubygems-perigo-de-roubo-de-/</link><pubDate>Fri, 08 Aug 2025 10:58:00 -0300</pubDate><guid>https://brdefense.center/news/pacotes-maliciosos-no-rubygems-perigo-de-roubo-de-/</guid><description>&lt;p>Uma nova ameaça alarmante foi identificada no ecossistema RubyGems, onde 60 pacotes maliciosos foram descobertos se passando por ferramentas de automação para redes sociais e blogs. Desde março de 2023, esses pacotes têm sido usados para roubar credenciais de usuários desavisados, com mais de 275.000 downloads registrados. Os pacotes, que prometem funcionalidades como postagens em massa, na verdade contêm códigos ocultos que exfiltram nomes de usuário e senhas para servidores controlados por cibercriminosos, representando um risco significativo para a segurança dos dados dos usuários.A operação, que se concentra principalmente em usuários sul-coreanos, utiliza interfaces em coreano e servidores com domínios .kr para capturar informações sensíveis. Essa campanha sofisticada e persistente destaca a necessidade urgente de medidas preventivas e de segurança robustas para proteger sistemas contra infostealers disfarçados de ferramentas legítimas. Especialistas em segurança cibernética alertam para o impacto devastador que tais ataques podem ter, especialmente em usuários que dependem dessas ferramentas para campanhas de marketing e SEO, muitas vezes sem perceber o perigo iminente que enfrentam.&lt;/p></description></item><item><title>Lançamento do ChatGPT-5: Potenciais Riscos de Segurança e Privacidade</title><link>https://brdefense.center/news/lancamento-do-chatgpt-5-potenciais-riscos-de-seguranca-e-privacidade/</link><pubDate>Thu, 07 Aug 2025 18:06:50 -0300</pubDate><guid>https://brdefense.center/news/lancamento-do-chatgpt-5-potenciais-riscos-de-seguranca-e-privacidade/</guid><description>&lt;p>O lançamento do ChatGPT-5 pela OpenAI traz à tona preocupações sérias sobre segurança e privacidade, especialmente devido à sua capacidade de se conectar a contas do Google, como Gmail e Google Calendar. Essa funcionalidade, embora ofereça conveniência, também aumenta o risco de exposição de dados pessoais e sensíveis, caso medidas de segurança robustas não sejam implementadas adequadamente. Especialistas em cibersegurança alertam que a integração com serviços de terceiros pode ser um vetor de ataque para cibercriminosos, que buscam explorar vulnerabilidades em sistemas interconectados.&lt;/p></description></item><item><title>Técnica de Evasão em Chamadas Fantasmas Ameaça Segurança em Plataformas de Videoconferência</title><link>https://brdefense.center/news/tecnica-de-evasao-em-chamadas-fantasmas-ameaca-seguranca-em-plataformas-de-video/</link><pubDate>Thu, 07 Aug 2025 17:28:00 -0300</pubDate><guid>https://brdefense.center/news/tecnica-de-evasao-em-chamadas-fantasmas-ameaca-seguranca-em-plataformas-de-video/</guid><description>&lt;p>Pesquisadores da Praetorian alertam sobre a técnica de evasão conhecida como Chamadas Fantasmas, que explora plataformas de videoconferência como Microsoft Teams e Zoom para realizar ataques de comando e controle sem detecção. Ao sequestrar credenciais temporárias TURN, os cibercriminosos conseguem estabelecer túneis entre o host comprometido e suas máquinas, utilizando a infraestrutura confiável dessas plataformas para mascarar suas atividades maliciosas. Este método de ataque é particularmente preocupante, pois aproveita a infraestrutura já permitida por firewalls corporativos, proxies e inspeção TLS, tornando-se invisível para as defesas tradicionais.A técnica de Chamadas Fantasmas não depende de vulnerabilidades específicas a serem corrigidas, mas sim da implementação de salvaguardas adicionais por parte dos fornecedores para prevenir tais ataques. A natureza criptografada e ofuscada do tráfego de videoconferência, muitas vezes protegido por AES ou outras criptografias fortes, dificulta ainda mais a detecção de atividades maliciosas. Com credenciais TURN expirando em dois a três dias, os túneis são de curta duração, mas a ameaça permanece significativa, exigindo atenção urgente das organizações para mitigar riscos de exfiltração de dados e outras consequências graves.&lt;/p></description></item><item><title>Preocupações com Privacidade e Desempenho no Uso do Gaming Copilot da Microsoft</title><link>https://brdefense.center/news/preocupacoes-com-privacidade-e-desempenho-no-uso-do-gaming-copilot-da-microsoft/</link><pubDate>Thu, 07 Aug 2025 17:00:00 -0300</pubDate><guid>https://brdefense.center/news/preocupacoes-com-privacidade-e-desempenho-no-uso-do-gaming-copilot-da-microsoft/</guid><description>&lt;p>A Microsoft lançou o Gaming Copilot, um assistente de inteligência artificial para jogadores, na Game Bar do Windows 11, atualmente em fase de testes beta. Embora a ferramenta prometa ajudar jogadores a superar desafios em jogos sem a necessidade de alternar para um navegador, surgem preocupações sobre a privacidade dos usuários, já que a IA monitora a atividade de jogo para oferecer assistência. Além disso, há receios sobre o impacto no desempenho e na vida útil da bateria de dispositivos portáteis de jogos, uma vez que o recurso adiciona uma carga extra ao sistema durante o jogo.&lt;/p></description></item><item><title>Vulnerabilidade Crítica na Plataforma Akamai Permite Solicitações Maliciosas Ocultas</title><link>https://brdefense.center/news/vulnerabilidade-critica-na-plataforma-akamai-permite-solicitacoes-maliciosas-ocu/</link><pubDate>Thu, 07 Aug 2025 13:29:58 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-critica-na-plataforma-akamai-permite-solicitacoes-maliciosas-ocu/</guid><description>&lt;p>Uma vulnerabilidade significativa de HTTP Request Smuggling, identificada como CVE-2025-32094, foi descoberta na plataforma Akamai em março de 2025. Esta falha, que envolvia solicitações OPTIONS combinadas com técnicas obsoletas de quebra de linha, foi completamente resolvida pela Akamai, sem evidências de exploração bem-sucedida. A vulnerabilidade surgiu de uma interação complexa entre dois defeitos específicos na implementação do sistema de processamento de solicitações HTTP/1.x da Akamai, permitindo que atacantes introduzissem solicitações maliciosas ocultas no corpo da solicitação e potencialmente burlassem controles de segurança.A resposta coordenada da Akamai à CVE-2025-32094 exemplifica práticas eficazes de gerenciamento de vulnerabilidades na indústria de cibersegurança. Após receber o relatório do programa de recompensas por bugs, a empresa implementou uma correção em toda a plataforma, protegendo todos os clientes e mantendo uma comunicação transparente por meio de atualizações regulares. A linha do tempo de divulgação foi coordenada com a apresentação de pesquisa de James Kettle na Black Hat 2025, permitindo uma conscientização pública abrangente sobre a metodologia de ataque.&lt;/p></description></item><item><title>Pacotes Maliciosos em Go Ameaçam Sistemas Windows e Linux</title><link>https://brdefense.center/news/pacotes-maliciosos-em-go-ameacam-sistemas-windows-e-linux/</link><pubDate>Thu, 07 Aug 2025 13:19:00 -0300</pubDate><guid>https://brdefense.center/news/pacotes-maliciosos-em-go-ameacam-sistemas-windows-e-linux/</guid><description>&lt;p>Pesquisadores de cibersegurança identificaram 11 pacotes maliciosos desenvolvidos em Go que representam uma ameaça significativa para sistemas Windows e Linux. Esses pacotes são projetados para baixar cargas adicionais de servidores remotos e executá-las silenciosamente, comprometendo a segurança dos sistemas. A técnica utilizada pelos cibercriminosos envolve a execução de um shell que busca cargas de segundo estágio de endpoints de comando e controle, permitindo a coleta de informações do host e o acesso a dados de navegadores web. A natureza descentralizada do ecossistema Go facilita a importação direta de módulos de repositórios GitHub, aumentando o risco de desenvolvedores integrarem código malicioso inadvertidamente em seus projetos.A descoberta destaca os riscos contínuos à cadeia de suprimentos, exacerbados pela natureza multiplataforma do Go, que facilita a propagação de malware. A confusão gerada por nomes de módulos semelhantes, mas não necessariamente maliciosos, é explorada por atacantes para aumentar a probabilidade de integração de código destrutivo. A situação é agravada pela reutilização de servidores de comando e controle, sugerindo a ação de um único ator de ameaça. É crucial que desenvolvedores e organizações adotem medidas preventivas rigorosas para mitigar esses riscos e proteger seus ambientes de desenvolvimento e produção.&lt;/p></description></item><item><title>Exploit de Injeção de Prompt em Gemini Rouba Dados Sensíveis de Usuários</title><link>https://brdefense.center/news/exploit-de-injecao-de-prompt-em-gemini-rouba-dados-sensiveis-de-usuarios/</link><pubDate>Thu, 07 Aug 2025 13:08:10 -0300</pubDate><guid>https://brdefense.center/news/exploit-de-injecao-de-prompt-em-gemini-rouba-dados-sensiveis-de-usuarios/</guid><description>&lt;p>Pesquisadores de cibersegurança revelaram um ataque sofisticado chamado TARA (Targeted Promptware Attack) que compromete assistentes alimentados pelo Gemini do Google através de convites de e-mail e eventos de calendário aparentemente inocentes. Liderados pelo renomado especialista em segurança Ben Nassi, da Universidade de Tel-Aviv, o estudo demonstra como cibercriminosos podem manipular sistemas de IA para realizar ações maliciosas, desde roubo de dados até o controle de dispositivos domésticos inteligentes, representando uma ameaça crescente à segurança digital e física dos usuários.&lt;/p></description></item><item><title>Hackers Exploram Plataformas de Conferência para Canais C2 Ocultos</title><link>https://brdefense.center/news/hackers-exploram-plataformas-de-conferencia-para-canais-c2-ocultos/</link><pubDate>Thu, 07 Aug 2025 12:31:10 -0300</pubDate><guid>https://brdefense.center/news/hackers-exploram-plataformas-de-conferencia-para-canais-c2-ocultos/</guid><description>&lt;p>Pesquisadores de segurança revelaram uma técnica de ataque sofisticada que utiliza plataformas de conferência web para estabelecer canais de comando e controle (C2) ocultos. Esta abordagem permite que cibercriminosos disfarcem tráfego malicioso como reuniões online legítimas, potencialmente burlando medidas tradicionais de segurança de rede. A técnica, apresentada na Black Hat USA 2025, destaca como protocolos de comunicação em tempo real podem ser explorados para criar sessões C2 interativas de alta largura de banda, que se misturam de forma indistinguível com o tráfego de colaboração empresarial normal.&lt;/p></description></item><item><title>Ataque a Active Directory Bypassa Autenticação e Rouba Dados Sensíveis</title><link>https://brdefense.center/news/ataque-a-active-directory-bypassa-autenticacao-e-rouba-dados-sensiveis/</link><pubDate>Thu, 07 Aug 2025 12:09:13 -0300</pubDate><guid>https://brdefense.center/news/ataque-a-active-directory-bypassa-autenticacao-e-rouba-dados-sensiveis/</guid><description>&lt;p>Pesquisador de segurança Dirk-Jan Mollema, da Outsider Security, revelou técnicas avançadas de movimento lateral que permitem a atores de ameaça comprometer a infraestrutura de nuvem da Microsoft através de vulnerabilidades no Active Directory local. Durante sua apresentação na Black Hat USA 2025, Mollema destacou lacunas críticas de segurança em ambientes híbridos de AD que podem permitir que atacantes contornem a autenticação multifator e exfiltrem dados sensíveis sem detecção, explorando relações de confiança entre domínios locais e recursos na nuvem.&lt;/p></description></item><item><title>Vulnerabilidade Crítica no Exchange Server Ameaça Segurança de Ambientes Híbridos</title><link>https://brdefense.center/news/vulnerabilidade-critica-no-exchange-server-ameaca-seguranca-de-ambientes-hibrido/</link><pubDate>Thu, 07 Aug 2025 10:42:00 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-critica-no-exchange-server-ameaca-seguranca-de-ambientes-hibrido/</guid><description>&lt;p>A Microsoft divulgou um alerta sobre uma vulnerabilidade de alta gravidade, identificada como CVE-2025-53786, que afeta versões on-premise do Exchange Server. Essa falha, com um CVSS de 8.0, pode permitir que um atacante, já com acesso administrativo, escale privilégios dentro do ambiente de nuvem conectado da organização sem deixar rastros facilmente detectáveis. A ameaça é particularmente preocupante em implantações híbridas, onde o Exchange Server e o Exchange Online compartilham o mesmo serviço principal, aumentando o risco de comprometimento da integridade de identidade do serviço Exchange Online se não corrigida.A Agência de Segurança Cibernética e de Infraestrutura dos EUA (CISA) destacou a importância de aplicar correções, como o Hot Fix de abril de 2025, e revisar as configurações de segurança para implantações híbridas. A Microsoft também anunciou medidas temporárias para bloquear o tráfego de Exchange Web Services (EWS) usando o serviço principal compartilhado, visando melhorar a segurança do ambiente híbrido. Organizações são instadas a atualizar suas configurações e descontinuar o uso de servidores Exchange ou SharePoint que atingiram o fim de vida ou serviço, para mitigar riscos adicionais de exploração por atores maliciosos.&lt;/p></description></item><item><title>Ameaças Crescentes: Ataques na Nuvem Impulsionados por IA</title><link>https://brdefense.center/news/ameacas-crescentes-ataques-na-nuvem-impulsionados-por-ia/</link><pubDate>Thu, 07 Aug 2025 10:33:00 -0300</pubDate><guid>https://brdefense.center/news/ameacas-crescentes-ataques-na-nuvem-impulsionados-por-ia/</guid><description>&lt;p>Em 2025, os ataques na nuvem estão evoluindo em uma velocidade alarmante, com a inteligência artificial (IA) sendo utilizada tanto como arma quanto como escudo. A recente evolução dos ataques, como a campanha CRYSTALRAY, demonstra um nível de coordenação e rapidez que seria impossível sem a automação. Esses ataques, que incluem reconhecimento, movimento lateral e coleta de credenciais, representam uma ameaça crescente para as empresas que dependem de soluções em nuvem. As equipes de segurança estão sendo desafiadas a adotar defesas em tempo real e contextualmente conscientes para enfrentar essas ameaças que operam em velocidades de máquina.Por outro lado, a própria IA se tornou um alvo crítico, necessitando de proteção robusta. O aumento de 500% nas cargas de trabalho em nuvem contendo pacotes de IA/ML em 2024 destaca a adoção massiva dessas tecnologias, mas também expõe novas superfícies de ataque. Para mitigar esses riscos, é essencial implementar medidas de segurança como a autenticação de APIs, endurecimento de configurações e a aplicação do princípio de menor privilégio. A segurança na nuvem deve evoluir para ser tão ágil quanto as ameaças que enfrenta, garantindo que as joias digitais da era da IA sejam devidamente protegidas contra cibercriminosos cada vez mais sofisticados.&lt;/p></description></item><item><title>Vulnerabilidade Crítica em SonicWall Ameaça Segurança de Firewalls</title><link>https://brdefense.center/news/vulnerabilidade-critica-em-sonicwall-ameaca-seguranca-de-firewalls/</link><pubDate>Thu, 07 Aug 2025 10:32:00 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-critica-em-sonicwall-ameaca-seguranca-de-firewalls/</guid><description>&lt;p>A SonicWall revelou que o recente aumento de atividades maliciosas direcionadas aos seus firewalls Gen 7 e mais recentes, com SSL VPN habilitado, está relacionado a uma vulnerabilidade antiga, agora corrigida, e ao uso repetido de senhas. A vulnerabilidade, identificada como CVE-2024-40766, foi divulgada pela primeira vez em agosto de 2024 e possui um escore CVSS de 9.3, indicando um risco elevado de acesso não autorizado aos dispositivos. A empresa está investigando menos de 40 incidentes relacionados a essa atividade, muitos dos quais estão associados a migrações de firewalls Gen 6 para Gen 7 sem redefinição das senhas dos usuários locais, uma ação recomendada crucial.Para mitigar os riscos, a SonicWall recomenda a atualização do firmware para a versão SonicOS 7.3.0, redefinição de todas as senhas de contas de usuários locais com acesso SSLVPN, habilitação de proteção contra botnets e filtragem Geo-IP, além da implementação de autenticação multifator e políticas de senhas fortes. Este desenvolvimento ocorre em meio a um aumento nos ataques que exploram dispositivos SonicWall SSL VPN para ataques de ransomware Akira, destacando a necessidade urgente de medidas preventivas robustas para proteger as infraestruturas de rede.&lt;/p></description></item><item><title>NVIDIA Alerta para Riscos de Vulnerabilidades em Hardware com Backdoors</title><link>https://brdefense.center/news/nvidia-alerta-para-riscos-de-vulnerabilidades-em-hardware-com-backdoors/</link><pubDate>Thu, 07 Aug 2025 08:51:12 -0300</pubDate><guid>https://brdefense.center/news/nvidia-alerta-para-riscos-de-vulnerabilidades-em-hardware-com-backdoors/</guid><description>&lt;p>A NVIDIA emitiu uma declaração enfática rejeitando a inclusão de backdoors e kill switches em seus hardwares de GPU, destacando que tais características comprometeriam gravemente a infraestrutura de cibersegurança global. A empresa argumenta que a introdução de vulnerabilidades embutidas nos componentes críticos de computação representa uma ameaça perigosa, criando vetores de ataque permanentes que poderiam ser explorados por atores maliciosos. Essa posição surge em meio a discussões políticas crescentes sobre mecanismos de controle remoto em hardwares essenciais, com a NVIDIA defendendo que tais propostas são um desvio perigoso dos princípios de segurança estabelecidos.A empresa enfatiza a importância do princípio de &amp;lsquo;defesa em profundidade&amp;rsquo;, que busca eliminar vulnerabilidades de ponto único através de uma abordagem de segurança em camadas. A introdução de vulnerabilidades deliberadas em hardwares críticos, como GPUs, comprometeria não apenas sistemas individuais, mas também ecossistemas tecnológicos inteiros que dependem de computação acelerada por GPU. A NVIDIA defende soluções de software transparentes e ferramentas de monitoramento que aumentem a segurança do sistema sem comprometer a integridade do hardware, rejeitando comparações com funcionalidades de smartphones que operam com o consentimento do usuário.&lt;/p></description></item><item><title>Ameaça Crescente: Ataques à Cadeia de Suprimentos Python Colocam Sistemas em Risco</title><link>https://brdefense.center/news/ameaca-crescente-ataques-a-cadeia-de-suprimentos-p/</link><pubDate>Thu, 07 Aug 2025 07:16:00 -0300</pubDate><guid>https://brdefense.center/news/ameaca-crescente-ataques-a-cadeia-de-suprimentos-p/</guid><description>&lt;p>Os ataques à cadeia de suprimentos envolvendo pacotes Python estão se tornando uma ameaça alarmante e crescente em 2025. Criminosos cibernéticos estão explorando vulnerabilidades em repositórios de código aberto, como o Python Package Index (PyPI), para introduzir pacotes maliciosos que passam despercebidos até causarem danos significativos. Um exemplo grave ocorreu em dezembro de 2024, quando o pacote Ultralytics YOLO, amplamente utilizado em aplicações de visão computacional, foi comprometido e baixado milhares de vezes antes de ser detectado. Este cenário destaca a urgência de tratar a segurança da cadeia de suprimentos Python como uma prioridade crítica.Os métodos utilizados pelos atacantes incluem técnicas como typo-squatting, repo-jacking e slop-squatting, que exploram falhas na gestão de pacotes e repositórios. Além disso, até mesmo imagens oficiais do contêiner Python contêm vulnerabilidades críticas, com mais de 100 CVEs de alta gravidade identificados. Para mitigar esses riscos, é essencial que desenvolvedores e engenheiros de segurança adotem ferramentas e práticas robustas, como pip-audit, Sigstore e SBOMs, para garantir a integridade do código e proteger suas aplicações contra essas ameaças sofisticadas e em rápida evolução.&lt;/p></description></item><item><title>Vulnerabilidade Crítica no Amazon ECS Permite Escalação de Privilégios</title><link>https://brdefense.center/news/vulnerabilidade-critica-no-amazon-ecs-permite-esca/</link><pubDate>Wed, 06 Aug 2025 20:30:00 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-critica-no-amazon-ecs-permite-esca/</guid><description>&lt;p>Pesquisadores de cibersegurança identificaram uma vulnerabilidade alarmante no Amazon Elastic Container Service (ECS), que pode ser explorada por atacantes para realizar movimentações laterais, acessar dados sensíveis e assumir o controle do ambiente em nuvem. A técnica de ataque, denominada ECScape, foi apresentada na conferência de segurança Black Hat USA, destacando como um contêiner malicioso com permissões limitadas pode obter credenciais de IAM de contêineres mais privilegiados na mesma instância EC2, comprometendo seriamente a segurança do ambiente AWS.&lt;/p></description></item><item><title>Vulnerabilidades Críticas em Notebooks Dell Expõem Dados Sensíveis</title><link>https://brdefense.center/news/vulnerabilidades-criticas-em-notebooks-dell-expoem/</link><pubDate>Wed, 06 Aug 2025 20:21:25 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidades-criticas-em-notebooks-dell-expoem/</guid><description>&lt;p>Pesquisadores da Cisco Talos identificaram cinco vulnerabilidades críticas nos chips Broadcom BCM5820X, presentes em mais de 100 modelos de notebooks Dell, incluindo as séries Latitude e Precision. Essas falhas, catalogadas como CVE-2025-24311, CVE-2025-25215, CVE-2025-24922, CVE-2025-25050 e CVE-2025-24919, afetam a função ControlVault3, responsável por armazenar dados sensíveis como senhas e informações biométricas. Um invasor com poucos privilégios poderia explorar essas vulnerabilidades para roubar dados, executar códigos maliciosos remotamente e até implantar um backdoor no firmware, comprometendo a segurança dos dispositivos afetados.&lt;/p></description></item><item><title>Alerta: Aplicativos Maliciosos Disfarçados de VPN e Bloqueadores de Spam</title><link>https://brdefense.center/news/alerta-aplicativos-maliciosos-disfarcados-de-vpn-e/</link><pubDate>Wed, 06 Aug 2025 20:00:00 -0300</pubDate><guid>https://brdefense.center/news/alerta-aplicativos-maliciosos-disfarcados-de-vpn-e/</guid><description>&lt;p>O grupo criminoso VexTrio Viper tem desenvolvido aplicativos maliciosos que estão sendo distribuídos nas lojas oficiais da Apple e Google, sob o disfarce de aplicativos úteis como VPNs, bloqueadores de spam e serviços de namoro. Esses aplicativos, uma vez instalados, enganam os usuários para que se inscrevam em assinaturas difíceis de cancelar, inundam-nos com anúncios e coletam informações pessoais, como endereços de e-mail. A empresa de inteligência de ameaças DNS, Infoblox, destacou que esses aplicativos foram baixados milhões de vezes, expondo um grande número de usuários a riscos significativos de segurança e privacidade.A análise revela que o VexTrio Viper opera uma rede criminosa multinacional, utilizando serviços de distribuição de tráfego para redirecionar grandes volumes de tráfego da internet para golpes através de suas redes de publicidade. Desde 2015, eles têm gerido processadores de pagamento e ferramentas de validação de e-mail, facilitando fraudes em larga escala. A complexidade e o alcance dessas operações destacam a necessidade urgente de medidas preventivas e de conscientização dos usuários para evitar cair em armadilhas digitais tão sofisticadas e prejudiciais.&lt;/p></description></item><item><title>Permissões Excessivas em Nuvem: Uma Vulnerabilidade Urgente e Explorada</title><link>https://brdefense.center/news/permissoes-excessivas-em-nuvem-uma-vulnerabilidade/</link><pubDate>Wed, 06 Aug 2025 18:00:00 -0300</pubDate><guid>https://brdefense.center/news/permissoes-excessivas-em-nuvem-uma-vulnerabilidade/</guid><description>&lt;p>O Relatório de Riscos de Segurança na Nuvem 2025 revela uma preocupação alarmante: 83% das empresas que utilizam a Amazon Web Services (AWS) enfrentam problemas com permissões excessivas e acessos permanentes. Apesar dos avanços na centralização do controle de acesso por meio de Provedores de Identidade (IdPs), a segurança total ainda está longe de ser alcançada. Permissões mal configuradas e acessos sem limite de tempo criam brechas exploráveis por agentes maliciosos, ampliando a superfície de ataque de forma desnecessária. A resistência à autenticação multifator (MFA) e a permanência de permissões temporárias são desafios que exigem atenção imediata.Para mitigar esses riscos, é crucial adotar o princípio do menor privilégio, implementar acesso just-in-time e realizar auditorias frequentes e automáticas nas permissões concedidas. A segurança de identidade deve ser uma prioridade contínua, especialmente em um cenário onde os ataques se tornam cada vez mais sofisticados. A mudança de mentalidade é essencial para garantir que a configuração correta não seja uma tarefa pontual, mas sim um processo contínuo de monitoramento, visibilidade e automação. A gestão eficaz de identidades não pode ser opcional, mas sim uma prioridade estratégica para proteger o perímetro digital das organizações.&lt;/p></description></item><item><title>Grave Vazamento de Dados em Empresa de Saúde Exposto por Grupo de Ransomware</title><link>https://brdefense.center/news/grave-vazamento-de-dados-em-empresa-de-saude-exposto-por-grupo-de-ransomware/</link><pubDate>Wed, 06 Aug 2025 17:29:38 -0300</pubDate><guid>https://brdefense.center/news/grave-vazamento-de-dados-em-empresa-de-saude-exposto-por-grupo-de-ransomware/</guid><description>&lt;p>O grupo de ransomware PEAR assumiu a responsabilidade por um grave vazamento de dados ocorrido em junho de 2025 na Think Big Health Care Solutions, uma empresa de gestão de saúde na Flórida. Durante o ataque, foram comprometidos 60 GB de informações pessoais sensíveis, incluindo números de segurança social, dados financeiros, informações médicas e muito mais. O grupo criminoso publicou imagens dos documentos roubados para comprovar a violação, embora a autenticidade das imagens ainda não tenha sido verificada de forma independente. A Think Big ainda não confirmou a reivindicação do PEAR, mas está oferecendo monitoramento de crédito gratuito e proteção contra roubo de identidade para as vítimas elegíveis.Este incidente destaca o impacto devastador que ataques de ransomware podem ter em empresas de saúde, expondo dados críticos e colocando em risco a privacidade de milhares de indivíduos. A PEAR, que se concentra em roubar dados e extorquir organizações sem criptografar arquivos, já reivindicou outros 17 ataques não confirmados em 2025. Este caso ressalta a necessidade urgente de medidas preventivas robustas e de uma resposta rápida a atividades suspeitas para mitigar os riscos associados a tais violações de segurança cibernética.&lt;/p></description></item><item><title>Grave Vazamento de Dados Atinge Google em Ataque de Engenharia Social</title><link>https://brdefense.center/news/grave-vazamento-de-dados-atinge-google-em-ataque-de-engenharia-social/</link><pubDate>Wed, 06 Aug 2025 15:48:26 -0300</pubDate><guid>https://brdefense.center/news/grave-vazamento-de-dados-atinge-google-em-ataque-de-engenharia-social/</guid><description>&lt;p>Em junho, o Google foi vítima de um ataque sofisticado de engenharia social, conhecido como vishing, conduzido pelo grupo de ameaças UNC6040. Os criminosos conseguiram acessar uma instância do Salesforce da empresa, roubando dados de clientes de pequenas e médias empresas. Este vazamento de dados representa uma violação grave, com o potencial de expor informações sensíveis e impactar a confiança dos clientes. O Google respondeu rapidamente ao incidente, realizando uma análise de impacto e implementando medidas de mitigação para conter a ameaça. No entanto, a situação destaca a necessidade urgente de reforçar as defesas contra ataques de engenharia social, que continuam a evoluir em complexidade e sofisticação. Organizações devem estar em alerta máximo e adotar práticas de segurança robustas para proteger seus dados contra tais violações.&lt;/p></description></item><item><title>Criminosos Usam IA para Ransomware com Negociações Automatizadas no Brasil</title><link>https://brdefense.center/news/criminosos-usam-ia-para-ransomware-com-negociacoes/</link><pubDate>Wed, 06 Aug 2025 14:30:00 -0300</pubDate><guid>https://brdefense.center/news/criminosos-usam-ia-para-ransomware-com-negociacoes/</guid><description>&lt;p>Uma nova e alarmante ameaça de ransomware está emergindo no cenário cibernético global, com o grupo Global Group utilizando inteligência artificial para automatizar negociações de resgate. Desde junho de 2025, essa plataforma de ransomware as a service comprometeu pelo menos 17 organizações em países como Estados Unidos, Reino Unido, Austrália e Brasil, exigindo resgates que chegam a US$ 1 milhão. A integração de chatbots de IA permite que os cibercriminosos conduzam múltiplas negociações simultâneas sem intervenção humana, aumentando a escala e a eficiência de suas operações criminosas.&lt;/p></description></item><item><title>Ataque de Ransomware Ameaça Divulgar 90 GB de Dados de Escolas em Connecticut</title><link>https://brdefense.center/news/ataque-de-ransomware-ameaca-divulgar-90-gb-de-dados-de-escolas-em-connecticut/</link><pubDate>Wed, 06 Aug 2025 14:00:33 -0300</pubDate><guid>https://brdefense.center/news/ataque-de-ransomware-ameaca-divulgar-90-gb-de-dados-de-escolas-em-connecticut/</guid><description>&lt;p>O grupo de ransomware SafePay reivindicou um ataque cibernético ao distrito escolar Ridgefield Public Schools, em Connecticut, ocorrido em 24 de julho de 2025. Os criminosos estabeleceram um prazo de pouco mais de dois dias para o pagamento do resgate, ameaçando divulgar 90 GB de dados caso suas exigências não sejam atendidas. Este incidente destaca a crescente ameaça de ataques de ransomware no setor educacional, com consequências potencialmente devastadoras para a privacidade e segurança dos dados de alunos e funcionários.&lt;/p></description></item><item><title>Adoção de Serviços vCISO Aumenta 319% em Resposta a Ameaças Cibernéticas Crescentes</title><link>https://brdefense.center/news/adocao-de-servicos-vciso-aumenta-319-em-resposta-a/</link><pubDate>Wed, 06 Aug 2025 11:00:00 -0300</pubDate><guid>https://brdefense.center/news/adocao-de-servicos-vciso-aumenta-319-em-resposta-a/</guid><description>&lt;p>A crescente sofisticação e volume de ameaças cibernéticas estão tornando a segurança digital uma prioridade crítica para empresas de todos os tamanhos. Em resposta a essa realidade alarmante, as pequenas e médias empresas (SMBs) estão recorrendo urgentemente aos serviços de vCISO (Chief Information Security Officer virtual) para enfrentar as crescentes demandas de segurança e compliance. Um relatório recente da Cynomi revela que 79% dos MSPs (Provedores de Serviços Gerenciados) e MSSPs (Provedores de Serviços de Segurança Gerenciados) estão observando uma alta demanda por esses serviços entre as SMBs, destacando a importância de estratégias robustas de segurança cibernética para mitigar riscos e proteger dados sensíveis.&lt;/p></description></item><item><title>Ohio Implementa Medidas Rigorosas para Pagamentos de Ransomware</title><link>https://brdefense.center/news/ohio-implementa-medidas-rigorosas-para-pagamentos-de-ransomware/</link><pubDate>Wed, 06 Aug 2025 10:49:49 -0300</pubDate><guid>https://brdefense.center/news/ohio-implementa-medidas-rigorosas-para-pagamentos-de-ransomware/</guid><description>&lt;p>O estado de Ohio está adotando uma postura crítica em relação aos ataques de ransomware que têm assolado governos locais, exigindo que todos os condados, cidades, distritos escolares, bibliotecas e outras entidades governamentais locais estabeleçam políticas de cibersegurança que atendam a padrões específicos. A partir de 30 de setembro de 2025, qualquer pagamento de resgate só poderá ser aprovado em reuniões públicas, garantindo que decisões sobre pagamentos sejam tomadas de forma transparente e responsável, visando proteger o dinheiro dos contribuintes e informações pessoais.&lt;/p></description></item><item><title>Microsoft Avança na Detecção de Malware com Projeto Ire</title><link>https://brdefense.center/news/microsoft-avanca-na-deteccao-de-malware-com-projet/</link><pubDate>Wed, 06 Aug 2025 10:36:00 -0300</pubDate><guid>https://brdefense.center/news/microsoft-avanca-na-deteccao-de-malware-com-projet/</guid><description>&lt;p>A Microsoft anunciou o Projeto Ire, um sistema autônomo de inteligência artificial projetado para aprimorar a detecção de malware. Este protótipo, alimentado por um modelo de linguagem de grande escala, visa automatizar a engenharia reversa de arquivos de software, classificando-os como maliciosos ou benignos sem a necessidade de intervenção humana. Utilizando ferramentas especializadas, o sistema realiza análises detalhadas que vão desde a análise binária de baixo nível até a interpretação de comportamento de código em alto nível, permitindo uma resposta mais rápida a ameaças e reduzindo o esforço manual dos analistas.&lt;/p></description></item><item><title>Falhas Críticas em Console da Trend Micro Exigem Ação Imediata</title><link>https://brdefense.center/news/falhas-criticas-em-console-da-trend-micro-exigem-a/</link><pubDate>Wed, 06 Aug 2025 08:57:00 -0300</pubDate><guid>https://brdefense.center/news/falhas-criticas-em-console-da-trend-micro-exigem-a/</guid><description>&lt;p>A Trend Micro identificou e divulgou mitigações para vulnerabilidades críticas em versões on-premise do Apex One Management Console, classificadas com uma pontuação alarmante de 9.4 no sistema CVSS. As falhas, CVE-2025-54948 e CVE-2025-54987, permitem que atacantes remotos não autenticados injetem comandos e executem código malicioso, representando um risco significativo para as organizações que utilizam essa solução. Embora a empresa tenha observado tentativas de exploração ativa dessas vulnerabilidades, detalhes específicos sobre os ataques ainda não foram revelados.&lt;/p></description></item><item><title>Cibercriminoso Extraditado por Hackeamento e Fraude nos EUA</title><link>https://brdefense.center/news/cibercriminoso-extraditado-por-hackeamento-e-fraude-nos-eua/</link><pubDate>Tue, 05 Aug 2025 23:32:48 -0300</pubDate><guid>https://brdefense.center/news/cibercriminoso-extraditado-por-hackeamento-e-fraude-nos-eua/</guid><description>&lt;p>Um homem nigeriano foi extraditado para os Estados Unidos sob acusações graves de hackeamento, fraude e roubo de identidade. Chukwuemeka Victor Amachukwu, de 39 anos, juntamente com co-conspiradores baseados na Nigéria, teria invadido empresas de preparação de impostos nos EUA, roubado informações de identificação de clientes e apresentado declarações de impostos fraudulentas. Este esquema resultou em um prejuízo de pelo menos $2,5 milhões em reembolsos de impostos obtidos de forma fraudulenta do Internal Revenue Service (IRS), conforme comunicado do Departamento de Justiça dos EUA.&lt;/p></description></item><item><title>Nova Técnica de Phishing Explora Vulnerabilidades em Serviços de Proteção</title><link>https://brdefense.center/news/nova-tecnica-de-phishing-explora-vulnerabilidades-/</link><pubDate>Tue, 05 Aug 2025 22:35:00 -0300</pubDate><guid>https://brdefense.center/news/nova-tecnica-de-phishing-explora-vulnerabilidades-/</guid><description>&lt;p>Uma alarmante campanha de phishing foi identificada entre junho e julho de 2025, onde cibercriminosos exploraram serviços de encapsulamento de links da Proofpoint e Intermedia para mascarar URLs maliciosas. Essa técnica subverte tecnologias projetadas para proteger usuários, transformando domínios confiáveis em vetores de ataque, e destaca uma vulnerabilidade crítica na arquitetura de segurança de e-mail, onde a confiança implícita em domínios reconhecidos pode ser explorada para roubo de credenciais do Microsoft 365.&lt;/p></description></item><item><title>Ataque de Ransomware na DaVita Expõe Dados Sensíveis de Mais de 1 Milhão de Pacientes</title><link>https://brdefense.center/news/ataque-de-ransomware-na-davita-expoe-dados-sensiveis-de-mais-de-1-milhao-de-paci/</link><pubDate>Tue, 05 Aug 2025 19:51:25 -0300</pubDate><guid>https://brdefense.center/news/ataque-de-ransomware-na-davita-expoe-dados-sensiveis-de-mais-de-1-milhao-de-paci/</guid><description>&lt;p>O recente ataque de ransomware à DaVita Dialysis, iniciado em 24 de março de 2025 e contido em 12 de abril de 2025, resultou em um vazamento devastador de dados sensíveis de mais de 1 milhão de pacientes. O grupo de cibercriminosos InterLock, responsável pelo ataque, cumpriu a ameaça de divulgar 1,5 TB de informações, incluindo nomes, números de segurança social, dados de seguro saúde e resultados de testes clínicos. Este incidente destaca a crescente ameaça de ransomware e a necessidade urgente de medidas preventivas robustas para proteger informações críticas de saúde.A DaVita já havia enfrentado múltiplos incidentes de segurança no passado, mas este ataque recente sublinha a gravidade das violações de dados na área da saúde. Com dados de apenas cinco estados, o número preliminar de pacientes afetados já ultrapassa 1 milhão, e é provável que esse número aumente à medida que mais informações se tornem disponíveis. Este evento ressalta a importância de práticas de segurança cibernética rigorosas e a implementação de protocolos de resposta a incidentes para mitigar os riscos associados a ataques de ransomware cada vez mais sofisticados.&lt;/p></description></item><item><title>Grave Vazamento de Dados na DaVita Compromete Informações Sensíveis de Pacientes</title><link>https://brdefense.center/news/grave-vazamento-de-dados-na-davita-compromete-informacoes-sensiveis-de-pacientes/</link><pubDate>Tue, 05 Aug 2025 14:50:14 -0300</pubDate><guid>https://brdefense.center/news/grave-vazamento-de-dados-na-davita-compromete-informacoes-sensiveis-de-pacientes/</guid><description>&lt;p>A empresa de diálise renal DaVita notificou 915.952 pessoas sobre um vazamento de dados ocorrido em abril de 2025, que comprometeu informações sensíveis de pacientes, incluindo nomes, números de segurança social, informações de seguro de saúde e dados médicos. Este incidente, atribuído ao grupo de ransomware Interlock, resultou em uma violação significativa que expôs 1,5 TB de dados, afetando gravemente as operações internas da DaVita. A empresa está oferecendo assistência gratuita de restauração de identidade para as vítimas elegíveis, com prazo de inscrição até 28 de novembro de 2025.O ataque, que começou em 24 de março de 2025 e foi contido em 12 de abril de 2025, destaca a crescente ameaça que os grupos de ransomware representam para o setor de saúde. Interlock, conhecido por extorquir organizações para desbloquear sistemas infectados e não vender ou liberar dados roubados, já reivindicou 23 ataques confirmados. Este incidente ressalta a importância de medidas preventivas robustas e a necessidade de uma resposta rápida e eficaz para mitigar os impactos devastadores de tais violações de segurança.&lt;/p></description></item><item><title>Passkeys: Uma Solução Urgente para Vulnerabilidades de Senhas</title><link>https://brdefense.center/news/passkeys-uma-solucao-urgente-para-vulnerabilidades-de-senhas/</link><pubDate>Mon, 04 Aug 2025 21:36:38 -0300</pubDate><guid>https://brdefense.center/news/passkeys-uma-solucao-urgente-para-vulnerabilidades-de-senhas/</guid><description>&lt;p>As senhas tradicionais têm sido uma vulnerabilidade significativa na segurança cibernética, frequentemente exploradas em violações de dados e ataques de phishing. A introdução das passkeys, desenvolvidas pela FIDO Alliance e apoiadas por gigantes como Apple, Google e Microsoft, representa uma abordagem técnica e urgente para mitigar esses riscos. Utilizando criptografia de chave pública, as passkeys eliminam a necessidade de compartilhar segredos, protegendo contra erros humanos e sites fraudulentos. A chave privada nunca deixa o dispositivo do usuário, garantindo uma camada adicional de segurança contra interceptações e comprometimentos.&lt;/p></description></item><item><title>Cibercriminosos Intensificam Golpes de Malvertising e Falso Suporte ao Cliente</title><link>https://brdefense.center/news/cibercriminosos-intensificam-golpes-de-malvertisin/</link><pubDate>Thu, 31 Jul 2025 19:00:04 -0300</pubDate><guid>https://brdefense.center/news/cibercriminosos-intensificam-golpes-de-malvertisin/</guid><description>&lt;p>A crescente onda de golpes online, como o malvertising e o falso suporte ao cliente, representa uma ameaça séria à segurança dos dados pessoais e financeiros dos usuários. Criminosos estão utilizando anúncios infectados para instalar softwares nocivos e se passando por empresas conhecidas para obter informações sensíveis. Essa tática perigosa exige que os usuários adotem medidas preventivas urgentes, como verificar a segurança dos sites e confirmar a identidade de remetentes por canais oficiais antes de compartilhar qualquer informação.&lt;/p></description></item></channel></rss>