<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Inteligência Artificial on BR Defense Center</title><link>https://brdefense.center/tags/intelig%C3%AAncia-artificial/</link><description>Recent content in Inteligência Artificial on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Sat, 01 Nov 2025 12:57:33 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/intelig%C3%AAncia-artificial/index.xml" rel="self" type="application/rss+xml"/><item><title>IA e Regulamentação Tendências em Cibersegurança para 2026</title><link>https://brdefense.center/news/ia-e-regulamentacao-tendencias-em-ciberseguranca-p/</link><pubDate>Sat, 01 Nov 2025 12:57:33 -0300</pubDate><guid>https://brdefense.center/news/ia-e-regulamentacao-tendencias-em-ciberseguranca-p/</guid><description>&lt;p>No último Fórum Latinoamericano de Segurança da ESET, realizado no Uruguai, especialistas discutiram as tendências em cibersegurança até 2026, destacando o uso crescente da inteligência artificial (IA) em crimes virtuais. Pesquisadores como Martina López e Mario Micucci alertaram para o aumento do uso de IA agêntica, que permite a execução de ataques cibernéticos com mínima intervenção humana, especialmente em phishing e spear-phishing. Além disso, a evolução dos ransomwares, incluindo o modelo ransomware-as-a-service (RaaS), foi enfatizada, com a introdução de ransomwares desenvolvidos com IA, como o LunaLock. A regulamentação da IA também foi um ponto central, com a necessidade de legislações que garantam transparência e proteção contra abusos, como deepfakes. O Ato de Inteligência Artificial da União Europeia foi citado como um exemplo positivo, exigindo que empresas informem sobre o uso de IA. O artigo conclui que a cibersegurança enfrentará desafios significativos, com a necessidade de auditorias eficazes e regulamentações que protejam a integridade dos dispositivos tecnológicos.&lt;/p></description></item><item><title>Polícia usa IA para decifrar comunicação de cibercriminosos</title><link>https://brdefense.center/news/policia-usa-ia-para-decifrar-comunicacao-de-ciberc/</link><pubDate>Fri, 31 Oct 2025 18:59:32 -0300</pubDate><guid>https://brdefense.center/news/policia-usa-ia-para-decifrar-comunicacao-de-ciberc/</guid><description>&lt;p>A Polícia Federal da Austrália (AFP) está desenvolvendo uma ferramenta de inteligência artificial (IA) para decifrar a comunicação de cibercriminosos, especialmente aqueles que utilizam emojis e gírias das gerações Z e Alpha em discussões online sobre crimes. Esses criminosos, conhecidos como &amp;lsquo;crimefluencers&amp;rsquo;, atraem jovens e crianças para grupos de ódio, utilizando uma linguagem que pode ser difícil de interpretar para as autoridades. A comissária da AFP, Krissy Barrett, destacou que a maioria das vítimas são pré-adolescentes e jovens, o que motivou a criação dessa ferramenta. O projeto ainda está em fase de desenvolvimento e busca criar um protótipo que consiga interpretar a comunicação criptografada em grupos de bate-papo. A expectativa é que a IA consiga traduzir termos específicos com base no contexto e na semântica, embora o desafio de acompanhar a constante evolução das gírias e emojis possa dificultar a eficácia da ferramenta. A iniciativa faz parte de uma força-tarefa maior da Five Eyes Law Enforcement Group, que inclui países como Reino Unido, EUA, Canadá e Nova Zelândia, todos trabalhando juntos para combater crimes digitais.&lt;/p></description></item><item><title>OpenAI lança Aardvark, pesquisador de segurança autônomo com IA</title><link>https://brdefense.center/news/openai-lanca-aardvark-pesquisador-de-seguranca-aut/</link><pubDate>Fri, 31 Oct 2025 18:57:22 -0300</pubDate><guid>https://brdefense.center/news/openai-lanca-aardvark-pesquisador-de-seguranca-aut/</guid><description>&lt;p>A OpenAI anunciou o lançamento do Aardvark, um pesquisador de segurança autônomo alimentado pelo modelo de linguagem GPT-5. Este agente de inteligência artificial foi projetado para ajudar desenvolvedores e equipes de segurança a identificar e corrigir vulnerabilidades em código de forma escalável. Atualmente em beta privada, o Aardvark analisa repositórios de código-fonte continuamente, identificando vulnerabilidades, avaliando sua explorabilidade e propondo correções. O modelo GPT-5, introduzido em agosto de 2025, oferece capacidades de raciocínio mais profundas e um &amp;lsquo;roteador em tempo real&amp;rsquo; para otimizar a interação com os usuários.&lt;/p></description></item><item><title>Google Introduz Proteção com IA no Android Contra Golpes Móveis</title><link>https://brdefense.center/news/google-introduz-protecao-com-ia-no-android-contra/</link><pubDate>Fri, 31 Oct 2025 12:59:41 -0300</pubDate><guid>https://brdefense.center/news/google-introduz-protecao-com-ia-no-android-contra/</guid><description>&lt;p>Em resposta à crescente ameaça de golpes móveis, a Google anunciou melhorias significativas na proteção do Android, utilizando inteligência artificial para combater fraudes. Em um relatório divulgado em 30 de outubro de 2025, a empresa destacou que suas defesas baseadas em IA superam as de outras plataformas, com um impacto positivo na segurança dos usuários. No último ano, os golpes móveis geraram perdas superiores a 400 bilhões de dólares globalmente. O sistema do Android processa mensalmente mais de 10 bilhões de chamadas e mensagens suspeitas, bloqueando mais de 100 milhões de números fraudulentos recentemente. A pesquisa realizada pela YouGov, envolvendo 5.000 usuários nos EUA, Índia e Brasil, revelou que usuários do Android, especialmente os do Google Pixel, relataram menos mensagens de golpe em comparação aos usuários do iOS. Além disso, a análise de segurança da Leviathan Security Group confirmou que o Pixel 10 Pro oferece a melhor proteção contra fraudes. As funcionalidades incluem filtragem automática de spam e detecção de padrões de conversação fraudulentos, garantindo a privacidade dos usuários. Com atualizações contínuas através do Google Play Protect, o Android se mantém à frente das ameaças móveis em constante evolução.&lt;/p></description></item><item><title>Brasil lidera ranking mundial de fraudes digitais</title><link>https://brdefense.center/news/brasil-lidera-ranking-mundial-de-fraudes-digitais/</link><pubDate>Thu, 30 Oct 2025 18:59:49 -0300</pubDate><guid>https://brdefense.center/news/brasil-lidera-ranking-mundial-de-fraudes-digitais/</guid><description>&lt;p>O Brasil ocupa a primeira posição no ranking global de vítimas de fraudes digitais, segundo o Índice de Fraude 2025, elaborado pela Veriff. A pesquisa revela que os brasileiros enfrentam ataques online cinco vezes mais do que cidadãos dos Estados Unidos e do Reino Unido. Aproximadamente 26% dos entrevistados no Brasil relataram ter sido vítimas de fraudes nos últimos doze meses, enquanto as taxas nos EUA e Reino Unido são de 15% e 10%, respectivamente. O impacto financeiro é alarmante, com quase 40% dos brasileiros perdendo até R$ 1.300 em golpes, e 5% relatando perdas superiores a R$ 26 mil em um único incidente. A pesquisa também destaca o papel crescente da inteligência artificial (IA) e dos deepfakes, que contribuíram para um aumento de 21% nas fraudes digitais em comparação ao ano anterior. Quase metade dos entrevistados expressou preocupação com o uso de IA em golpes, refletindo um clima de insegurança. Apesar disso, os brasileiros demonstram maior disposição para adotar sistemas de proteção digital em comparação à média global, indicando uma conscientização crescente sobre a segurança online.&lt;/p></description></item><item><title>Simulação de Brechas A Nova Fronteira da Cibersegurança</title><link>https://brdefense.center/news/simulacao-de-brechas-a-nova-fronteira-da-cibersegu/</link><pubDate>Thu, 30 Oct 2025 12:58:54 -0300</pubDate><guid>https://brdefense.center/news/simulacao-de-brechas-a-nova-fronteira-da-cibersegu/</guid><description>&lt;p>O Picus Breach and Simulation (BAS) Summit deste ano destacou uma mudança significativa na abordagem da cibersegurança, enfatizando que a defesa não se trata mais de prever ataques, mas de provar a eficácia das defesas existentes. Com a velocidade com que novos exploits surgem e se espalham, a necessidade de testar controles em tempo real se torna crucial. O BAS evoluiu de uma atividade anual de conformidade para uma prática diária que valida se as defesas estão realmente funcionando. A simulação de comportamentos adversariais em ambientes controlados permite que as equipes de segurança entendam como suas defesas reagem a ataques, focando em resultados e não apenas em inventários de vulnerabilidades. Além disso, a integração da inteligência artificial no processo de cibersegurança se mostrou mais eficaz na organização de dados do que na criação de novos, permitindo uma resposta mais rápida e precisa a ameaças. O evento também evidenciou que a validação contínua das defesas pode transformar a abordagem de &amp;lsquo;corrigir tudo&amp;rsquo; para &amp;lsquo;corrigir o que realmente importa&amp;rsquo;, priorizando as vulnerabilidades que representam riscos reais. Essa mudança de paradigma é essencial para que as organizações se mantenham à frente das ameaças cibernéticas.&lt;/p></description></item><item><title>Avanço da IA desafia empresas com aumento de fraudes corporativas</title><link>https://brdefense.center/news/avanco-da-ia-desafia-empresas-com-aumento-de-fraud/</link><pubDate>Wed, 29 Oct 2025 18:58:37 -0300</pubDate><guid>https://brdefense.center/news/avanco-da-ia-desafia-empresas-com-aumento-de-fraud/</guid><description>&lt;p>O uso crescente da inteligência artificial (IA) no ambiente corporativo trouxe não apenas otimizações, mas também um aumento alarmante nas fraudes. Um levantamento da plataforma AppZen revelou que, em setembro de 2025, cerca de 14% dos documentos falsos foram gerados com a ajuda da IA, um aumento significativo em relação a 2024, quando essas fraudes eram raras. Os esquemas mais comuns incluem a criação de notas fiscais e comprovantes falsos, tornando a detecção desses golpes cada vez mais desafiadora. A fintech Ramp, por exemplo, bloqueou mais de US$ 1 milhão em notas suspeitas nos últimos três meses. Especialistas, como Fernando Nery, CEO da fintech Portão 3, alertam que a sofisticação das fraudes exige que as empresas invistam em mecanismos de verificação inteligente e cruzamento de dados em tempo real para aumentar a confiança na detecção de documentos falsificados. A situação exige uma reavaliação das práticas de controle financeiro, uma vez que o risco não se limita mais à falta de processos, mas à capacidade de identificar falsificações quase perfeitas geradas por IA.&lt;/p></description></item><item><title>Inteligência Artificial e sua Transformação no GRC</title><link>https://brdefense.center/news/inteligencia-artificial-e-sua-transformacao-no-grc/</link><pubDate>Wed, 29 Oct 2025 13:02:06 -0300</pubDate><guid>https://brdefense.center/news/inteligencia-artificial-e-sua-transformacao-no-grc/</guid><description>&lt;p>A Inteligência Artificial (IA) está revolucionando a Governança, Risco e Conformidade (GRC), trazendo mudanças significativas na forma como as equipes operam. As capacidades da IA incluem acelerar auditorias, identificar riscos críticos rapidamente e reduzir o trabalho manual, resultando em maior eficiência e precisão. No entanto, essa transformação também apresenta novos desafios, como viés potencial, lacunas regulatórias e pontos cegos perigosos, que ainda estão sendo abordados por órgãos reguladores. Para ajudar as organizações a se adaptarem a esse novo cenário, será realizado um webinar gratuito intitulado &amp;lsquo;O Futuro da IA no GRC: Oportunidades, Riscos e Insights Práticos&amp;rsquo;. O evento abordará exemplos reais de como a IA melhora fluxos de trabalho de conformidade, lições aprendidas e melhores práticas, além de estratégias para identificar e mitigar riscos comuns. A velocidade da inovação em IA é impressionante, e a lacuna entre a capacidade tecnológica e o arcabouço legal representa uma exposição imediata ao risco. O webinar reunirá especialistas e exemplos práticos, permitindo que as organizações se preparem proativamente para os desafios que a IA traz ao GRC.&lt;/p></description></item><item><title>Nova vulnerabilidade em navegadores expõe modelos de IA a ataques</title><link>https://brdefense.center/news/nova-vulnerabilidade-em-navegadores-expoe-modelos/</link><pubDate>Wed, 29 Oct 2025 13:01:44 -0300</pubDate><guid>https://brdefense.center/news/nova-vulnerabilidade-em-navegadores-expoe-modelos/</guid><description>&lt;p>Pesquisadores em cibersegurança identificaram uma nova vulnerabilidade em navegadores web que utilizam inteligência artificial, como o OpenAI ChatGPT Atlas. O problema, denominado &amp;lsquo;cloaking direcionado a IA&amp;rsquo;, permite que atacantes manipulem o conteúdo exibido para crawlers de IA, expondo-os a ataques de envenenamento de contexto. A técnica, semelhante ao cloaking de motores de busca, utiliza uma verificação simples do agente do usuário para entregar conteúdo diferente para humanos e sistemas de IA. Isso pode distorcer a percepção de autoridade e verdade, afetando milhões de usuários. A empresa SPLX, que divulgou a vulnerabilidade, alerta que essa manipulação pode ser uma arma poderosa de desinformação, comprometendo a confiança nas ferramentas de IA. Além disso, um estudo da hCaptcha Threat Analysis Group revelou que muitos navegadores tentaram executar ações maliciosas sem necessidade de jailbreak, indicando uma falta de salvaguardas adequadas. Isso levanta preocupações sobre a segurança de sistemas que dependem de IA, especialmente em um cenário onde a otimização para IA se torna cada vez mais comum.&lt;/p></description></item><item><title>Quando malware de IA encontra DDoS um novo desafio para a resiliência online</title><link>https://brdefense.center/news/quando-malware-de-ia-encontra-ddos-um-novo-desafio/</link><pubDate>Wed, 29 Oct 2025 07:02:09 -0300</pubDate><guid>https://brdefense.center/news/quando-malware-de-ia-encontra-ddos-um-novo-desafio/</guid><description>&lt;p>O uso de inteligência artificial (IA) no cibercrime está crescendo rapidamente, com 80% dos ataques de ransomware em 2023-2024 utilizando essa tecnologia. Ferramentas como GhostGPT e AkiraBot estão permitindo que cibercriminosos criem códigos maliciosos, elaborem e-mails de phishing e contornem CAPTCHAs. A evolução dos ataques DDoS, especialmente os de camada de aplicação, se torna mais complexa, pois a IA pode mimetizar o comportamento humano, dificultando a identificação de bots. A proteção tradicional, baseada em CAPTCHAs, já não é eficaz. Em resposta, a filtragem baseada em intenção surge como uma alternativa, avaliando o comportamento do usuário em vez de tentar distinguir humanos de máquinas. As empresas precisam investir em plataformas de mitigação de DDoS que suportem essa nova abordagem e implementar monitoramento em múltiplas camadas para detectar anomalias. A falta de soluções adequadas entre os provedores de segurança gerencia um risco significativo, especialmente para grandes empresas, que podem sofrer danos reputacionais e financeiros severos em caso de ataques bem-sucedidos.&lt;/p></description></item><item><title>IA generativa permite falsificação perfeita de documentos, alerta especialista</title><link>https://brdefense.center/news/ia-generativa-permite-falsificacao-perfeita-de-doc/</link><pubDate>Tue, 28 Oct 2025 19:00:50 -0300</pubDate><guid>https://brdefense.center/news/ia-generativa-permite-falsificacao-perfeita-de-doc/</guid><description>&lt;p>Durante o Cyber Security Summit 2025, o especialista em cibersegurança Andrew Bindner alertou sobre os riscos da inteligência artificial generativa na falsificação de documentos. Ele destacou que qualquer pessoa com acesso a ferramentas de IA pode criar documentos falsos, como carteiras de identidade e passaportes, que são visualmente perfeitos. Essa facilidade de criação de documentos falsificados representa uma ameaça significativa à segurança global, pois torna mais difícil a detecção de fraudes e espionagem. Bindner enfatizou a necessidade de educação cibernética e cooperação internacional para fortalecer a confiança no ambiente digital. Vitor Garcia, da Embraer, complementou que a IA não é apenas uma ameaça, mas também pode ser utilizada como uma ferramenta de defesa contra crimes digitais. A discussão levantou a importância de um esforço conjunto entre empresas e governos para mitigar os riscos associados ao uso malicioso da IA, que pode automatizar crimes digitais e comprometer a segurança das identidades digitais.&lt;/p></description></item><item><title>A Crise Silenciosa da Segurança em Inteligência Artificial</title><link>https://brdefense.center/news/a-crise-silenciosa-da-seguranca-em-inteligencia-ar/</link><pubDate>Thu, 23 Oct 2025 12:58:58 -0300</pubDate><guid>https://brdefense.center/news/a-crise-silenciosa-da-seguranca-em-inteligencia-ar/</guid><description>&lt;p>O uso crescente de inteligência artificial (IA) nas empresas traz benefícios como produtos mais rápidos e sistemas mais inteligentes, mas também levanta preocupações significativas em relação à segurança. Atualmente, estima-se que existam 100 agentes de IA para cada funcionário humano, e alarmantes 99% desses agentes estão completamente não gerenciados, sem supervisão ou controles de ciclo de vida. Isso representa um risco real, pois cada um desses agentes pode se tornar uma porta dos fundos para invasões. O artigo destaca a necessidade urgente de adaptar as ferramentas de segurança tradicionais para lidar com esse novo cenário. Um webinar gratuito intitulado &amp;lsquo;Transformando Controles em Aceleradores da Adoção de IA&amp;rsquo; promete oferecer estratégias práticas para que as empresas possam implementar segurança desde o início, em vez de como uma reflexão tardia. Os participantes aprenderão a governar agentes de IA, a evitar a proliferação de credenciais e a alinhar a segurança com os objetivos de negócios, permitindo que a segurança não seja um obstáculo, mas sim um facilitador da adoção de IA. Essa abordagem é essencial para que engenheiros, arquitetos e CISOs possam deixar de atuar de forma reativa e passar a ter controle e confiança em suas operações de segurança.&lt;/p></description></item><item><title>Ciberataques e espionagem internacional são impulsionados por IA generativa</title><link>https://brdefense.center/news/ciberataques-e-espionagem-internacional-sao-impuls/</link><pubDate>Wed, 22 Oct 2025 13:03:09 -0300</pubDate><guid>https://brdefense.center/news/ciberataques-e-espionagem-internacional-sao-impuls/</guid><description>&lt;p>Um relatório da Microsoft revelou que, entre janeiro e julho de 2025, mais de 200 casos de hackers estrangeiros utilizaram inteligência artificial (IA) para criar e disseminar conteúdo falso e realizar ataques diretos a governos. Este número representa um aumento significativo em relação aos anos anteriores, com mais do que o dobro de casos registrados em 2024 e mais de dez vezes em comparação a 2023. Os cibercriminosos estão utilizando IA para automatizar ataques, como a tradução de e-mails de phishing, tornando-os mais convincentes e difíceis de identificar. Além disso, a criação de clones digitais de altos funcionários governamentais tem sofisticado as táticas de engenharia social, visando a obtenção de dados confidenciais e a desestabilização de serviços essenciais. A vice-presidente de Segurança e Confiança do Cliente da Microsoft, Amy Hogan-Buney, destacou que os EUA são o país mais visado, seguido por Israel e Ucrânia. Apesar das evidências, países como Rússia e China negam envolvimento em operações cibernéticas de espionagem. A Coreia do Norte, por sua vez, tem utilizado IA para criar identidades falsas, permitindo acesso a segredos comerciais e a instalação de malwares em empresas de tecnologia.&lt;/p></description></item><item><title>Inteligência Artificial e Segurança Cibernética Desafios e Oportunidades</title><link>https://brdefense.center/news/inteligencia-artificial-e-seguranca-cibernetica-de/</link><pubDate>Tue, 21 Oct 2025 12:59:48 -0300</pubDate><guid>https://brdefense.center/news/inteligencia-artificial-e-seguranca-cibernetica-de/</guid><description>&lt;p>A inteligência artificial (IA) tem um grande potencial para aprimorar a defesa cibernética, facilitando o trabalho dos profissionais de segurança. Ela pode ajudar a reduzir a fadiga de alertas, identificar padrões rapidamente e escalar operações de segurança de forma que os analistas humanos não conseguem. No entanto, a adoção de IA também amplia a superfície de ataque das organizações, exigindo governança clara, controles de identidade robustos e visibilidade nas decisões tomadas pela IA. Para garantir a segurança, é fundamental estabelecer confiança nos dados que a IA utiliza, responsabilidade pelas ações que executa e supervisão dos resultados que produz. O artigo destaca a importância de tratar sistemas de IA como identidades críticas dentro do gerenciamento de identidade e acesso (IAM), aplicando controles rigorosos como credenciais limitadas, autenticação forte e monitoramento contínuo. Além disso, sugere práticas recomendadas para proteger modelos de IA, incluindo controles de acesso, validação de dados e segurança na inferência. A integração responsável da IA nas operações de segurança pode permitir que as equipes trabalhem de maneira mais inteligente e eficaz, mas é essencial encontrar um equilíbrio entre automação e supervisão humana.&lt;/p></description></item><item><title>Cibercrime movimenta US 10 trilhões dados sobre IA e segurança</title><link>https://brdefense.center/news/cibercrime-movimenta-us-10-trilhoes-dados-sobre-ia/</link><pubDate>Tue, 21 Oct 2025 00:59:25 -0300</pubDate><guid>https://brdefense.center/news/cibercrime-movimenta-us-10-trilhoes-dados-sobre-ia/</guid><description>&lt;p>O avanço da inteligência artificial generativa tem transformado o cibercrime em uma economia paralela que movimenta anualmente cerca de US$ 10 trilhões, segundo Tania Cosentino, ex-presidente da Microsoft Brasil. Durante sua apresentação no CRM Zummit 2025, Cosentino destacou que a combinação de novas tecnologias, como a migração para a nuvem e o trabalho remoto, ampliou a superfície de ataque, tornando as empresas mais vulneráveis. Os hackers utilizam IA para aumentar a velocidade e a sofisticação de seus ataques, resultando em ameaças complexas, como ransomware e ataques a cadeias de suprimento. O tempo de resposta dos atacantes é alarmante, com a média de apenas 1 hora e 12 minutos para se mover lateralmente dentro de uma rede após o acesso inicial. O Brasil é um dos países mais atacados, especialmente em ransomware, devido à percepção de que os resgates são frequentemente pagos. Além disso, a falta de profissionais qualificados em cibersegurança e a disparidade entre regiões do país agravam a situação. A segurança cibernética não é apenas uma questão técnica, mas também um diferencial competitivo, pois 69% dos consumidores evitam empresas percebidas como inseguras.&lt;/p></description></item><item><title>63 dos consumidores brasileiros não conseguem identificar golpes com IA</title><link>https://brdefense.center/news/63-dos-consumidores-brasileiros-nao-conseguem-iden/</link><pubDate>Mon, 20 Oct 2025 13:00:03 -0300</pubDate><guid>https://brdefense.center/news/63-dos-consumidores-brasileiros-nao-conseguem-iden/</guid><description>&lt;p>Uma pesquisa realizada pelo Reclame AQUI revelou que 63% dos consumidores brasileiros não conseguem identificar golpes digitais que utilizam inteligência artificial (IA), uma vulnerabilidade preocupante especialmente com a aproximação da Black Friday. O estudo, que ouviu mais de 3.300 pessoas, destaca que 79% dos entrevistados planejam comprar online durante a Black Friday, mas apenas 43% verificam links e ofertas com ferramentas de segurança. A pesquisa também aponta que 20% dos consumidores já foram vítimas de fraudes em edições anteriores do evento. O uso crescente de IA por cibercriminosos para criar campanhas de phishing mais sofisticadas torna essencial que os consumidores estejam informados e preparados. O relatório, intitulado &amp;ldquo;Black Friday na era da Inteligência Artificial&amp;rdquo;, serve como um guia tanto para consumidores quanto para marcas, enfatizando a importância da segurança nas compras online.&lt;/p></description></item><item><title>Risco zero não existe alívio para quem precisa decidir</title><link>https://brdefense.center/news/risco-zero-nao-existe-alivio-para-quem-precisa-dec/</link><pubDate>Wed, 15 Oct 2025 18:59:48 -0300</pubDate><guid>https://brdefense.center/news/risco-zero-nao-existe-alivio-para-quem-precisa-dec/</guid><description>&lt;p>O artigo de Arthur Capella discute a crescente complexidade da cibersegurança em um ambiente de trabalho distribuído e digitalizado, onde a migração para a nuvem e a adoção de inteligência artificial (IA) aumentam tanto o valor quanto o risco. A superfície de ataque se expandiu mais rapidamente do que a capacidade das empresas de medir e responder a essas ameaças. A gestão de exposição é apresentada como uma disciplina estratégica, essencial para priorizar riscos com base no impacto nos negócios, em vez de se concentrar apenas em uma lista de vulnerabilidades. O autor destaca a escassez de profissionais qualificados em cibersegurança e a limitação orçamentária como desafios constantes. Além disso, enfatiza que apenas 3% das vulnerabilidades frequentemente resultam em riscos significativos, tornando a priorização crucial. O artigo conclui que, em vez de tentar eliminar todos os riscos, as empresas devem focar em fechar as portas que realmente importam, equilibrando inovação e segurança.&lt;/p></description></item><item><title>Como a IA está transformando a segurança cibernética</title><link>https://brdefense.center/news/como-a-ia-esta-transformando-a-seguranca-ciberneti/</link><pubDate>Tue, 14 Oct 2025 12:59:24 -0300</pubDate><guid>https://brdefense.center/news/como-a-ia-esta-transformando-a-seguranca-ciberneti/</guid><description>&lt;p>O uso crescente da inteligência artificial (IA) está revolucionando a forma como os atacantes realizam a fase de reconhecimento em cibersegurança. Antes de enviar um ataque, os hackers analisam minuciosamente o ambiente da vítima, explorando fluxos de login, arquivos JavaScript, mensagens de erro e documentação de APIs. A IA acelera esse processo, permitindo que os atacantes mapeiem sistemas com maior rapidez e precisão. Embora a IA não execute ataques de forma autônoma, ela otimiza a coleta e análise de informações, ajudando a identificar vulnerabilidades e caminhos de ataque.&lt;/p></description></item><item><title>Ataques cibernéticos em evolução vulnerabilidades e ameaças emergentes</title><link>https://brdefense.center/news/ataques-ciberneticos-em-evolucao-vulnerabilidades/</link><pubDate>Mon, 13 Oct 2025 12:59:04 -0300</pubDate><guid>https://brdefense.center/news/ataques-ciberneticos-em-evolucao-vulnerabilidades/</guid><description>&lt;p>O cenário de cibersegurança continua a se deteriorar, com ataques cada vez mais sofisticados e coordenados. Um dos principais incidentes recentes envolve a exploração de uma falha crítica no Oracle E-Business Suite, afetando diversas organizações desde agosto de 2025. A falha, identificada como CVE-2025-61882, possui uma pontuação CVSS de 9.8 e foi utilizada por grupos como o Cl0p para exfiltrar dados sensíveis. Além disso, o grupo Storm-1175 explorou uma vulnerabilidade no GoAnywhere MFT, resultando em ataques em setores variados, como transporte e educação.&lt;/p></description></item><item><title>Hackers russos usam inteligência artificial em ataques cibernéticos na Ucrânia</title><link>https://brdefense.center/news/hackers-russos-usam-inteligencia-artificial-em-ata/</link><pubDate>Thu, 09 Oct 2025 06:57:47 -0300</pubDate><guid>https://brdefense.center/news/hackers-russos-usam-inteligencia-artificial-em-ata/</guid><description>&lt;p>No primeiro semestre de 2025, hackers russos intensificaram o uso de inteligência artificial (IA) em ataques cibernéticos contra a Ucrânia, conforme relatado pelo Serviço Estatal de Comunicações Especiais e Proteção da Informação (SSSCIP). A agência registrou 3.018 incidentes cibernéticos, um aumento em relação aos 2.575 do segundo semestre de 2024. Os ataques incluem campanhas de phishing e o uso de malware gerado por IA, como o WRECKSTEEL, que visa a administração estatal e infraestrutura crítica. Além disso, grupos como UAC-0218 e UAC-0226 têm direcionado suas ações a forças de defesa e órgãos governamentais, utilizando táticas sofisticadas como arquivos RAR armadilhados e técnicas de engenharia social. O SSSCIP também observou a exploração de vulnerabilidades em softwares de webmail, permitindo ataques sem interação do usuário. A utilização de serviços legítimos como Dropbox e Google Drive para hospedar malware também tem crescido, evidenciando a adaptação dos atacantes às tecnologias disponíveis. O cenário de guerra híbrida se intensifica, com operações cibernéticas sincronizadas a ataques físicos no campo de batalha.&lt;/p></description></item><item><title>Da exaustão à superação fotógrafos recuperam tempo perdido com IA</title><link>https://brdefense.center/news/da-exaustao-a-superacao-fotografos-recuperam-tempo/</link><pubDate>Wed, 08 Oct 2025 19:01:18 -0300</pubDate><guid>https://brdefense.center/news/da-exaustao-a-superacao-fotografos-recuperam-tempo/</guid><description>&lt;p>A indústria da fotografia está passando por uma transformação significativa com a adoção de ferramentas de inteligência artificial (IA), conforme revelado no relatório Aftershoot Photography Workflow Report de 2025. Com base em respostas de mais de 1.000 fotógrafos profissionais globalmente, o estudo indica que 81% dos entrevistados que implementaram fluxos de trabalho baseados em IA melhoraram seu equilíbrio entre vida profissional e pessoal, recuperando tempo anteriormente perdido em edições repetitivas. Um dado impressionante é que 64% dos fotógrafos afirmaram que seus clientes não perceberam diferença entre imagens editadas por IA e aquelas editadas manualmente. Essa mudança de percepção está redefinindo o que significa ter um negócio criativo sustentável, permitindo que os profissionais se concentrem em crescimento pessoal e bem-estar mental. Além disso, 28% dos fotógrafos agora conseguem entregar galerias completas em menos de uma semana, o que representa o dobro da taxa de 2024. A automação não apenas aumenta a produtividade, mas também redefine o tempo criativo, permitindo que os fotógrafos se concentrem em projetos pessoais e desenvolvimento de habilidades. A pesquisa sugere que a IA não substitui a criatividade, mas a amplifica, ajudando os fotógrafos a atender às expectativas de entrega rápida e qualidade consistente.&lt;/p></description></item><item><title>As 10 Melhores Empresas de Prevenção à Fraude em 2025</title><link>https://brdefense.center/news/as-10-melhores-empresas-de-prevencao-a-fraude-em-2/</link><pubDate>Wed, 08 Oct 2025 18:59:53 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-empresas-de-prevencao-a-fraude-em-2/</guid><description>&lt;p>A prevenção de fraudes é uma prioridade crítica para empresas de todos os tamanhos em 2025, à medida que os cibercriminosos evoluem suas táticas e exploram novas vulnerabilidades. Proteger dados sensíveis, garantir a segurança das transações e manter a confiança do cliente são essenciais no cenário digital atual. Este artigo apresenta as dez melhores empresas de prevenção à fraude de 2025, selecionadas com base em suas tecnologias avançadas, soluções abrangentes e sucesso comprovado no combate à fraude. As empresas listadas utilizam inteligência artificial, aprendizado de máquina, biometria comportamental e análises em tempo real para detectar e prevenir atividades fraudulentas de forma rápida e precisa. As soluções não apenas protegem as empresas contra perdas financeiras, mas também ajudam a manter a conformidade com as regulamentações em evolução e a preservar a reputação da marca. A escolha da melhor empresa de prevenção à fraude permite que as organizações se mantenham à frente das tendências de fraude e protejam suas operações de forma eficaz, reduzindo falsos positivos e otimizando fluxos de trabalho de fraude, melhorando a experiência do cliente.&lt;/p></description></item><item><title>As 10 Melhores Empresas de Segurança em Inteligência de Cadeia de Suprimentos em 2025</title><link>https://brdefense.center/news/as-10-melhores-empresas-de-seguranca-em-inteligenc/</link><pubDate>Wed, 08 Oct 2025 18:59:34 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-empresas-de-seguranca-em-inteligenc/</guid><description>&lt;p>No contexto atual da economia global interconectada, a segurança das cadeias de suprimentos se tornou uma prioridade crítica para empresas em todo o mundo. O aumento de ciberataques, vazamentos de dados e interrupções geopolíticas ameaça a estabilidade das cadeias de suprimentos e a continuidade dos negócios. Para enfrentar esses riscos, empresas especializadas em segurança de inteligência de cadeia de suprimentos utilizam tecnologias avançadas como inteligência artificial (IA), aprendizado de máquina, inteligência de ameaças e análises de risco. Essas soluções permitem que as organizações identifiquem proativamente vulnerabilidades, monitorem fornecedores e mitiguem ameaças em tempo real. O artigo apresenta uma análise das dez melhores empresas de segurança em inteligência de cadeia de suprimentos em 2025, avaliando-as com base em critérios como especificações, recursos, razões para compra, prós e contras. A lista destaca empresas que se destacam em precisão, capacidade de integração e insights acionáveis, ajudando os gestores de risco a responder rapidamente e reduzir potenciais interrupções ou violações na cadeia de suprimentos.&lt;/p></description></item><item><title>Top 10 Melhores Soluções de Proteção de Marca para Empresas em 2025</title><link>https://brdefense.center/news/top-10-melhores-solucoes-de-protecao-de-marca-para/</link><pubDate>Wed, 08 Oct 2025 13:00:53 -0300</pubDate><guid>https://brdefense.center/news/top-10-melhores-solucoes-de-protecao-de-marca-para/</guid><description>&lt;p>Em 2025, com o aumento sem precedentes de riscos digitais, como falsificações, phishing e roubo de propriedade intelectual, as empresas precisam de soluções rigorosas de proteção de marca. O artigo apresenta as 10 melhores soluções de proteção de marca, destacando suas forças, especificações e razões para aquisição. As soluções modernas combinam automação, inteligência artificial e expertise humana para monitorar ativos digitais e proteger a confiança da marca em escala global. Entre as principais soluções estão Red Points, BrandShield e MarkMonitor, cada uma oferecendo recursos como detecção automatizada, cobertura multicanal e análises impulsionadas por IA. A escolha da solução certa é crucial para que as marcas operem com confiança e inovem de forma segura, especialmente em um cenário onde a proteção vai além da segurança tradicional.&lt;/p></description></item><item><title>As 10 Melhores Plataformas de Proteção Digital em 2025</title><link>https://brdefense.center/news/as-10-melhores-plataformas-de-protecao-digital-em/</link><pubDate>Wed, 08 Oct 2025 06:59:27 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-plataformas-de-protecao-digital-em/</guid><description>&lt;p>Com a crescente digitalização das empresas, a superfície de ataque a ameaças cibernéticas também se expande. As plataformas de Proteção de Risco Digital (DRP) são essenciais para detectar, monitorar e mitigar ameaças externas, garantindo uma defesa proativa. Em 2025, as principais plataformas de DRP incorporaram automação, análises impulsionadas por inteligência artificial e integração de informações. As organizações não podem mais depender apenas de ferramentas tradicionais de cibersegurança, como firewalls. As dez melhores plataformas de DRP oferecem monitoramento em tempo real, enriquecimento de inteligência sobre ameaças e integração de resposta a incidentes. A escolha da plataforma certa pode ser a diferença entre antecipar-se a ataques ou reagir tarde demais, resultando em danos à marca e perdas financeiras. Entre as principais plataformas destacam-se Proofpoint, ReliaQuest e BlueVoyant Sky, cada uma com características únicas que atendem a diferentes necessidades de segurança, especialmente para grandes empresas e instituições financeiras. A adoção dessas tecnologias é crucial para proteger a reputação e os ativos digitais das organizações frente a ameaças emergentes.&lt;/p></description></item><item><title>OpenAI desmantela grupos que usavam ChatGPT para desenvolver malware</title><link>https://brdefense.center/news/openai-desmantela-grupos-que-usavam-chatgpt-para-d/</link><pubDate>Wed, 08 Oct 2025 06:58:40 -0300</pubDate><guid>https://brdefense.center/news/openai-desmantela-grupos-que-usavam-chatgpt-para-d/</guid><description>&lt;p>No dia 8 de outubro de 2025, a OpenAI anunciou a interrupção de três grupos de atividade que estavam utilizando sua ferramenta de inteligência artificial, o ChatGPT, para facilitar o desenvolvimento de malware. Um dos grupos, de língua russa, usou o chatbot para criar e aprimorar um trojan de acesso remoto (RAT) e um ladrão de credenciais, buscando evitar a detecção. A OpenAI observou que esses usuários estavam associados a grupos criminosos que compartilhavam evidências de suas atividades em canais do Telegram. Embora os modelos de linguagem da OpenAI tenham se recusado a atender a pedidos diretos para criar conteúdo malicioso, os criminosos contornaram essa limitação, gerando códigos que foram montados para criar fluxos de trabalho maliciosos. Outro grupo, da Coreia do Norte, utilizou o ChatGPT para desenvolver malware e ferramentas de comando e controle, enquanto um terceiro grupo, da China, focou em campanhas de phishing. Além disso, a OpenAI bloqueou contas que estavam envolvidas em fraudes e operações de influência, incluindo atividades de vigilância ligadas a entidades governamentais chinesas. A empresa destacou que os atores de ameaça estão se adaptando para ocultar sinais de que o conteúdo foi gerado por uma ferramenta de IA, o que representa um novo desafio para a segurança cibernética.&lt;/p></description></item><item><title>A Inteligência Artificial e a Evolução da Cibersegurança</title><link>https://brdefense.center/news/a-inteligencia-artificial-e-a-evolucao-da-ciberseg/</link><pubDate>Wed, 08 Oct 2025 06:58:20 -0300</pubDate><guid>https://brdefense.center/news/a-inteligencia-artificial-e-a-evolucao-da-ciberseg/</guid><description>&lt;p>A inteligência artificial (IA) está transformando o cenário da cibersegurança, tanto para atacantes quanto para defensores. Os cibercriminosos utilizam ferramentas baseadas em IA para automatizar e acelerar ataques, criando um desafio sem precedentes para as equipes de segurança, que enfrentam uma avalanche de dados sobre vulnerabilidades e alertas. Apesar do potencial da IA, muitas empresas ainda têm dificuldades em integrá-la efetivamente em suas estratégias de segurança. O artigo destaca três áreas principais onde a IA pode ser aplicada para maximizar a eficácia: deduplicação e correlação de dados, priorização de riscos e uma camada de inteligência que complementa a análise humana. A deduplicação ajuda a criar uma visão clara dos riscos, enquanto a priorização permite que as equipes concentrem seus esforços nas vulnerabilidades mais críticas. A camada de inteligência fornece recomendações e simulações que capacitam os analistas a tomar decisões mais informadas. Com a crescente utilização de IA pelos atacantes, é imperativo que as organizações adotem essas tecnologias para se manterem à frente. Plataformas como a PlexTrac estão na vanguarda dessa transformação, investindo em capacidades de IA para ajudar as equipes a gerenciar dados de forma centralizada e eficaz.&lt;/p></description></item><item><title>As 10 Melhores Soluções de Gestão de Risco da Cadeia de Suprimentos em 2025</title><link>https://brdefense.center/news/as-10-melhores-solucoes-de-gestao-de-risco-da-cade/</link><pubDate>Tue, 07 Oct 2025 18:59:40 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-solucoes-de-gestao-de-risco-da-cade/</guid><description>&lt;p>A gestão de risco da cadeia de suprimentos (SCRM) se tornou um pilar essencial para empresas que buscam resiliência em 2025. Com a crescente interconexão e fragilidade das cadeias globais, as organizações enfrentam riscos que vão desde conflitos geopolíticos até ciberataques. O artigo destaca as 10 melhores soluções de SCRM, que utilizam análises preditivas, monitoramento em tempo real e insights impulsionados por inteligência artificial para proteger suas redes de suprimentos. Entre as soluções mencionadas, Prewave se destaca por sua capacidade de detectar riscos em tempo real e monitorar a conformidade ESG, enquanto Resilinc oferece visibilidade em múltiplos níveis da cadeia de suprimentos, essencial para setores como tecnologia e saúde. Sphera é reconhecida por sua forte ênfase em gestão de riscos ambientais e de sustentabilidade. A escolha da solução adequada pode melhorar significativamente a visibilidade, mitigar riscos e fortalecer o desempenho dos fornecedores, tornando-se crucial para a competitividade das empresas no cenário atual.&lt;/p></description></item><item><title>A Inteligência Artificial e o Risco de Vazamento de Dados Corporativos</title><link>https://brdefense.center/news/a-inteligencia-artificial-e-o-risco-de-vazamento-d/</link><pubDate>Tue, 07 Oct 2025 12:59:10 -0300</pubDate><guid>https://brdefense.center/news/a-inteligencia-artificial-e-o-risco-de-vazamento-d/</guid><description>&lt;p>Um novo relatório da LayerX revela que a inteligência artificial (IA) se tornou o maior canal não controlado para a exfiltração de dados corporativos, superando ferramentas de SaaS não gerenciadas e compartilhamento de arquivos. Com 45% dos funcionários de empresas utilizando ferramentas de IA generativa, como ChatGPT, a falta de governança é alarmante, pois 67% do uso ocorre em contas pessoais não gerenciadas. O estudo aponta que 40% dos arquivos enviados para ferramentas de IA contêm dados sensíveis, e 77% dos funcionários colam informações nessas plataformas, com 82% dessas ações originando de contas não gerenciadas. A segurança tradicional, focada em uploads de arquivos, ignora esses vetores de vazamento. Além disso, 87% do uso de mensagens instantâneas ocorre em contas não gerenciadas, criando um cenário de risco elevado. O relatório recomenda que a segurança da IA seja tratada como uma categoria essencial, com estratégias de governança que incluam monitoramento de uploads e restrições a contas pessoais. Para os líderes de segurança, a urgência em adaptar as políticas de segurança é clara, pois a IA já está integrada aos fluxos de trabalho e representa um vetor principal para a perda de dados corporativos.&lt;/p></description></item><item><title>Google DeepMind lança agente de IA para corrigir vulnerabilidades de código</title><link>https://brdefense.center/news/google-deepmind-lanca-agente-de-ia-para-corrigir-v/</link><pubDate>Tue, 07 Oct 2025 12:58:45 -0300</pubDate><guid>https://brdefense.center/news/google-deepmind-lanca-agente-de-ia-para-corrigir-v/</guid><description>&lt;p>A divisão DeepMind do Google anunciou o lançamento do CodeMender, um agente de inteligência artificial (IA) que detecta, corrige e reescreve automaticamente códigos vulneráveis, visando prevenir futuras explorações. O CodeMender é projetado para ser tanto reativo quanto proativo, corrigindo novas vulnerabilidades assim que são identificadas e reforçando códigos existentes para eliminar classes inteiras de falhas. Nos últimos seis meses, a ferramenta já contribuiu com 72 correções de segurança para projetos de código aberto, incluindo alguns com até 4,5 milhões de linhas de código.&lt;/p></description></item><item><title>Gestão da Segurança em IA Perguntas Cruciais para Escolher Soluções</title><link>https://brdefense.center/news/gestao-da-seguranca-em-ia-perguntas-cruciais-para/</link><pubDate>Mon, 06 Oct 2025 12:59:32 -0300</pubDate><guid>https://brdefense.center/news/gestao-da-seguranca-em-ia-perguntas-cruciais-para/</guid><description>&lt;p>No contexto atual de rápida evolução da inteligência artificial (IA) e das tecnologias em nuvem, as organizações estão cada vez mais adotando medidas de segurança para proteger dados sensíveis e garantir conformidade regulatória. As soluções de AI-SPM (Gestão da Postura de Segurança em IA) têm se destacado como ferramentas essenciais para proteger pipelines de IA e ativos de dados. O artigo destaca cinco perguntas críticas que as empresas devem fazer ao avaliar soluções de AI-SPM. A primeira pergunta aborda a necessidade de visibilidade e controle abrangentes sobre os riscos associados à IA e aos dados. A segunda pergunta foca na capacidade da solução de identificar e remediar riscos específicos da IA, como ataques adversariais e viés em modelos preditivos. A conformidade regulatória é o tema da terceira pergunta, enfatizando a importância de garantir que as soluções atendam a normas como a LGPD e o GDPR. A escalabilidade em arquiteturas dinâmicas de nuvem é discutida na quarta pergunta, enquanto a integração com ferramentas de segurança existentes é abordada na quinta. O artigo conclui ressaltando que a segurança em IA deve ser proativa, permitindo que as organizações inovem com confiança em um ambiente de ameaças em constante evolução.&lt;/p></description></item><item><title>A IA está mudando a automação, mas nem sempre para melhor</title><link>https://brdefense.center/news/a-ia-esta-mudando-a-automacao-mas-nem-sempre-para/</link><pubDate>Wed, 01 Oct 2025 18:58:01 -0300</pubDate><guid>https://brdefense.center/news/a-ia-esta-mudando-a-automacao-mas-nem-sempre-para/</guid><description>&lt;p>A automação impulsionada pela inteligência artificial (IA) está transformando a forma como as organizações operam, mas não sem desafios significativos. O artigo destaca que a busca por automação total pode resultar em sistemas frágeis, onde a intervenção humana excessiva atrasa respostas e a rigidez das regras não se adapta a novas ameaças. Além disso, o uso excessivo de IA pode gerar processos obscuros que comprometem a confiança e a conformidade. Para líderes de cibersegurança e operações, a necessidade de fluxos de trabalho rápidos, confiáveis e auditáveis é crucial. O webinar &amp;lsquo;Workflow Clarity: Where AI Fits in Modern Automation&amp;rsquo;, apresentado por Thomas Kinsella, Co-fundador e Diretor de Clientes da Tines, abordará como as equipes de segurança estão integrando pessoas, regras e agentes de IA de forma intencional para criar fluxos de trabalho eficazes. Os participantes aprenderão a identificar onde a IA é mais útil, como evitar a complexidade desnecessária e garantir a segurança e a auditabilidade dos processos. O evento é voltado para líderes que buscam estratégias práticas para implementar automação que fortaleça as defesas sem criar novos riscos.&lt;/p></description></item><item><title>Malwares se disfarçam de ferramentas de IA para infectar empresas</title><link>https://brdefense.center/news/malwares-se-disfarcam-de-ferramentas-de-ia-para-in/</link><pubDate>Wed, 01 Oct 2025 13:02:33 -0300</pubDate><guid>https://brdefense.center/news/malwares-se-disfarcam-de-ferramentas-de-ia-para-in/</guid><description>&lt;p>Um estudo da Trend Micro revelou que malwares estão se disfarçando como ferramentas de inteligência artificial para infectar empresas em diversas regiões do mundo, incluindo Brasil, Estados Unidos, França e Índia. O malware mais destacado na pesquisa é o EvilAI, que imita softwares legítimos, dificultando a detecção por parte dos usuários. Os alvos principais incluem indústrias, agências governamentais e setores de saúde e tecnologia. Os hackers utilizam certificados válidos de empresas descartáveis para aumentar a credibilidade dos programas maliciosos. Uma vez instalados, esses malwares conseguem extrair dados sensíveis dos navegadores das vítimas e enviá-los para servidores controlados pelos criminosos. A distribuição ocorre por meio de anúncios falsos, sites de venda fraudulentos e manipulação de SEO. A situação é alarmante, pois a popularidade das ferramentas de IA está sendo explorada para enganar usuários, e a criação de mercados de malware na dark web facilita ainda mais esses ataques. Especialistas alertam que a tendência pode se intensificar, exigindo atenção redobrada das empresas em relação à segurança cibernética.&lt;/p></description></item><item><title>Desafios dos SOCs Legados e a Necessidade de Contexto na Cibersegurança</title><link>https://brdefense.center/news/desafios-dos-socs-legados-e-a-necessidade-de-conte/</link><pubDate>Tue, 30 Sep 2025 12:58:26 -0300</pubDate><guid>https://brdefense.center/news/desafios-dos-socs-legados-e-a-necessidade-de-conte/</guid><description>&lt;p>Os Centros de Operações de Segurança (SOCs) enfrentam um desafio crescente com a avalanche de alertas que chegam diariamente, resultando em um cenário caótico onde os analistas lutam para manter o controle. O modelo tradicional, que se baseia em regras e gera alertas sem contexto, muitas vezes resulta em atrasos na identificação de ameaças reais. Para superar essa situação, é essencial adotar uma abordagem que priorize o contexto em vez do caos. Ao normalizar e conectar dados de diferentes fontes, como logs de sistemas de identidade e cargas de trabalho em nuvem, os analistas podem obter uma visão mais clara das atividades suspeitas. Isso transforma tentativas de login em potencial em informações valiosas sobre um possível ataque em andamento.&lt;/p></description></item><item><title>Microsoft expande solução de segurança com novo data lake do Sentinel</title><link>https://brdefense.center/news/microsoft-expande-solucao-de-seguranca-com-novo-da/</link><pubDate>Tue, 30 Sep 2025 12:58:01 -0300</pubDate><guid>https://brdefense.center/news/microsoft-expande-solucao-de-seguranca-com-novo-da/</guid><description>&lt;p>No dia 30 de setembro de 2025, a Microsoft anunciou a expansão de sua solução de gerenciamento de incidentes e eventos de segurança (SIEM), o Sentinel, com a disponibilização geral do Sentinel data lake. Este novo recurso é uma ferramenta nativa da nuvem, projetada para ingerir, gerenciar e analisar dados de segurança, proporcionando melhor visibilidade e análises avançadas. O data lake permite que modelos de inteligência artificial, como o Security Copilot, tenham acesso ao contexto completo necessário para detectar padrões sutis e correlacionar sinais, facilitando a identificação de comportamentos de atacantes e a resposta a incidentes. Além disso, a Microsoft introduziu o Sentinel Graph e o Modelo de Contexto do Protocolo (MCP), que permitem uma orquestração mais eficiente e uma compreensão contextual mais rica dos dados de segurança. A empresa também destacou a importância de proteger plataformas de IA contra ataques de injeção de prompt, anunciando melhorias no Azure AI Foundry para aumentar a segurança dos agentes de IA. Com essas inovações, a Microsoft visa transformar a cibersegurança de um modelo reativo para um preditivo, permitindo que as equipes de segurança respondam mais rapidamente a eventos em larga escala.&lt;/p></description></item><item><title>Vulnerabilidades no assistente de IA Gemini expõem riscos de privacidade</title><link>https://brdefense.center/news/vulnerabilidades-no-assistente-de-ia-gemini-expoem/</link><pubDate>Tue, 30 Sep 2025 12:57:40 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidades-no-assistente-de-ia-gemini-expoem/</guid><description>&lt;p>Pesquisadores de cibersegurança revelaram três vulnerabilidades críticas no assistente de inteligência artificial Gemini do Google, que, se exploradas, poderiam comprometer a privacidade dos usuários e permitir o roubo de dados. As falhas, coletivamente chamadas de &amp;lsquo;Gemini Trifecta&amp;rsquo;, incluem: uma injeção de prompt no Gemini Cloud Assist, que poderia permitir que atacantes manipulassem serviços em nuvem; uma injeção de busca no modelo de Personalização de Busca do Gemini, que poderia vazar informações salvas e dados de localização ao manipular o histórico de busca do Chrome; e uma falha de injeção indireta no Gemini Browsing Tool, que poderia exfiltrar dados do usuário para servidores externos. Após a divulgação responsável, o Google implementou medidas de segurança, como a interrupção da renderização de hyperlinks nas respostas de resumo de logs. A Tenable, empresa de segurança, destacou que a situação evidencia que a IA pode ser utilizada como veículo de ataque, não apenas como alvo, enfatizando a necessidade de visibilidade e controle rigoroso sobre ferramentas de IA em ambientes corporativos.&lt;/p></description></item><item><title>Adoção de IA nas empresas riscos e segurança na cadeia de suprimentos</title><link>https://brdefense.center/news/adocao-de-ia-nas-empresas-riscos-e-seguranca-na-ca/</link><pubDate>Tue, 30 Sep 2025 06:57:13 -0300</pubDate><guid>https://brdefense.center/news/adocao-de-ia-nas-empresas-riscos-e-seguranca-na-ca/</guid><description>&lt;p>A adoção de Inteligência Artificial (IA) nas empresas está em rápida ascensão, com ferramentas de IA generativa sendo integradas a diversas funções, como marketing, desenvolvimento e recursos humanos. Essa transformação traz inovação e eficiência, mas também novos riscos que precisam ser geridos. Entre os principais desafios estão a &amp;rsquo;expansão da IA&amp;rsquo;, onde funcionários utilizam ferramentas sem supervisão de segurança, e as vulnerabilidades na cadeia de suprimentos, que aumentam a superfície de ataque. Além disso, o compartilhamento de dados sensíveis com serviços de IA externos levanta preocupações sobre vazamentos e uso indevido de informações. Para mitigar esses riscos, é necessário um novo paradigma de segurança que inclua descoberta contínua, monitoramento em tempo real e avaliação adaptativa de riscos. A Wing Security se destaca nesse cenário, oferecendo visibilidade e controle sobre a utilização de aplicações de IA, permitindo que as empresas inovem com segurança, reduzindo a exposição a ataques e garantindo conformidade regulatória. Essa abordagem transforma a segurança em um facilitador de negócios, permitindo que as organizações adotem ferramentas de IA de forma responsável e segura.&lt;/p></description></item><item><title>Banalização da privacidade app paga para você vender sua voz para IAs</title><link>https://brdefense.center/news/banalizacao-da-privacidade-app-paga-para-voce-vend/</link><pubDate>Mon, 29 Sep 2025 18:59:41 -0300</pubDate><guid>https://brdefense.center/news/banalizacao-da-privacidade-app-paga-para-voce-vend/</guid><description>&lt;p>O Neon Mobile é um aplicativo que permite aos usuários venderem suas gravações de voz, gerando polêmica sobre privacidade e ética. O app grava ligações telefônicas e paga US$ 0,30 por minuto, com um limite diário de US$ 30. Embora os usuários possam decidir o que fazer com seus dados, a política de privacidade do Neon levanta preocupações sobre o uso e a venda dessas gravações para empresas de inteligência artificial. O app afirma que remove informações pessoais antes de vender os dados, mas não esclarece como os parceiros utilizarão essas gravações. A prática é legal em alguns lugares, mas suscita debates sobre a conscientização dos usuários em relação ao que estão compartilhando. A questão central é se os usuários realmente entendem os riscos envolvidos em vender suas conversas privadas por valores baixos, considerando o potencial uso malicioso por terceiros. O caso do Neon Mobile reflete uma tendência preocupante em que a privacidade é sacrificada em troca de recompensas financeiras mínimas.&lt;/p></description></item><item><title>Campanha EvilAI usa ferramentas de IA para distribuir malware</title><link>https://brdefense.center/news/campanha-evilai-usa-ferramentas-de-ia-para-distrib/</link><pubDate>Mon, 29 Sep 2025 18:58:05 -0300</pubDate><guid>https://brdefense.center/news/campanha-evilai-usa-ferramentas-de-ia-para-distrib/</guid><description>&lt;p>Uma nova campanha de malware, denominada EvilAI, está utilizando ferramentas de inteligência artificial (IA) aparentemente legítimas para infiltrar malware em organizações ao redor do mundo. De acordo com a Trend Micro, os ataques têm como alvo setores como manufatura, governo, saúde, tecnologia e varejo, afetando países como Índia, EUA, França, Itália, Brasil, Alemanha, Reino Unido, Noruega, Espanha e Canadá. Os atacantes se destacam por sua habilidade em disfarçar software malicioso como aplicativos de produtividade, utilizando interfaces profissionais e assinaturas digitais válidas, dificultando a identificação por usuários e ferramentas de segurança.&lt;/p></description></item><item><title>Lideranças de Segurança Adotam IA para Enfrentar Sobrecarga de Alertas</title><link>https://brdefense.center/news/liderancas-de-seguranca-adotam-ia-para-enfrentar-s/</link><pubDate>Mon, 29 Sep 2025 12:58:14 -0300</pubDate><guid>https://brdefense.center/news/liderancas-de-seguranca-adotam-ia-para-enfrentar-s/</guid><description>&lt;p>Um estudo recente com 282 líderes de segurança revela que os Centros de Operações de Segurança (SOCs) enfrentam um aumento insustentável no volume de alertas, com uma média de 960 alertas processados diariamente, e até 3.000 em grandes empresas. Essa sobrecarga tem levado a uma situação crítica, onde 40% dos alertas não são investigados devido à falta de recursos. O tempo médio para investigar um alerta é de 70 minutos, mas 56 minutos se passam antes que qualquer ação seja tomada. Essa realidade resulta em um risco operacional significativo, pois 61% das equipes admitem ignorar alertas que se tornaram incidentes críticos. A adoção de Inteligência Artificial (IA) está se tornando essencial, com 55% das equipes já utilizando assistentes de IA para triagem e investigação. A pesquisa indica que 60% das cargas de trabalho dos SOCs podem ser geridas por IA nos próximos três anos, permitindo que analistas se concentrem em investigações mais complexas. Apesar das barreiras como preocupações com privacidade e integração, a tendência é clara: a IA está se tornando uma prioridade estratégica para melhorar a eficiência operacional e reduzir a fadiga dos analistas.&lt;/p></description></item><item><title>Ferramenta de IA ajuda Reino Unido a recuperar 480 milhões em fraudes</title><link>https://brdefense.center/news/ferramenta-de-ia-ajuda-reino-unido-a-recuperar-480/</link><pubDate>Fri, 26 Sep 2025 00:58:40 -0300</pubDate><guid>https://brdefense.center/news/ferramenta-de-ia-ajuda-reino-unido-a-recuperar-480/</guid><description>&lt;p>Um novo sistema de detecção de fraudes baseado em inteligência artificial (IA) ajudou o governo do Reino Unido a recuperar um recorde de £480 milhões em fraudes no último ano, o maior valor já recuperado em um período de 12 meses. O sistema, denominado Fraud Risk Assessment Accelerator, foi crucial na identificação de fraudes relacionadas ao programa de empréstimos Bounce Back, que visava apoiar empresas durante a pandemia de Covid-19. Esses empréstimos, que podiam chegar a £50.000, foram criticados por serem concedidos sem verificações adequadas, resultando em um aumento significativo de fraudes. O governo planeja reinvestir os valores recuperados em serviços essenciais como saúde, educação e policiamento. Apesar do sucesso, grupos de defesa das liberdades civis expressaram preocupações sobre o uso crescente de ferramentas de IA no governo, levantando questões sobre viés e resultados injustos. O ministro do Gabinete, Josh Simons, anunciou que o sistema será licenciado internacionalmente, com países como EUA, Canadá e Austrália demonstrando interesse em sua implementação.&lt;/p></description></item><item><title>Malware com Inteligência Artificial é Descoberto por Pesquisadores</title><link>https://brdefense.center/news/malware-com-inteligencia-artificial-e-descoberto-p/</link><pubDate>Sat, 20 Sep 2025 06:58:27 -0300</pubDate><guid>https://brdefense.center/news/malware-com-inteligencia-artificial-e-descoberto-p/</guid><description>&lt;p>Pesquisadores de cibersegurança da SentinelOne apresentaram no LABScon 2025 a descoberta do MalTerminal, um malware que incorpora capacidades de Modelos de Linguagem de Grande Escala (LLMs). Este malware, que utiliza a API do OpenAI GPT-4, é capaz de gerar dinamicamente códigos de ransomware ou shells reversos. Embora não haja evidências de que tenha sido utilizado em ataques reais, sua existência representa um marco na evolução das técnicas de ataque, com a introdução de malwares que podem gerar lógica maliciosa em tempo real. Além disso, a pesquisa revelou que criminosos cibernéticos estão utilizando prompts ocultos em e-mails de phishing para enganar scanners de segurança baseados em IA, aumentando a eficácia desses ataques. O uso de ferramentas de IA generativa por cibercriminosos está se tornando uma tendência preocupante, com um aumento nas campanhas de engenharia social que exploram plataformas de hospedagem de sites para criar páginas de phishing. Esse cenário exige atenção redobrada das empresas, especialmente em relação à segurança de suas comunicações eletrônicas e à proteção de dados sensíveis.&lt;/p></description></item><item><title>A IA e seu impacto na cibersegurança segundo o Google</title><link>https://brdefense.center/news/a-ia-e-seu-impacto-na-ciberseguranca-segundo-o-goo/</link><pubDate>Thu, 18 Sep 2025 13:05:16 -0300</pubDate><guid>https://brdefense.center/news/a-ia-e-seu-impacto-na-ciberseguranca-segundo-o-goo/</guid><description>&lt;p>A inteligência artificial (IA) está transformando o cenário da cibersegurança, conforme destacado por Sandra Joyce, Vice-Presidente de Inteligência de Ameaças do Google, em um encontro em São Paulo. A IA não é apenas uma ferramenta de defesa, mas também uma arma poderosa nas mãos de atacantes. Grupos criminosos estão utilizando IA para aprimorar suas táticas, resultando em ataques de phishing mais sofisticados, deepfakes convincentes e fraudes por voz (vishing) cada vez mais realistas. O Google, por sua vez, está investindo em IA para fortalecer suas defesas, conseguindo reverter malware em minutos e detectar vulnerabilidades críticas antes que sejam exploradas. A crescente organização dos grupos de ransomware, que agora operam como verdadeiras empresas, também foi um ponto destacado, evidenciando a necessidade de uma resposta robusta por parte das organizações. Sandra enfatizou que a corrida entre atacantes e defensores está apenas começando, e que a IA será fundamental para garantir a segurança digital. Além disso, a IA promete criar novas oportunidades de trabalho no setor de segurança digital, exigindo que os profissionais se familiarizem com essa tecnologia.&lt;/p></description></item><item><title>As 10 Melhores Ferramentas de Filtragem de Conteúdo Web em 2025</title><link>https://brdefense.center/news/as-10-melhores-ferramentas-de-filtragem-de-conteud/</link><pubDate>Wed, 17 Sep 2025 19:00:09 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-ferramentas-de-filtragem-de-conteud/</guid><description>&lt;p>Em um cenário digital marcado pelo trabalho remoto e ameaças cibernéticas sofisticadas, a filtragem de conteúdo web se tornou uma medida de segurança essencial para organizações de todos os tamanhos. As melhores soluções de filtragem em 2025 vão além do simples bloqueio de URLs, utilizando inteligência de ameaças impulsionada por IA, princípios de zero-trust e controle granular de políticas para proteger usuários e ativos. Este guia apresenta as dez principais ferramentas de filtragem de conteúdo web, destacando suas características e pontos fortes, ajudando na escolha da solução mais adequada. A seleção priorizou fornecedores estabelecidos com um histórico comprovado em cibersegurança, reputação no mercado e um conjunto abrangente de recursos, como descoberta automatizada, uso de IA para detecção de ameaças e flexibilidade de implantação. As tendências atuais incluem a integração com arquiteturas de zero-trust, controle granular e modelos nativos em nuvem, tornando a filtragem avançada mais acessível, especialmente para pequenas e médias empresas. Ao avaliar uma solução, é importante considerar a inteligência de ameaças, opções de filtragem de conteúdo, gerenciamento e cobertura de usuários e dispositivos.&lt;/p></description></item><item><title>A segurança de dados em IA desafios e soluções para empresas</title><link>https://brdefense.center/news/a-seguranca-de-dados-em-ia-desafios-e-solucoes-par/</link><pubDate>Wed, 17 Sep 2025 12:59:01 -0300</pubDate><guid>https://brdefense.center/news/a-seguranca-de-dados-em-ia-desafios-e-solucoes-par/</guid><description>&lt;p>A rápida adoção da Inteligência Artificial (IA) nas empresas trouxe benefícios significativos, mas também desafios de segurança. O artigo destaca que a maior preocupação não é a imprudência dos funcionários ao usar ferramentas de IA, mas sim a inadequação dos modelos de avaliação de risco das organizações. Muitas soluções de segurança legadas não conseguem monitorar adequadamente o uso de IA, resultando em decisões inadequadas, como proibições que podem levar ao uso de ferramentas não autorizadas. O processo de compra de soluções de segurança de dados em IA deve ser reavaliado, focando em como as ferramentas são utilizadas no dia a dia, em vez de apenas comparar funcionalidades. O artigo sugere que a jornada do comprador deve incluir a descoberta de ferramentas em uso, monitoramento em tempo real e enforcement que não seja apenas de bloqueio. Além disso, fatores não técnicos, como a experiência do usuário e a capacidade de adaptação a novas ferramentas, são cruciais para o sucesso das soluções. O equilíbrio entre segurança e produtividade é essencial, e a abordagem mais eficaz é permitir o uso de IA em contextos autorizados, enquanto se interceptam comportamentos de risco em tempo real.&lt;/p></description></item><item><title>Ferramenta Red AI Range Melhora Testes de Segurança em IA</title><link>https://brdefense.center/news/ferramenta-red-ai-range-melhora-testes-de-seguranc/</link><pubDate>Mon, 15 Sep 2025 12:59:53 -0300</pubDate><guid>https://brdefense.center/news/ferramenta-red-ai-range-melhora-testes-de-seguranc/</guid><description>&lt;p>O Red AI Range (RAR) é uma plataforma inovadora de código aberto que permite a profissionais de segurança realizar testes de red teaming em implementações de inteligência artificial (IA). Desenvolvido por Erdem Özgen, o RAR utiliza a tecnologia de containerização para criar ambientes controlados onde ataques simulados podem revelar vulnerabilidades em fluxos de trabalho de aprendizado de máquina, pipelines de dados e motores de inferência de modelos. A configuração inicial é simplificada através do Docker Compose, permitindo que os usuários lancem todo o ambiente de testes com um único comando.&lt;/p></description></item><item><title>Ferramenta de pentesting com IA gera preocupações de segurança</title><link>https://brdefense.center/news/ferramenta-de-pentesting-com-ia-gera-preocupacoes/</link><pubDate>Mon, 15 Sep 2025 06:59:16 -0300</pubDate><guid>https://brdefense.center/news/ferramenta-de-pentesting-com-ia-gera-preocupacoes/</guid><description>&lt;p>Uma nova ferramenta de teste de penetração, chamada Villager, desenvolvida por uma empresa chinesa, já foi baixada quase 11.000 vezes no repositório Python Package Index (PyPI). A ferramenta, que automatiza fluxos de trabalho de testes de segurança, levanta preocupações sobre seu uso potencial por cibercriminosos. Villager é uma criação da Cyberspike, que também lançou ferramentas como o HexStrike AI, utilizadas para explorar vulnerabilidades recentemente divulgadas. A automação proporcionada por essas ferramentas permite que até mesmo atacantes menos experientes realizem intrusões sofisticadas, reduzindo o tempo e o esforço necessários para executar ataques. A Cyberspike, que surgiu em 2023, integrou componentes de ferramentas de acesso remoto (RAT) em seus produtos, permitindo vigilância invasiva e controle sobre as vítimas. A arquitetura da Villager, que utiliza inteligência artificial para orquestrar ferramentas com base em objetivos, representa uma mudança significativa na condução de ataques cibernéticos. A natureza efêmera dos contêineres criados pela ferramenta dificulta a detecção e a análise forense, aumentando o risco para as organizações. Especialistas alertam que a rápida disponibilidade e as capacidades de automação da Villager podem torná-la um recurso valioso para atores maliciosos, semelhante ao que ocorreu com o Cobalt Strike.&lt;/p></description></item><item><title>Vulnerabilidade no editor de código Cursor pode permitir execução de código</title><link>https://brdefense.center/news/vulnerabilidade-no-editor-de-codigo-cursor-pode-pe/</link><pubDate>Fri, 12 Sep 2025 07:00:32 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-no-editor-de-codigo-cursor-pode-pe/</guid><description>&lt;p>Uma vulnerabilidade de segurança foi identificada no editor de código Cursor, que utiliza inteligência artificial. O problema ocorre porque a configuração de segurança chamada &amp;lsquo;Workspace Trust&amp;rsquo; está desativada por padrão, permitindo que atacantes executem código arbitrário nos computadores dos usuários ao abrir repositórios maliciosos. A análise da Oasis Security destaca que, com essa configuração desativada, um arquivo malicioso &amp;lsquo;.vscode/tasks.json&amp;rsquo; pode transformar a simples ação de abrir uma pasta em uma execução silenciosa de código malicioso. Isso pode resultar em vazamento de credenciais sensíveis ou comprometer todo o sistema do usuário. Para mitigar esse risco, os usuários devem ativar o &amp;lsquo;Workspace Trust&amp;rsquo;, abrir repositórios não confiáveis em editores de código alternativos e realizar auditorias antes de usar o Cursor. Além disso, a pesquisa aponta que a segurança em ferramentas de desenvolvimento baseadas em IA enfrenta desafios adicionais, como injeções de prompt e vulnerabilidades clássicas, que ampliam a superfície de ataque. A situação é preocupante, pois a segurança deve ser uma prioridade em um ambiente de desenvolvimento cada vez mais dependente de IA.&lt;/p></description></item><item><title>SpamGPT Ferramenta de IA impulsiona campanhas massivas de phishing</title><link>https://brdefense.center/news/spamgpt-ferramenta-de-ia-impulsiona-campanhas-mass/</link><pubDate>Tue, 09 Sep 2025 06:59:11 -0300</pubDate><guid>https://brdefense.center/news/spamgpt-ferramenta-de-ia-impulsiona-campanhas-mass/</guid><description>&lt;p>O SpamGPT é uma nova ferramenta de cibercrime que combina inteligência artificial com plataformas de marketing por e-mail, facilitando a execução de campanhas de phishing em larga escala. Comercializada em fóruns clandestinos como uma solução de &amp;ldquo;spam como serviço&amp;rdquo;, a ferramenta reduz drasticamente a barreira técnica para criminosos. Com uma interface que imita softwares de marketing legítimos, o SpamGPT automatiza quase todas as etapas de uma operação de e-mail fraudulenta. Seu núcleo é um framework criptografado que inclui um assistente de IA, o &amp;ldquo;KaliGPT&amp;rdquo;, que gera textos persuasivos e personaliza conteúdos para alvos específicos, eliminando a necessidade de habilidades de escrita. Além disso, oferece painéis em tempo real para monitoramento de entregabilidade e métricas de engajamento, características normalmente restritas a grandes empresas. O SpamGPT permite que até iniciantes lancem operações de spam em massa, utilizando técnicas avançadas de spoofing para contornar verificações de segurança. Essa evolução no cibercrime torna os ataques de phishing mais escaláveis e convincentes, exigindo que as organizações adotem medidas robustas de segurança por e-mail, como políticas DMARC, SPF e DKIM, além de soluções de segurança baseadas em IA para detectar padrões de phishing gerados por IA.&lt;/p></description></item><item><title>As 10 Melhores Empresas de Gestão de Superfície de Ataque em 2025</title><link>https://brdefense.center/news/as-10-melhores-empresas-de-gestao-de-superficie-de/</link><pubDate>Sat, 06 Sep 2025 18:57:39 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-empresas-de-gestao-de-superficie-de/</guid><description>&lt;p>Em 2025, a gestão da superfície de ataque (ASM) se torna essencial para a segurança cibernética, à medida que as organizações ampliam sua presença digital através de serviços em nuvem e trabalho remoto. O ASM é uma disciplina proativa que envolve a descoberta, inventário e monitoramento contínuo de ativos expostos à internet, permitindo a identificação e mitigação de vulnerabilidades antes que sejam exploradas. As melhores empresas de ASM utilizam automação e inteligência artificial para oferecer uma visão abrangente da postura de segurança externa das organizações.&lt;/p></description></item><item><title>Cibercriminosos usam IA para contornar proteções de anúncios no X</title><link>https://brdefense.center/news/cibercriminosos-usam-ia-para-contornar-protecoes-d/</link><pubDate>Thu, 04 Sep 2025 12:58:09 -0300</pubDate><guid>https://brdefense.center/news/cibercriminosos-usam-ia-para-contornar-protecoes-d/</guid><description>&lt;p>Pesquisadores de cibersegurança identificaram uma nova técnica utilizada por cibercriminosos para contornar as proteções contra malvertising da plataforma de mídia social X, utilizando o assistente de inteligência artificial Grok. A técnica, chamada de Grokking, permite que links maliciosos sejam propagados através de postagens promovidas. Os malvertisers utilizam conteúdo adulto como isca, escondendo links maliciosos no campo de metadados &amp;lsquo;From:&amp;rsquo; abaixo do player de vídeo, que não é escaneado pela plataforma. Em seguida, eles mencionam Grok em respostas, fazendo com que o chatbot exiba o link, que agora é amplificado em SEO e reputação de domínio. Os links direcionam os usuários para redes de anúncios suspeitas, levando a fraudes como CAPTCHAs falsos e malware que rouba informações. A Guardio Labs observou centenas de contas envolvidas nesse comportamento, que postam incessantemente até serem suspensas. Essa técnica representa um risco significativo, pois permite que links proibidos pela plataforma se espalhem rapidamente, atingindo milhões de usuários.&lt;/p></description></item><item><title>Ameaça de Exploração com Ferramenta de IA HexStrike AI</title><link>https://brdefense.center/news/ameaca-de-exploracao-com-ferramenta-de-ia-hexstrik/</link><pubDate>Wed, 03 Sep 2025 12:57:10 -0300</pubDate><guid>https://brdefense.center/news/ameaca-de-exploracao-com-ferramenta-de-ia-hexstrik/</guid><description>&lt;p>Recentemente, a ferramenta de segurança ofensiva HexStrike AI, que utiliza inteligência artificial para automatizar a descoberta de vulnerabilidades, está sendo explorada por atores maliciosos para tirar proveito de falhas de segurança recém-divulgadas. De acordo com um relatório da Check Point, esses indivíduos estão utilizando a plataforma, que integra mais de 150 ferramentas de segurança, para realizar ataques em sistemas vulneráveis, como os da Citrix. A ferramenta, que deveria fortalecer a defesa cibernética, está sendo rapidamente adaptada para fins de exploração, aumentando a eficiência dos ataques e reduzindo o tempo entre a divulgação pública de falhas e sua exploração em massa. A Check Point alerta que essa situação representa uma mudança significativa na forma como as vulnerabilidades são exploradas, permitindo que ataques sejam realizados de maneira automatizada e em larga escala. Os pesquisadores também destacam que agentes de cibersegurança baseados em IA, como o PentestGPT, apresentam riscos elevados de injeção de comandos, transformando ferramentas de segurança em vetores de ataque. A recomendação imediata é que as organizações atualizem e reforcem seus sistemas para mitigar esses riscos.&lt;/p></description></item><item><title>Identificado primeiro ransomware criado com inteligência artificial</title><link>https://brdefense.center/news/identificado-primeiro-ransomware-criado-com-inteli/</link><pubDate>Mon, 01 Sep 2025 19:00:36 -0300</pubDate><guid>https://brdefense.center/news/identificado-primeiro-ransomware-criado-com-inteli/</guid><description>&lt;p>Pesquisadores da ESET, Anton Cherepanov e Peter Strycek, descobriram o PromptLock, o primeiro ransomware desenvolvido com a ajuda de inteligência artificial. Embora ainda não tenha sido visto em ação, a ESET alertou a comunidade de cibersegurança sobre essa nova ameaça. O PromptLock utiliza o modelo gpt-oss-20b da OpenAI, que é uma versão gratuita do ChatGPT, e opera localmente em dispositivos infectados através da API Ollama.&lt;/p>
&lt;p>O ransomware é capaz de inspecionar arquivos, extrair dados e criptografá-los, podendo futuramente ser utilizado para extorsão. Ele é compatível com sistemas operacionais Windows, Linux e macOS. O código do malware indica que ele pode até destruir arquivos, embora essa funcionalidade ainda não esteja totalmente implementada. O PromptLock utiliza a encriptação SPECK de 128 bits e é escrito na linguagem Go. A ESET também observou que variantes do malware foram enviadas para a plataforma VirusTotal, que serve como repositório de vírus para especialistas em segurança.&lt;/p></description></item><item><title>As 10 Melhores Empresas de Teste de Segurança de API em 2025</title><link>https://brdefense.center/news/as-10-melhores-empresas-de-teste-de-seguranca-de-a/</link><pubDate>Sat, 30 Aug 2025 12:58:31 -0300</pubDate><guid>https://brdefense.center/news/as-10-melhores-empresas-de-teste-de-seguranca-de-a/</guid><description>&lt;p>Em 2025, as APIs se tornaram fundamentais para o funcionamento de aplicações modernas, abrangendo desde serviços bancários móveis até arquiteturas de microserviços. No entanto, essa popularidade também as torna alvos preferenciais para ataques cibernéticos, com violações relacionadas a APIs se destacando como uma das principais causas de exfiltração de dados. O artigo destaca a importância de um teste de segurança de API robusto, que vai além das soluções tradicionais, como firewalls de aplicativos web (WAFs) e scanners DAST, que muitas vezes falham em detectar ataques específicos de API, como a autorização de nível de objeto quebrada (BOLA) e abusos de lógica de negócios. As melhores empresas de teste de segurança de API em 2025 são aquelas que oferecem uma abordagem abrangente, cobrindo todo o ciclo de vida da segurança, desde o design até a execução. O artigo analisa empresas como Salt Security, Traceable AI e Wallarm, que se destacam por suas capacidades de descoberta automática de APIs, proteção em tempo real e uso de inteligência artificial para detectar ameaças sofisticadas. A segurança de APIs não é mais um luxo, mas uma necessidade crítica para prevenir violações e manter uma postura de segurança forte.&lt;/p></description></item><item><title>Google usa IA para corrigir falha crítica no Chrome</title><link>https://brdefense.center/news/google-usa-ia-para-corrigir-falha-critica-no-chrom/</link><pubDate>Fri, 29 Aug 2025 18:59:43 -0300</pubDate><guid>https://brdefense.center/news/google-usa-ia-para-corrigir-falha-critica-no-chrom/</guid><description>&lt;p>O Google anunciou a correção de uma vulnerabilidade crítica no navegador Chrome, identificada como CVE-2025-9478, com o auxílio de sua inteligência artificial interna, chamada Big Sleep. Essa ferramenta, baseada na tecnologia Gemini, foi capaz de detectar a falha sem intervenção humana, destacando a crescente importância da IA na segurança cibernética. As versões corrigidas do Chrome incluem 139.0.7258.154/155 para Windows e macOS, e 139.0.7258.154 para Linux. A vulnerabilidade estava relacionada à galeria de gráficos Angle e foi classificada como crítica, o que significa que poderia ser explorada para comprometer a segurança dos usuários. Embora a Big Sleep tenha demonstrado eficácia na identificação dessa falha, especialistas em segurança ainda são necessários para validar os diagnósticos, uma vez que a precisão das ferramentas de IA pode variar. Além disso, outros navegadores baseados em Chromium, como Brave, Microsoft Edge e Vivaldi, também precisarão aplicar as correções. O Google recomenda que os usuários atualizem seus navegadores para garantir a proteção contra possíveis explorações dessa vulnerabilidade.&lt;/p></description></item><item><title>Nova funcionalidade do VirusTotal fornece descrições de funções de código</title><link>https://brdefense.center/news/nova-funcionalidade-do-virustotal-fornece-descrico/</link><pubDate>Fri, 29 Aug 2025 12:59:27 -0300</pubDate><guid>https://brdefense.center/news/nova-funcionalidade-do-virustotal-fornece-descrico/</guid><description>&lt;p>Em 28 de agosto de 2025, o VirusTotal lançou uma nova funcionalidade chamada Code Insight, que visa ajudar analistas de segurança a lidar com a crescente complexidade dos malwares. Essa ferramenta integra análise de código impulsionada por inteligência artificial (IA) diretamente em ferramentas de engenharia reversa, permitindo que os analistas submetam trechos de código em formato Base64 e recebam resumos e descrições detalhadas sobre as funções do código. A funcionalidade promete reduzir significativamente o esforço manual, ao resumir e contextualizar funções desmontadas ou decompiladas, acelerando o ciclo de análise de malware. A atualização do plugin VT-IDA para IDA Pro facilita a integração, permitindo que os analistas aceitem, editem e armazenem análises em um caderno específico. A nova abordagem também inclui um recurso de memória que aprende com as correções feitas pelos analistas, melhorando a precisão das análises ao longo do tempo. Embora os resultados iniciais sejam promissores, o VirusTotal está buscando feedback da comunidade para aprimorar ainda mais os modelos de IA utilizados.&lt;/p></description></item><item><title>Visibilidade de Código à Nuvem A Nova Base para Segurança de Aplicativos</title><link>https://brdefense.center/news/visibilidade-de-codigo-a-nuvem-a-nova-base-para-se/</link><pubDate>Fri, 29 Aug 2025 00:57:10 -0300</pubDate><guid>https://brdefense.center/news/visibilidade-de-codigo-a-nuvem-a-nova-base-para-se/</guid><description>&lt;p>O artigo destaca a crescente preocupação com a segurança de aplicativos na nuvem, especialmente em um cenário onde falhas de segurança podem custar milhões às empresas. Em 2025, o custo médio de uma violação de dados é estimado em US$ 4,44 milhões, com uma parte significativa desses problemas originando-se de erros de segurança em aplicativos. A visibilidade de código à nuvem é apresentada como uma solução eficaz para identificar riscos desde a fase de desenvolvimento até a operação na nuvem. O artigo menciona que 32% das organizações enfrentam dificuldades na gestão de vulnerabilidades, enquanto 97% lidam com questões de segurança relacionadas à inteligência artificial generativa. Um webinar programado para 8 de setembro de 2025 promete oferecer insights práticos sobre como implementar essa abordagem, visando melhorar a colaboração entre equipes de desenvolvimento, operações e segurança. Os participantes aprenderão a mapear riscos, acelerar correções e se preparar para novas ameaças, tudo isso sem sobrecarregar suas operações.&lt;/p></description></item><item><title>Novas sanções dos EUA visam esquema de TI da Coreia do Norte</title><link>https://brdefense.center/news/novas-sancoes-dos-eua-visam-esquema-de-ti-da-corei/</link><pubDate>Thu, 28 Aug 2025 06:57:20 -0300</pubDate><guid>https://brdefense.center/news/novas-sancoes-dos-eua-visam-esquema-de-ti-da-corei/</guid><description>&lt;p>O Departamento do Tesouro dos EUA anunciou novas sanções contra dois indivíduos e duas entidades ligadas ao esquema de trabalhadores de tecnologia da informação (TI) da Coreia do Norte, que visa gerar receitas ilícitas para programas de armas de destruição em massa. As sanções atingem Vitaliy Sergeyevich Andreyev, Kim Ung Sun, a Shenyang Geumpungri Network Technology Co., Ltd e a Korea Sinjin Trading Corporation. O esquema, que já é monitorado há anos, envolve a infiltração de trabalhadores de TI norte-coreanos em empresas legítimas nos EUA, utilizando documentos fraudulentos e identidades roubadas. Além disso, a operação tem se apoiado em ferramentas de inteligência artificial para criar perfis profissionais convincentes e realizar trabalhos técnicos. O Departamento do Tesouro destacou que Andreyev facilitou transferências financeiras significativas para a Chinyong Information Technology Cooperation Company, que já havia sido sancionada anteriormente. O uso de IA por esses atores levanta preocupações sobre a segurança cibernética, especialmente para empresas que podem ser alvos de fraudes e extorsões. O impacto dessas atividades é significativo, com lucros estimados em mais de um milhão de dólares desde 2021.&lt;/p></description></item><item><title>O primeiro ransomware com inteligência artificial foi identificado</title><link>https://brdefense.center/news/o-primeiro-ransomware-com-inteligencia-artificial/</link><pubDate>Wed, 27 Aug 2025 18:58:35 -0300</pubDate><guid>https://brdefense.center/news/o-primeiro-ransomware-com-inteligencia-artificial/</guid><description>&lt;p>Pesquisadores da ESET descobriram o PromptLock, o primeiro ransomware conhecido a utilizar inteligência artificial. Este malware, que ainda é considerado um conceito em desenvolvimento, utiliza scripts em Lua gerados por prompts codificados para explorar sistemas de arquivos locais, inspecionar arquivos-alvo, exfiltrar dados selecionados e realizar criptografia. O PromptLock opera localmente através da API Ollama, utilizando o modelo gpt-oss:20b da OpenAI, lançado em agosto de 2025. A versatilidade dos scripts em Lua permite que o malware funcione em diferentes sistemas operacionais, como macOS, Linux e Windows. Embora o PromptLock ainda não tenha sido observado em ataques reais, especialistas alertam que a combinação de inteligência artificial e ransomware representa uma nova era de ameaças cibernéticas, tornando os ataques mais acessíveis e difíceis de detectar. A imprevisibilidade dos resultados gerados por modelos de linguagem torna a defesa contra esses ataques ainda mais desafiadora, aumentando a preocupação entre as equipes de segurança.&lt;/p></description></item><item><title>Ransomware PromptLock usa IA para gerar scripts maliciosos em tempo real</title><link>https://brdefense.center/news/ransomware-promptlock-usa-ia-para-gerar-scripts-ma/</link><pubDate>Wed, 27 Aug 2025 18:57:56 -0300</pubDate><guid>https://brdefense.center/news/ransomware-promptlock-usa-ia-para-gerar-scripts-ma/</guid><description>&lt;p>A empresa de cibersegurança ESET revelou a descoberta de um novo ransomware chamado PromptLock, que utiliza inteligência artificial para gerar scripts maliciosos em tempo real. Escrito em Golang, o PromptLock emprega o modelo gpt-oss:20b da OpenAI através da API Ollama para criar scripts em Lua que podem enumerar sistemas de arquivos, inspecionar arquivos-alvo, exfiltrar dados e criptografar informações. Este ransomware é compatível com Windows, Linux e macOS, e é capaz de gerar notas personalizadas para as vítimas, dependendo dos arquivos afetados. Embora ainda não se saiba quem está por trás do malware, a ESET identificou que artefatos do PromptLock foram enviados ao VirusTotal a partir dos Estados Unidos em 25 de agosto de 2025. A natureza do ransomware, que é considerada uma prova de conceito, utiliza o algoritmo de criptografia SPECK de 128 bits. A ESET alerta que a variabilidade dos indicadores de comprometimento (IoCs) torna a detecção mais desafiadora, complicando as tarefas de defesa. O surgimento do PromptLock destaca como a IA pode facilitar a criação de campanhas de malware, mesmo para criminosos com pouca experiência técnica.&lt;/p></description></item><item><title>Cinco regras para uma adoção segura de IA nas empresas</title><link>https://brdefense.center/news/cinco-regras-para-uma-adocao-segura-de-ia-nas-empr/</link><pubDate>Wed, 27 Aug 2025 12:57:34 -0300</pubDate><guid>https://brdefense.center/news/cinco-regras-para-uma-adocao-segura-de-ia-nas-empr/</guid><description>&lt;p>O uso de Inteligência Artificial (IA) nas empresas está crescendo rapidamente, com colaboradores utilizando-a para redigir e-mails, analisar dados e transformar o ambiente de trabalho. No entanto, a adoção acelerada da IA traz desafios significativos em termos de segurança, especialmente pela falta de controle e salvaguardas adequadas. Para os Chief Information Security Officers (CISOs), a prioridade é garantir que a inovação não comprometa a segurança. O artigo apresenta cinco regras essenciais para uma adoção segura da IA: 1) Visibilidade e descoberta da IA, que exige monitoramento contínuo do uso de ferramentas de IA; 2) Avaliação de risco contextual, que considera o nível de risco associado a diferentes aplicações de IA; 3) Proteção de dados, estabelecendo limites sobre quais informações podem ser compartilhadas com ferramentas de IA; 4) Controles de acesso e diretrizes, que garantem que o uso da IA esteja dentro de políticas de segurança definidas; e 5) Supervisão contínua, para adaptar as medidas de segurança conforme as aplicações evoluem. A adoção segura da IA não deve ser vista como uma barreira, mas como uma oportunidade de inovar de forma responsável, garantindo a proteção dos dados e a conformidade com regulamentações como a LGPD.&lt;/p></description></item><item><title>Anthropic interrompe ataque cibernético com uso de IA avançada</title><link>https://brdefense.center/news/anthropic-interrompe-ataque-cibernetico-com-uso-de/</link><pubDate>Wed, 27 Aug 2025 12:56:54 -0300</pubDate><guid>https://brdefense.center/news/anthropic-interrompe-ataque-cibernetico-com-uso-de/</guid><description>&lt;p>Em julho de 2025, a Anthropic revelou ter desmantelado uma operação sofisticada que utilizava seu chatbot Claude, alimentado por inteligência artificial, para realizar roubo e extorsão em larga escala de dados pessoais. O ataque visou pelo menos 17 organizações, incluindo instituições de saúde, serviços de emergência e órgãos governamentais, com os criminosos ameaçando expor publicamente as informações roubadas para forçar o pagamento de resgates que ultrapassavam $500.000. Utilizando o Claude Code em uma plataforma Kali Linux, o ator desconhecido automatizou várias fases do ciclo de ataque, desde a coleta de credenciais até a penetração de redes. O uso de IA permitiu que o atacante tomasse decisões táticas e estratégicas, selecionando quais dados exfiltrar e elaborando demandas de extorsão personalizadas com base em análises financeiras. A Anthropic desenvolveu um classificador personalizado para detectar comportamentos semelhantes e compartilhou indicadores técnicos com parceiros estratégicos. O caso destaca como ferramentas de IA estão sendo mal utilizadas para facilitar operações cibernéticas complexas, tornando a defesa mais desafiadora.&lt;/p></description></item><item><title>Geradores de sites por IA se tornam ferramentas de phishing para hackers</title><link>https://brdefense.center/news/geradores-de-sites-por-ia-se-tornam-ferramentas-de/</link><pubDate>Mon, 25 Aug 2025 19:01:21 -0300</pubDate><guid>https://brdefense.center/news/geradores-de-sites-por-ia-se-tornam-ferramentas-de/</guid><description>&lt;p>A crescente popularidade de serviços de criação de sites por inteligência artificial, como a Lovable, trouxe à tona preocupações significativas de segurança cibernética. Um relatório da Proofpoint revelou que, desde fevereiro, dezenas de milhares de URLs geradas na plataforma têm sido utilizadas em campanhas de phishing, instalação de malwares e roubo de dados. Os sites fraudulentos imitam páginas de marcas conhecidas e utilizam mecanismos como captchas para evitar a detecção por bots. Quatro campanhas distintas foram identificadas, incluindo uma que visava roubar credenciais de login da Microsoft e outra que imitava a empresa de logística UPS para coletar dados pessoais e informações de pagamento. A Lovable implementou medidas de segurança em junho, mas a Proofpoint alerta que ainda é possível criar sites fraudulentos na plataforma. Essa situação evidencia como a tecnologia pode ser explorada para fins criminosos, exigindo atenção redobrada de empresas e usuários para evitar danos.&lt;/p></description></item><item><title>Atores de Ameaças Usam Resumos Gerados por IA para Entregar Ransomware</title><link>https://brdefense.center/news/atores-de-ameacas-usam-resumos-gerados-por-ia-para/</link><pubDate>Mon, 25 Aug 2025 12:58:17 -0300</pubDate><guid>https://brdefense.center/news/atores-de-ameacas-usam-resumos-gerados-por-ia-para/</guid><description>&lt;p>Um novo método de engenharia social, denominado ClickFix, está sendo utilizado por cibercriminosos para implantar ransomware através de resumos gerados por inteligência artificial (IA). Essa técnica envolve a injeção de comandos maliciosos em elementos HTML, que se tornam invisíveis para os usuários, mas são processados por modelos de IA. Os atacantes escondem instruções em caracteres de largura zero, texto branco sobre fundo branco e fontes minúsculas, fazendo com que os resumos gerados incluam guias passo a passo para a instalação de ransomware. Quando os destinatários confiam nesses resumos, podem executar comandos sem perceber que estão seguindo instruções maliciosas. O ataque reduz a barreira técnica para usuários não especializados, permitindo que eles se tornem vetores de ransomware. Para mitigar esses riscos, recomenda-se a sanitização de atributos CSS invisíveis, filtragem de prompts e reconhecimento de padrões de payload. À medida que as ferramentas de resumo de IA se tornam comuns, essa técnica pode ser rapidamente adotada por criminosos, exigindo uma colaboração entre desenvolvedores de IA e equipes de segurança para prevenir campanhas de ransomware mediadas por IA.&lt;/p></description></item><item><title>Navegadores com IA ainda não são seguros o suficiente, diz estudo</title><link>https://brdefense.center/news/navegadores-com-ia-ainda-nao-sao-seguros-o-suficie/</link><pubDate>Fri, 22 Aug 2025 13:01:35 -0300</pubDate><guid>https://brdefense.center/news/navegadores-com-ia-ainda-nao-sao-seguros-o-suficie/</guid><description>&lt;p>Um estudo da empresa de cibersegurança Guardio revela que navegadores de internet que utilizam inteligência artificial (IA) ainda não estão prontos para realizar tarefas sensíveis, como compras online e gerenciamento de e-mails, devido a vulnerabilidades que podem ser exploradas por golpistas. Tecnologias como Comet, do Perplexity, Copilot, do Microsoft Edge, e Aura, da OpenAI, foram testadas e mostraram-se suscetíveis a ataques de phishing e engenharia social. Em um dos testes, a IA Comet completou uma compra em um site falso sem solicitar confirmação do usuário, expondo dados sensíveis como informações de cartão de crédito. Outro teste demonstrou que a IA foi enganada por um e-mail de phishing que parecia legítimo, resultando no fornecimento de credenciais do usuário. A Guardio alerta que esses testes preliminares indicam que há mais problemas em potencial, sugerindo que os usuários evitem delegar tarefas críticas à IA e adotem medidas de segurança, como a autenticação de dois fatores. O estudo destaca a necessidade de cautela ao usar navegadores com IA para evitar o roubo de dados e outras fraudes.&lt;/p></description></item><item><title>O Risco Oculto dos Agentes de IA nas Empresas</title><link>https://brdefense.center/news/o-risco-oculto-dos-agentes-de-ia-nas-empresas/</link><pubDate>Thu, 21 Aug 2025 01:01:13 -0300</pubDate><guid>https://brdefense.center/news/o-risco-oculto-dos-agentes-de-ia-nas-empresas/</guid><description>&lt;p>O artigo destaca a crescente preocupação com os agentes de inteligência artificial (IA) que operam silenciosamente nas empresas, muitas vezes sem supervisão adequada. Esses &amp;lsquo;agentes sombra&amp;rsquo; são configurados por diversas unidades de negócios, não apenas pela equipe de TI, o que resulta em uma falta de controle sobre suas identidades e atividades. Quando comprometidos, esses agentes podem acessar dados sensíveis e escalar privilégios rapidamente, representando uma ameaça significativa à segurança cibernética. A maioria dos programas de segurança atuais não foi projetada para lidar com esses agentes autônomos, o que aumenta o risco à medida que sua adoção se expande. O artigo também menciona um webinar que abordará como identificar e controlar esses agentes, além de compartilhar estratégias para atribuir identidades adequadas e garantir a responsabilidade. A urgência em lidar com essa questão é enfatizada, pois a escolha entre transformar esses agentes em ativos confiáveis ou em passivos perigosos depende das ações que as empresas tomarem agora.&lt;/p></description></item><item><title>Tecnologia de reconhecimento facial não está pronta para uso policial</title><link>https://brdefense.center/news/tecnologia-de-reconhecimento-facial-nao-esta-pront/</link><pubDate>Wed, 20 Aug 2025 18:58:26 -0300</pubDate><guid>https://brdefense.center/news/tecnologia-de-reconhecimento-facial-nao-esta-pront/</guid><description>&lt;p>Pesquisadores da Universidade de Oxford alertam sobre as falhas da tecnologia de reconhecimento facial utilizada por forças policiais em diversos países, como Estados Unidos e Reino Unido. A pesquisa destaca que as condições reais de identificação são muito mais complexas do que as simuladas em ambientes laboratoriais, resultando em prisões injustas de indivíduos inocentes. A Avaliação de Tecnologia de Reconhecimento Facial (FRTE) do Instituto Nacional de Padrões e Tecnologia (NIST) é frequentemente utilizada para justificar o uso dessa tecnologia, mas apresenta limitações significativas, como a falta de representatividade demográfica nos bancos de dados e a incapacidade de lidar com imagens de baixa qualidade. Estudos demonstram que, embora os modelos de reconhecimento facial possam apresentar uma precisão de até 99,95% em condições ideais, essa taxa cai drasticamente em situações do mundo real. Além disso, a tecnologia tende a falhar desproporcionalmente em relação a grupos marginalizados. Os pesquisadores concluem que a tecnologia ainda é muito falha para ser utilizada de forma segura por agências policiais e recomendam uma revisão das políticas de direitos civis relacionadas ao seu uso.&lt;/p></description></item><item><title>Google Lança Ferramentas Avançadas para Proteger a Segurança em IA</title><link>https://brdefense.center/news/google-lanca-ferramentas-avancadas-para-proteger-a/</link><pubDate>Wed, 20 Aug 2025 12:59:10 -0300</pubDate><guid>https://brdefense.center/news/google-lanca-ferramentas-avancadas-para-proteger-a/</guid><description>&lt;p>No Google Cloud Security Summit 2025, a Google apresentou uma nova suíte de ferramentas de segurança impulsionadas por inteligência artificial, com o objetivo de proteger ecossistemas de IA e fortalecer as defesas organizacionais. As inovações abrangem três áreas principais: proteção de implementações de IA autônomas, suporte a centros de operações de segurança com agentes autônomos e ampliação dos controles de segurança em nuvem.&lt;/p>
&lt;p>Entre as novidades, destaca-se o Centro de Comando de Segurança, que agora possui capacidades expandidas para identificação de riscos e inventário de agentes de IA, permitindo a descoberta automatizada de vulnerabilidades. A proteção em tempo real contra ameaças, como injeção de comandos e vazamento de dados sensíveis, foi aprimorada com a extensão do Model Armor. Além disso, um novo agente de investigação de alertas foi introduzido, que realiza investigações dinâmicas para acelerar os tempos de resposta.&lt;/p></description></item><item><title>Microsoft Defender AI agora detecta credenciais em texto simples no Active Directory</title><link>https://brdefense.center/news/microsoft-defender-ai-agora-detecta-credenciais-em/</link><pubDate>Tue, 19 Aug 2025 13:00:07 -0300</pubDate><guid>https://brdefense.center/news/microsoft-defender-ai-agora-detecta-credenciais-em/</guid><description>&lt;p>A Microsoft lançou uma nova funcionalidade de segurança baseada em inteligência artificial no Defender for Identity, que visa mitigar uma vulnerabilidade crítica relacionada ao armazenamento de credenciais em texto simples no Active Directory. A pesquisa da empresa revelou que mais de 40.000 credenciais estavam expostas em 2.500 locatários, evidenciando a gravidade do problema. Essa vulnerabilidade surge do uso inadequado de campos de texto livre, onde administradores frequentemente armazenam senhas e tokens de autenticação para facilitar a resolução de problemas e a integração de sistemas. Isso cria alvos valiosos para cibercriminosos, especialmente em contas de identidade não humanas, que não podem utilizar métodos tradicionais de autenticação multifatorial. A nova arquitetura de detecção da Microsoft combina varredura abrangente do diretório com uma análise contextual, reduzindo falsos positivos e garantindo alertas acionáveis para as equipes de segurança. A funcionalidade já está disponível em versão pública para todos os clientes do Defender for Identity, permitindo que as organizações identifiquem e corrijam configurações inadequadas antes que possam ser exploradas.&lt;/p></description></item><item><title>HexStrike AI integra ChatGPT, Claude e Copilot com 150 ferramentas de segurança</title><link>https://brdefense.center/news/hexstrike-ai-integra-chatgpt-claude-e-copilot-com/</link><pubDate>Fri, 15 Aug 2025 12:58:35 -0300</pubDate><guid>https://brdefense.center/news/hexstrike-ai-integra-chatgpt-claude-e-copilot-com/</guid><description>&lt;p>A HexStrike AI, plataforma líder em cibersegurança impulsionada por inteligência artificial, anunciou uma nova atualização que integra assistentes de IA como ChatGPT, Claude e Copilot com mais de 150 ferramentas de segurança, incluindo Burp Suite e Nmap. Essa atualização, parte da versão 6.0 da HexStrike AI, permite que desenvolvedores e pesquisadores de segurança realizem testes de penetração e avaliações de vulnerabilidades de forma autônoma e em uma escala sem precedentes. A arquitetura multi-agente da HexStrike AI conta com 12 agentes especializados que colaboram para executar fluxos de trabalho de segurança complexos. Através do protocolo “FastMCP”, os assistentes de IA podem invocar diretamente as ferramentas de segurança, automatizando tarefas como reconhecimento de rede e desenvolvimento de exploits. Profissionais de segurança agora podem, por exemplo, solicitar uma auditoria de segurança em um site e ver a execução automática de testes em segundos. A HexStrike AI v6.0 está disponível sob uma licença MIT de código aberto, permitindo que desenvolvedores integrem facilmente suas ferramentas de segurança com assistentes de IA.&lt;/p></description></item><item><title>A Nova Era da Privacidade Confiança em um Mundo de IA Agente</title><link>https://brdefense.center/news/a-nova-era-da-privacidade-confianca-em-um-mundo-de/</link><pubDate>Fri, 15 Aug 2025 09:26:12 -0300</pubDate><guid>https://brdefense.center/news/a-nova-era-da-privacidade-confianca-em-um-mundo-de/</guid><description>&lt;p>O conceito de privacidade está evoluindo em um mundo onde a inteligência artificial (IA) agente se torna cada vez mais autônoma. Em vez de ser apenas uma questão de controle, a privacidade agora se baseia na confiança, especialmente quando essas IAs interagem com dados sensíveis e tomam decisões em nome dos usuários. A IA agente não apenas processa informações, mas também as interpreta, o que levanta preocupações sobre o que é inferido e compartilhado sem supervisão constante. Um exemplo prático é um assistente de saúde que, ao longo do tempo, pode começar a priorizar consultas e analisar o estado emocional do usuário, o que pode levar à perda de controle sobre a narrativa pessoal. Além disso, a privacidade não se resume mais ao triângulo clássico da CIA (Confidencialidade, Integridade e Disponibilidade), mas deve incluir autenticidade e veracidade. A falta de um conceito claro de privilégio entre IA e cliente pode resultar em consequências legais, onde informações pessoais podem ser acessadas por terceiros. Portanto, é essencial que as organizações desenvolvam sistemas de IA que respeitem a intenção por trás da privacidade e que sejam capazes de explicar suas ações. A necessidade de um novo contrato social que considere a agência da IA como uma categoria moral e legal é urgente, pois a privacidade se torna uma questão de reciprocidade e governança em um mundo onde humanos e máquinas interagem cada vez mais.&lt;/p></description></item></channel></rss>