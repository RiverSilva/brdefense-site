<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Riscos Organizacionais on BR Defense Center</title><link>https://brdefense.center/tags/riscos-organizacionais/</link><description>Recent content in Riscos Organizacionais on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Sat, 24 Jan 2026 06:57:33 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/riscos-organizacionais/index.xml" rel="self" type="application/rss+xml"/><item><title>Agentes de IA e os Desafios de Segurança nas Empresas</title><link>https://brdefense.center/news/agentes-de-ia-e-os-desafios-de-seguranca-nas-empre/</link><pubDate>Sat, 24 Jan 2026 06:57:33 -0300</pubDate><guid>https://brdefense.center/news/agentes-de-ia-e-os-desafios-de-seguranca-nas-empre/</guid><description>&lt;p>Os agentes de inteligência artificial (IA) estão transformando a forma como as empresas operam, aumentando a produtividade ao automatizar tarefas como agendamento de reuniões e acesso a dados. No entanto, essa rápida adoção levanta preocupações significativas de segurança, especialmente em relação à aprovação e responsabilidade pelo uso desses agentes. Diferente de usuários humanos ou contas de serviço tradicionais, os agentes de IA operam com autoridade delegada, permitindo-lhes agir em nome de múltiplos usuários sem supervisão contínua. Isso resulta em um fenômeno conhecido como &amp;lsquo;desvio de acesso&amp;rsquo;, onde os agentes acumulam permissões que podem exceder o que um usuário individual estaria autorizado a fazer. O artigo classifica os agentes de IA em três categorias: pessoais, de terceiros e organizacionais, sendo estes últimos os mais arriscados devido à falta de um proprietário claro e à possibilidade de ações não autorizadas. Para mitigar esses riscos, as organizações precisam redefinir a gestão de acesso, estabelecendo propriedade clara e mapeando como os usuários interagem com os agentes. A segurança dos agentes de IA deve ser tratada como uma prioridade, considerando seu potencial de criar caminhos de autorização que podem ser explorados maliciosamente.&lt;/p></description></item></channel></rss>