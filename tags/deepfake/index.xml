<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deepfake on BR Defense Center</title><link>https://brdefense.center/tags/deepfake/</link><description>Recent content in Deepfake on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Thu, 25 Sep 2025 13:03:24 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/deepfake/index.xml" rel="self" type="application/rss+xml"/><item><title>Quase 66 das empresas são impactadas por ataques de deepfake</title><link>https://brdefense.center/news/quase-66-das-empresas-sao-impactadas-por-ataques-d/</link><pubDate>Thu, 25 Sep 2025 13:03:24 -0300</pubDate><guid>https://brdefense.center/news/quase-66-das-empresas-sao-impactadas-por-ataques-d/</guid><description>&lt;p>Uma pesquisa realizada pelo Gartner Security revelou que cerca de 62% das empresas já foram alvo de ataques utilizando deepfake, uma tecnologia que combina engenharia social e phishing para roubar dados ou dinheiro. Os ataques frequentemente envolvem a imitação de executivos por meio de vídeos ou áudios falsificados, além da exploração de ferramentas de verificação automatizadas, como reconhecimento facial e de voz. O diretor sênior do Gartner, Akif Khan, destacou que a engenharia social continua sendo uma ferramenta eficaz para golpistas, tornando difícil a identificação de fraudes por parte de funcionários comuns. Para mitigar esses riscos, Khan sugere que as organizações implementem soluções técnicas inovadoras, como ferramentas de detecção de deepfakes em plataformas de videoconferência, e promovam treinamentos de conscientização para os colaboradores. Além disso, recomenda a revisão de processos de negócios, como a autorização de pagamentos, utilizando autenticação multi-fator (MFA) para aumentar a segurança. O relatório também aponta que 32% das organizações enfrentaram ataques envolvendo inteligência artificial nos últimos 12 meses, evidenciando a crescente sofisticação das ameaças. Apesar de ⅔ dos clientes da Gartner não terem relatado ataques, a necessidade de atenção a essas ameaças é evidente, especialmente considerando as implicações de conformidade com a LGPD.&lt;/p></description></item><item><title>A IA e seu impacto na cibersegurança segundo o Google</title><link>https://brdefense.center/news/a-ia-e-seu-impacto-na-ciberseguranca-segundo-o-goo/</link><pubDate>Thu, 18 Sep 2025 13:05:16 -0300</pubDate><guid>https://brdefense.center/news/a-ia-e-seu-impacto-na-ciberseguranca-segundo-o-goo/</guid><description>&lt;p>A inteligência artificial (IA) está transformando o cenário da cibersegurança, conforme destacado por Sandra Joyce, Vice-Presidente de Inteligência de Ameaças do Google, em um encontro em São Paulo. A IA não é apenas uma ferramenta de defesa, mas também uma arma poderosa nas mãos de atacantes. Grupos criminosos estão utilizando IA para aprimorar suas táticas, resultando em ataques de phishing mais sofisticados, deepfakes convincentes e fraudes por voz (vishing) cada vez mais realistas. O Google, por sua vez, está investindo em IA para fortalecer suas defesas, conseguindo reverter malware em minutos e detectar vulnerabilidades críticas antes que sejam exploradas. A crescente organização dos grupos de ransomware, que agora operam como verdadeiras empresas, também foi um ponto destacado, evidenciando a necessidade de uma resposta robusta por parte das organizações. Sandra enfatizou que a corrida entre atacantes e defensores está apenas começando, e que a IA será fundamental para garantir a segurança digital. Além disso, a IA promete criar novas oportunidades de trabalho no setor de segurança digital, exigindo que os profissionais se familiarizem com essa tecnologia.&lt;/p></description></item><item><title>Golpes de impersonação com IA disparam em 2025 saiba como se proteger</title><link>https://brdefense.center/news/golpes-de-impersonacao-com-ia-disparam-em-2025-sai/</link><pubDate>Sun, 31 Aug 2025 18:58:13 -0300</pubDate><guid>https://brdefense.center/news/golpes-de-impersonacao-com-ia-disparam-em-2025-sai/</guid><description>&lt;p>Os golpes de impersonação utilizando inteligência artificial (IA) estão em ascensão alarmante em 2025, com um aumento de 148% em comparação ao ano anterior, segundo especialistas em segurança. Esses golpes se aproveitam de tecnologias como clonagem de voz e deepfake para imitar com precisão a voz e a aparência de pessoas de confiança, como amigos, familiares e executivos de empresas. Os criminosos utilizam essas técnicas para realizar chamadas, reuniões por vídeo e enviar mensagens, criando um senso de urgência que pode levar as vítimas a agir rapidamente sem verificar a identidade do suposto remetente.&lt;/p></description></item></channel></rss>