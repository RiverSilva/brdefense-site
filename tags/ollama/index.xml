<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ollama on BR Defense Center</title><link>https://brdefense.center/tags/ollama/</link><description>Recent content in Ollama on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Thu, 29 Jan 2026 19:02:04 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/ollama/index.xml" rel="self" type="application/rss+xml"/><item><title>Infraestrutura de IA exposta representa risco crescente à segurança</title><link>https://brdefense.center/news/infraestrutura-de-ia-exposta-representa-risco-cres/</link><pubDate>Thu, 29 Jan 2026 19:02:04 -0300</pubDate><guid>https://brdefense.center/news/infraestrutura-de-ia-exposta-representa-risco-cres/</guid><description>&lt;p>Uma investigação conjunta da SentinelOne e Censys revelou que a implementação de inteligência artificial (IA) de código aberto criou uma vasta camada de infraestrutura de computação de IA não gerenciada, com 175.000 hosts únicos do Ollama em 130 países. A maioria das exposições está na China, seguida por países como EUA, Alemanha e Brasil. Esses sistemas operam fora dos controles de segurança padrão, apresentando riscos significativos. Quase 50% dos hosts observados possuem capacidades de chamada de ferramentas, permitindo a execução de código e acesso a APIs, o que altera o modelo de ameaça. A falta de autenticação e a exposição à rede aumentam o risco de LLMjacking, onde recursos de infraestrutura de IA são explorados por agentes maliciosos. A operação chamada &amp;lsquo;Operation Bizarre Bazaar&amp;rsquo; tem como alvo endpoints de serviços LLM expostos, comercializando o acesso a essas infraestruturas. A natureza descentralizada do ecossistema Ollama complica a governança e abre novas avenidas para injeções de prompt e tráfego malicioso. Para os defensores, é crucial tratar os LLMs com os mesmos controles de autenticação e monitoramento aplicados a outras infraestruturas acessíveis externamente.&lt;/p></description></item><item><title>Mais de 1.100 servidores de IA da Ollama expostos online, 20 vulneráveis</title><link>https://brdefense.center/news/mais-de-1100-servidores-de-ia-da-ollama-expostos-o/</link><pubDate>Wed, 03 Sep 2025 18:58:34 -0300</pubDate><guid>https://brdefense.center/news/mais-de-1100-servidores-de-ia-da-ollama-expostos-o/</guid><description>&lt;p>Pesquisadores da Cisco Talos identificaram mais de 1.100 instâncias do framework Ollama, utilizado para hospedar modelos de linguagem, acessíveis publicamente na internet. Aproximadamente 20% desses servidores estavam operando sem qualquer forma de autenticação, tornando-os vulneráveis a ataques severos. Em uma varredura rápida usando o Shodan, foram encontrados 1.139 endpoints expostos, dos quais 214 permitiam consultas de modelos sem credenciais. Essa falta de controle de acesso possibilita ataques de extração de modelo e a injeção de conteúdo malicioso. Mesmo os 80% restantes, que estavam inativos no momento da descoberta, apresentam riscos significativos, como uploads não autorizados de modelos e ataques de exaustão de recursos. A análise geoespacial revelou que a maioria dos servidores expostos está localizada nos Estados Unidos, China e Alemanha, evidenciando falhas na segurança da infraestrutura de IA. Para mitigar essas vulnerabilidades, recomenda-se a implementação de mecanismos de autenticação robustos, isolamento de rede e auditorias regulares de exposição. Essas medidas são essenciais para proteger a integridade dos modelos de IA e evitar abusos.&lt;/p></description></item></channel></rss>