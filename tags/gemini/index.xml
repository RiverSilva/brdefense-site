<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gemini on BR Defense Center</title><link>https://brdefense.center/tags/gemini/</link><description>Recent content in Gemini on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Sun, 18 Jan 2026 18:57:41 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/gemini/index.xml" rel="self" type="application/rss+xml"/><item><title>Google testa Skills para Gemini no Chrome</title><link>https://brdefense.center/news/google-testa-skills-para-gemini-no-chrome/</link><pubDate>Sun, 18 Jan 2026 18:57:41 -0300</pubDate><guid>https://brdefense.center/news/google-testa-skills-para-gemini-no-chrome/</guid><description>&lt;p>O Google está testando uma nova funcionalidade chamada &amp;lsquo;Skills&amp;rsquo; para o Gemini, sua inteligência artificial integrada ao navegador Chrome. Essa funcionalidade permitirá que o Gemini execute tarefas automaticamente, atuando como um assistente dentro do navegador. Atualmente, o Gemini já está disponível para usuários de desktop nos Estados Unidos, onde pode ajudar a explicar partes confusas de páginas, resumir conteúdos e comparar informações entre várias abas. Por exemplo, ao pesquisar por voos, hotéis e atividades, o usuário pode solicitar que o Gemini compile as informações em um único plano claro.&lt;/p></description></item><item><title>Google Gemini Deep Research agora acessa dados do Gmail, Chat e Drive</title><link>https://brdefense.center/news/google-gemini-deep-research-agora-acessa-dados-do/</link><pubDate>Mon, 10 Nov 2025 12:59:09 -0300</pubDate><guid>https://brdefense.center/news/google-gemini-deep-research-agora-acessa-dados-do/</guid><description>&lt;p>O Google expandiu a funcionalidade Deep Research do modelo de IA Gemini, permitindo que ele acesse dados diretamente das contas de Gmail, Google Drive e Google Chat dos usuários. Essa atualização possibilita a integração de e-mails pessoais, documentos, planilhas, apresentações e conversas em relatórios de pesquisa abrangentes, combinando informações internas com dados da web. Essa nova capacidade visa facilitar a colaboração entre profissionais e equipes, permitindo, por exemplo, que análises de mercado sejam iniciadas com documentos compartilhados do Drive e discussões em chats. No entanto, essa integração levanta preocupações significativas de segurança cibernética, uma vez que usuários podem expor dados confidenciais, como estratégias empresariais e comunicações com clientes, ao ecossistema de processamento do Google. Especialistas em segurança alertam para riscos como ataques de injeção de prompt, onde entradas maliciosas podem manipular a IA para vazar informações privadas. A Google recomenda que os usuários habilitem a autenticação de dois fatores e revisem regularmente os logs de acesso. Antes de utilizar a Deep Research com dados sensíveis, as organizações devem realizar avaliações de segurança rigorosas e estabelecer políticas claras sobre quais fontes de dados podem ser compartilhadas com ferramentas de IA.&lt;/p></description></item><item><title>Google não corrigirá falha no Gemini que executa código invisível</title><link>https://brdefense.center/news/google-nao-corrigira-falha-no-gemini-que-executa-c/</link><pubDate>Fri, 10 Oct 2025 13:05:48 -0300</pubDate><guid>https://brdefense.center/news/google-nao-corrigira-falha-no-gemini-que-executa-c/</guid><description>&lt;p>A Google decidiu não corrigir uma vulnerabilidade de segurança em sua ferramenta de inteligência artificial, Gemini, que permite a execução de códigos maliciosos ocultos em textos invisíveis. Essa técnica, conhecida como ASCII smuggling, utiliza caracteres especiais do Unicode para inserir comandos maliciosos na LLM (Large Language Model) sem que o usuário perceba. Embora a falha não seja nova, os riscos aumentaram com a maior autonomia e acesso a dados sensíveis que assistentes como o Gemini possuem. O pesquisador de segurança Viktor Markopoulos, da FireTail, testou várias ferramentas de IA e encontrou vulnerabilidades semelhantes em algumas delas, mas não em outras como Claude, ChatGPT e Microsoft Copilot, que possuem validação de dados de entrada. A Google, ao ser informada sobre a vulnerabilidade, minimizou o problema, alegando que ele só poderia ser explorado por meio de engenharia social. No entanto, a possibilidade de que convites de calendário e e-mails no Google Workspace possam incluir códigos maliciosos representa um risco significativo, pois esses códigos podem instruir as LLMs a acessar dados sensíveis do dispositivo da vítima e enviá-los aos atacantes.&lt;/p></description></item></channel></rss>