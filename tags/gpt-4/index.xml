<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gpt-4 on BR Defense Center</title><link>https://brdefense.center/tags/gpt-4/</link><description>Recent content in Gpt-4 on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Thu, 06 Nov 2025 07:01:34 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/gpt-4/index.xml" rel="self" type="application/rss+xml"/><item><title>HackedGPT Sete novas vulnerabilidades em GPT-4o e GPT-5 permitem ataques sem clique</title><link>https://brdefense.center/news/hackedgpt-sete-novas-vulnerabilidades-em-gpt-4o-e/</link><pubDate>Thu, 06 Nov 2025 07:01:34 -0300</pubDate><guid>https://brdefense.center/news/hackedgpt-sete-novas-vulnerabilidades-em-gpt-4o-e/</guid><description>&lt;p>Pesquisadores de segurança da Tenable descobriram sete vulnerabilidades críticas nos modelos ChatGPT da OpenAI, que expõem milhões de usuários a ataques sofisticados sem necessidade de interação direta. Essas falhas permitem que agentes maliciosos roubem dados sensíveis e comprometam sistemas, levantando sérias questões sobre a segurança dos modelos de linguagem. As vulnerabilidades afetam tanto o GPT-5 quanto o ChatGPT-4, explorando fraquezas na forma como esses modelos processam dados externos e gerenciam informações do usuário. Um dos pontos mais preocupantes é a capacidade de contornar mecanismos de segurança do ChatGPT utilizando links de rastreamento do Bing, permitindo que atacantes exfiltratem dados do usuário de forma discreta. Além disso, a técnica de Injeção de Memória possibilita que instruções maliciosas sejam persistentes em várias conversas, vazando informações privadas sem que o usuário perceba. A pesquisa também identificou uma vulnerabilidade de renderização de markdown, que oculta conteúdos maliciosos, tornando os ataques praticamente invisíveis. Esses vetores de ataque representam uma ameaça significativa, especialmente para organizações que utilizam o ChatGPT em trabalhos sensíveis, exigindo uma resposta rápida da OpenAI para mitigar os riscos.&lt;/p></description></item><item><title>Malware MalTerminal usa tecnologia LLM para gerar código de ransomware</title><link>https://brdefense.center/news/malware-malterminal-usa-tecnologia-llm-para-gerar/</link><pubDate>Fri, 10 Oct 2025 06:59:41 -0300</pubDate><guid>https://brdefense.center/news/malware-malterminal-usa-tecnologia-llm-para-gerar/</guid><description>&lt;p>Pesquisadores de segurança da SentinelLABS revelaram o MalTerminal, um novo malware que utiliza modelos de linguagem de grande escala (LLM) para gerar código de ransomware. Este executável para Windows, identificado após um ano de investigação, incorpora um endpoint da API de chat do OpenAI GPT-4, que foi descontinuado em novembro de 2023, indicando que o malware pode ter surgido entre o final de 2023 e o início de 2024. Os analistas desenvolveram regras YARA para detectar padrões de chaves de API exclusivas de provedores de LLM, encontrando mais de 7.000 amostras com mais de 6.000 chaves únicas. O MalTerminal se destaca como o primeiro exemplo conhecido de malware que gera lógica maliciosa dinamicamente em tempo de execução, emitindo um payload JSON estruturado para o endpoint GPT-4 e definindo seu papel como um especialista em cibersegurança. Embora não haja evidências de que o MalTerminal tenha sido implantado em ambientes reais, sua dependência de serviços comerciais de LLM e chaves de API válidas apresenta uma janela estreita para que os defensores aprimorem suas estratégias de detecção antes que arquiteturas mais resilientes sejam adotadas pelos adversários.&lt;/p></description></item></channel></rss>