<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Copilot on BR Defense Center</title><link>https://brdefense.center/tags/copilot/</link><description>Recent content in Copilot on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Thu, 15 Jan 2026 13:21:14 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/copilot/index.xml" rel="self" type="application/rss+xml"/><item><title>Ataque de IA do Microsoft Copilot compromete usuários com um clique</title><link>https://brdefense.center/news/ataque-de-ia-do-microsoft-copilot-compromete-usuar/</link><pubDate>Thu, 15 Jan 2026 13:21:14 -0300</pubDate><guid>https://brdefense.center/news/ataque-de-ia-do-microsoft-copilot-compromete-usuar/</guid><description>&lt;p>Pesquisadores de segurança da Varonis descobriram um novo método de ataque de injeção de prompt, chamado &amp;lsquo;Reprompt&amp;rsquo;, que compromete usuários do Microsoft Copilot com apenas um clique. Diferente de ataques anteriores que utilizavam e-mails maliciosos, essa nova técnica explora parâmetros de URL para injetar comandos prejudiciais. Quando um usuário clica em um link aparentemente legítimo que contém um parâmetro &amp;lsquo;q&amp;rsquo;, o Copilot interpreta esse conteúdo como um comando a ser executado, permitindo que dados sensíveis sejam vazados. A Microsoft já corrigiu essa vulnerabilidade, bloqueando a possibilidade de injeção de prompt via URLs. Essa descoberta destaca a necessidade de vigilância contínua em ferramentas de IA generativa, que ainda não conseguem distinguir adequadamente entre comandos e dados a serem lidos, tornando-as suscetíveis a ataques. A situação ressalta a importância de medidas de segurança robustas para proteger informações sensíveis em ambientes corporativos.&lt;/p></description></item><item><title>Vulnerabilidade do Microsoft 365 Copilot permite vazamento de e-mails</title><link>https://brdefense.center/news/vulnerabilidade-do-microsoft-365-copilot-permite-v/</link><pubDate>Tue, 21 Oct 2025 13:01:43 -0300</pubDate><guid>https://brdefense.center/news/vulnerabilidade-do-microsoft-365-copilot-permite-v/</guid><description>&lt;p>Uma nova vulnerabilidade no Microsoft 365 Copilot foi descoberta, permitindo que atacantes enganem o assistente de IA para acessar e vazar dados sensíveis de e-mails corporativos. Pesquisadores identificaram que, ao ocultar instruções secretas dentro de um documento do Office, os atacantes podem forçar o Copilot a buscar e codificar e-mails recentes, empacotando-os em um diagrama malicioso gerado pelo Mermaid. Quando um usuário clica no diagrama, os e-mails codificados são enviados para um servidor controlado pelo atacante.&lt;/p></description></item><item><title>Política de Agente do Microsoft Copilot expõe agentes de IA a qualquer usuário</title><link>https://brdefense.center/news/politica-de-agente-do-microsoft-copilot-expoe-agen/</link><pubDate>Mon, 25 Aug 2025 06:58:22 -0300</pubDate><guid>https://brdefense.center/news/politica-de-agente-do-microsoft-copilot-expoe-agen/</guid><description>&lt;p>O ecossistema do Microsoft Copilot enfrenta um grave problema de governança de segurança, onde as políticas de acesso configuradas estão sendo sistematicamente ignoradas. Isso permite a implantação não autorizada de agentes, mesmo diante de restrições administrativas explícitas. Desde maio de 2025, a Microsoft lançou 107 agentes Copilot, mas uma falha crítica foi identificada: a configuração da política de &amp;lsquo;Acesso a Dados&amp;rsquo;, que deveria impedir o acesso de usuários aos agentes, não está sendo aplicada corretamente. Essa vulnerabilidade compromete os controles de segurança das empresas e aumenta os riscos de exposição de dados em ambientes Microsoft 365. A falha se manifesta em múltiplos vetores, incluindo a incapacidade da Microsoft de implementar suas próprias políticas de controle de acesso e deficiências na gestão de inventário de agentes. Para mitigar esses riscos, os administradores devem realizar auditorias abrangentes, implementar bloqueios manuais e estabelecer monitoramento contínuo para detectar novas implantações não autorizadas. A situação exige uma resposta imediata da Microsoft para restaurar a confiança em seu ecossistema de IA.&lt;/p></description></item></channel></rss>