<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Governança on BR Defense Center</title><link>https://brdefense.center/tags/governan%C3%A7a/</link><description>Recent content in Governança on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Tue, 03 Feb 2026 13:38:20 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/governan%C3%A7a/index.xml" rel="self" type="application/rss+xml"/><item><title>Gestão de Identidade para Agentes de IA Um Novo Desafio de Segurança</title><link>https://brdefense.center/news/gestao-de-identidade-para-agentes-de-ia-um-novo-de/</link><pubDate>Tue, 03 Feb 2026 13:38:20 -0300</pubDate><guid>https://brdefense.center/news/gestao-de-identidade-para-agentes-de-ia-um-novo-de/</guid><description>&lt;p>O artigo de Ido Shlomo, CTO e cofundador da Token Security, destaca a crescente presença de agentes de IA autônomos nas empresas e os riscos associados à sua gestão de identidade. Tradicionalmente, as organizações gerenciavam identidades de humanos e máquinas, mas os agentes de IA não se encaixam perfeitamente em nenhuma dessas categorias. Eles são adaptáveis, operam em alta velocidade e podem realizar ações sem supervisão humana, o que cria lacunas significativas na governança de identidade. A falta de visibilidade sobre esses agentes leva a um crescimento descontrolado de identidades, tornando-as alvos fáceis para atacantes. O artigo sugere que a gestão do ciclo de vida das identidades dos agentes de IA deve ser contínua e em tempo real, garantindo visibilidade, responsabilidade e o princípio do menor privilégio. Além disso, enfatiza a importância de descobrir e monitorar esses agentes para evitar riscos de segurança. A gestão eficaz das identidades dos agentes de IA é apresentada como uma solução para mitigar riscos sem comprometer a inovação nas organizações.&lt;/p></description></item><item><title>Governança em escala é essencial para IA nas organizações</title><link>https://brdefense.center/news/governanca-em-escala-e-essencial-para-ia-nas-organ/</link><pubDate>Mon, 19 Jan 2026 07:03:40 -0300</pubDate><guid>https://brdefense.center/news/governanca-em-escala-e-essencial-para-ia-nas-organ/</guid><description>&lt;p>A inteligência artificial (IA) se tornou uma parte integral das operações empresariais, automatizando processos e auxiliando na tomada de decisões. No entanto, à medida que a IA acessa dados sensíveis e executa ações, ela se transforma em um vetor de risco potencial. Pesquisas da Tenable indicam que a IA pode ser manipulada para facilitar ataques internos, utilizando técnicas como injeção indireta de instruções. Isso altera a abordagem tradicional de segurança, que se focava apenas em invasões externas. A popularização de ferramentas no-code, que permitem que mais colaboradores criem agentes de IA, aumenta a exposição a riscos, como vazamentos de dados e fraudes financeiras. Para mitigar esses riscos, é crucial que as lideranças empresariais respondam a três perguntas fundamentais sobre o uso da IA em suas organizações. A governança deve ser proporcional ao impacto, envolvendo práticas como mapeamento de ferramentas, classificação de dados e monitoramento de interações. A maturidade em IA será medida não pela rapidez de adoção, mas pela capacidade de controle e segurança na sua implementação.&lt;/p></description></item><item><title>Acesso não justificado a dados sensíveis cresce em 64 em sites</title><link>https://brdefense.center/news/acesso-nao-justificado-a-dados-sensiveis-cresce-em/</link><pubDate>Wed, 14 Jan 2026 13:01:33 -0300</pubDate><guid>https://brdefense.center/news/acesso-nao-justificado-a-dados-sensiveis-cresce-em/</guid><description>&lt;p>Uma pesquisa recente analisou 4.700 sites líderes e revelou que 64% das aplicações de terceiros acessam dados sensíveis sem justificativa comercial, um aumento significativo em relação aos 51% registrados em 2024. O estudo destaca um aumento alarmante de atividades maliciosas no setor governamental, que saltou de 2% para 12,9%, e revela que 1 em cada 7 sites educacionais apresenta sinais de comprometimento. Ferramentas como Google Tag Manager, Shopify e Facebook Pixel são responsáveis por 8%, 5% e 4% das violações, respectivamente. Apesar de 81% dos líderes de segurança considerarem os ataques na web uma prioridade, apenas 39% implementaram soluções eficazes para mitigar esses riscos. A pesquisa também aponta uma lacuna de governança, onde equipes de marketing e digitais implantam aplicativos sem supervisão de TI, resultando em configurações inadequadas e acesso excessivo a dados sensíveis. O estudo sugere que a falta de ação, impulsionada por restrições orçamentárias e falta de pessoal, está tornando as organizações vulneráveis a ataques, especialmente em setores públicos que enfrentam desafios financeiros. A análise conclui que a gestão de exposição na web é crucial para proteger dados sensíveis e evitar brechas de segurança.&lt;/p></description></item><item><title>Segurança em SaaS Desafios e Soluções com a IA</title><link>https://brdefense.center/news/seguranca-em-saas-desafios-e-solucoes-com-a-ia/</link><pubDate>Thu, 18 Dec 2025 13:00:37 -0300</pubDate><guid>https://brdefense.center/news/seguranca-em-saas-desafios-e-solucoes-com-a-ia/</guid><description>&lt;p>Nos últimos anos, a integração de assistentes de inteligência artificial (IA) em aplicações SaaS, como Zoom, Slack e Microsoft 365, trouxe uma nova dinâmica ao gerenciamento de dados e segurança. Esses assistentes, que operam em alta velocidade e com privilégios elevados, criam caminhos de integração dinâmicos entre diferentes sistemas, o que desafia os modelos tradicionais de segurança que assumem interfaces fixas e papéis de usuário estáveis. A dificuldade em rastrear as ações desses agentes de IA, que muitas vezes se misturam aos logs de usuários normais, expõe vulnerabilidades significativas. Para mitigar esses riscos, as equipes de segurança precisam adotar uma abordagem de segurança dinâmica, que monitore e adapte as políticas em tempo real, garantindo visibilidade e auditabilidade das ações dos assistentes de IA. Essa nova camada de segurança deve ser capaz de detectar desvios de acesso e comportamentos anômalos, permitindo uma resposta proativa a incidentes. À medida que as organizações adotam copilotos de IA, é crucial que os líderes de segurança reavaliem suas estratégias para garantir que a inovação não comprometa a segurança dos dados.&lt;/p></description></item><item><title>Seis perguntas para elaborar um plano de habilitação de IA</title><link>https://brdefense.center/news/seis-perguntas-para-elaborar-um-plano-de-habilitac/</link><pubDate>Sat, 13 Dec 2025 12:57:33 -0300</pubDate><guid>https://brdefense.center/news/seis-perguntas-para-elaborar-um-plano-de-habilitac/</guid><description>&lt;p>À medida que nos aproximamos do final de 2025, dois fatos sobre a inteligência artificial (IA) são cruciais para os diretores de segurança da informação (CISOs). Primeiro, a maioria dos funcionários já utiliza ferramentas de IA generativa em suas atividades, mesmo que a empresa não forneça acesso ou proíba seu uso. Segundo, muitos desses funcionários já compartilharam informações internas e confidenciais com essas ferramentas. Um estudo da Microsoft revela que 75% dos trabalhadores do conhecimento estavam usando IA generativa em 2024, e 78% deles utilizavam ferramentas pessoais. Isso gera um aumento no &amp;lsquo;Access-Trust Gap&amp;rsquo;, que é a diferença entre aplicativos de negócios confiáveis e aqueles não gerenciados que acessam dados corporativos. Para mitigar riscos, as empresas precisam desenvolver um plano de habilitação de IA que inclua governança e controle de acesso. O artigo propõe seis perguntas essenciais para guiar essa elaboração, como quais casos de uso de IA são prioritários e quais ferramentas devem ser adotadas. A falta de governança pode resultar em violações de políticas e consequências legais. Portanto, é fundamental que as empresas adotem uma abordagem proativa e contínua para a governança da IA, garantindo que os funcionários utilizem aplicativos confiáveis e monitorados.&lt;/p></description></item><item><title>A Importância do Fabric de Segurança de Identidade na Cibersegurança</title><link>https://brdefense.center/news/a-importancia-do-fabric-de-seguranca-de-identidade/</link><pubDate>Tue, 18 Nov 2025 12:59:21 -0300</pubDate><guid>https://brdefense.center/news/a-importancia-do-fabric-de-seguranca-de-identidade/</guid><description>&lt;p>O Fabric de Segurança de Identidade (ISF) é uma estrutura arquitetônica unificada que integra diversas capacidades de identidade, como governança, gerenciamento de acesso e detecção de ameaças. Com o aumento da complexidade dos ambientes de TI e a prevalência de ataques cibernéticos, a abordagem tradicional com ferramentas isoladas se torna insuficiente. O ISF se destaca por proteger todos os tipos de identidade, incluindo humanos, máquinas e agentes de IA, em ambientes on-premises, híbridos e multi-nuvem.&lt;/p></description></item><item><title>Inteligência Artificial e sua Transformação no GRC</title><link>https://brdefense.center/news/inteligencia-artificial-e-sua-transformacao-no-grc/</link><pubDate>Wed, 29 Oct 2025 13:02:06 -0300</pubDate><guid>https://brdefense.center/news/inteligencia-artificial-e-sua-transformacao-no-grc/</guid><description>&lt;p>A Inteligência Artificial (IA) está revolucionando a Governança, Risco e Conformidade (GRC), trazendo mudanças significativas na forma como as equipes operam. As capacidades da IA incluem acelerar auditorias, identificar riscos críticos rapidamente e reduzir o trabalho manual, resultando em maior eficiência e precisão. No entanto, essa transformação também apresenta novos desafios, como viés potencial, lacunas regulatórias e pontos cegos perigosos, que ainda estão sendo abordados por órgãos reguladores. Para ajudar as organizações a se adaptarem a esse novo cenário, será realizado um webinar gratuito intitulado &amp;lsquo;O Futuro da IA no GRC: Oportunidades, Riscos e Insights Práticos&amp;rsquo;. O evento abordará exemplos reais de como a IA melhora fluxos de trabalho de conformidade, lições aprendidas e melhores práticas, além de estratégias para identificar e mitigar riscos comuns. A velocidade da inovação em IA é impressionante, e a lacuna entre a capacidade tecnológica e o arcabouço legal representa uma exposição imediata ao risco. O webinar reunirá especialistas e exemplos práticos, permitindo que as organizações se preparem proativamente para os desafios que a IA traz ao GRC.&lt;/p></description></item><item><title>Inteligência Artificial e Segurança Cibernética Desafios e Oportunidades</title><link>https://brdefense.center/news/inteligencia-artificial-e-seguranca-cibernetica-de/</link><pubDate>Tue, 21 Oct 2025 12:59:48 -0300</pubDate><guid>https://brdefense.center/news/inteligencia-artificial-e-seguranca-cibernetica-de/</guid><description>&lt;p>A inteligência artificial (IA) tem um grande potencial para aprimorar a defesa cibernética, facilitando o trabalho dos profissionais de segurança. Ela pode ajudar a reduzir a fadiga de alertas, identificar padrões rapidamente e escalar operações de segurança de forma que os analistas humanos não conseguem. No entanto, a adoção de IA também amplia a superfície de ataque das organizações, exigindo governança clara, controles de identidade robustos e visibilidade nas decisões tomadas pela IA. Para garantir a segurança, é fundamental estabelecer confiança nos dados que a IA utiliza, responsabilidade pelas ações que executa e supervisão dos resultados que produz. O artigo destaca a importância de tratar sistemas de IA como identidades críticas dentro do gerenciamento de identidade e acesso (IAM), aplicando controles rigorosos como credenciais limitadas, autenticação forte e monitoramento contínuo. Além disso, sugere práticas recomendadas para proteger modelos de IA, incluindo controles de acesso, validação de dados e segurança na inferência. A integração responsável da IA nas operações de segurança pode permitir que as equipes trabalhem de maneira mais inteligente e eficaz, mas é essencial encontrar um equilíbrio entre automação e supervisão humana.&lt;/p></description></item><item><title>A Inteligência Artificial e o Risco de Vazamento de Dados Corporativos</title><link>https://brdefense.center/news/a-inteligencia-artificial-e-o-risco-de-vazamento-d/</link><pubDate>Tue, 07 Oct 2025 12:59:10 -0300</pubDate><guid>https://brdefense.center/news/a-inteligencia-artificial-e-o-risco-de-vazamento-d/</guid><description>&lt;p>Um novo relatório da LayerX revela que a inteligência artificial (IA) se tornou o maior canal não controlado para a exfiltração de dados corporativos, superando ferramentas de SaaS não gerenciadas e compartilhamento de arquivos. Com 45% dos funcionários de empresas utilizando ferramentas de IA generativa, como ChatGPT, a falta de governança é alarmante, pois 67% do uso ocorre em contas pessoais não gerenciadas. O estudo aponta que 40% dos arquivos enviados para ferramentas de IA contêm dados sensíveis, e 77% dos funcionários colam informações nessas plataformas, com 82% dessas ações originando de contas não gerenciadas. A segurança tradicional, focada em uploads de arquivos, ignora esses vetores de vazamento. Além disso, 87% do uso de mensagens instantâneas ocorre em contas não gerenciadas, criando um cenário de risco elevado. O relatório recomenda que a segurança da IA seja tratada como uma categoria essencial, com estratégias de governança que incluam monitoramento de uploads e restrições a contas pessoais. Para os líderes de segurança, a urgência em adaptar as políticas de segurança é clara, pois a IA já está integrada aos fluxos de trabalho e representa um vetor principal para a perda de dados corporativos.&lt;/p></description></item><item><title>A Dura Realidade da Adoção de IA nas Empresas</title><link>https://brdefense.center/news/a-dura-realidade-da-adocao-de-ia-nas-empresas/</link><pubDate>Tue, 02 Sep 2025 12:57:21 -0300</pubDate><guid>https://brdefense.center/news/a-dura-realidade-da-adocao-de-ia-nas-empresas/</guid><description>&lt;p>Um relatório do MIT revelou que 40% das organizações adquiriram assinaturas de LLMs empresariais, mas mais de 90% dos funcionários utilizam ferramentas de IA no dia a dia. A pesquisa da Harmonic Security indica que 45,4% das interações sensíveis com IA ocorrem em contas de e-mail pessoais, o que levanta preocupações sobre a chamada &amp;lsquo;Economia de IA Sombra&amp;rsquo;. Essa situação ocorre porque a adoção de IA é impulsionada pelos funcionários, e não por diretrizes corporativas. Muitas empresas tentam bloquear o acesso a plataformas de IA, mas essa estratégia falha, pois a IA está integrada em quase todos os aplicativos SaaS. Para mitigar riscos, as equipes de segurança precisam entender e governar o uso de IA, tanto em contas autorizadas quanto não autorizadas. A descoberta da IA Sombra é essencial para manter a conformidade regulatória e proteger dados sensíveis. A Harmonic Security oferece soluções para monitorar o uso de IA e aplicar políticas de governança adequadas, permitindo que as empresas se beneficiem da produtividade da IA, enquanto protegem suas informações.&lt;/p></description></item><item><title>A Nova Era da Privacidade Confiança em um Mundo de IA Agente</title><link>https://brdefense.center/news/a-nova-era-da-privacidade-confianca-em-um-mundo-de/</link><pubDate>Fri, 15 Aug 2025 09:26:12 -0300</pubDate><guid>https://brdefense.center/news/a-nova-era-da-privacidade-confianca-em-um-mundo-de/</guid><description>&lt;p>O conceito de privacidade está evoluindo em um mundo onde a inteligência artificial (IA) agente se torna cada vez mais autônoma. Em vez de ser apenas uma questão de controle, a privacidade agora se baseia na confiança, especialmente quando essas IAs interagem com dados sensíveis e tomam decisões em nome dos usuários. A IA agente não apenas processa informações, mas também as interpreta, o que levanta preocupações sobre o que é inferido e compartilhado sem supervisão constante. Um exemplo prático é um assistente de saúde que, ao longo do tempo, pode começar a priorizar consultas e analisar o estado emocional do usuário, o que pode levar à perda de controle sobre a narrativa pessoal. Além disso, a privacidade não se resume mais ao triângulo clássico da CIA (Confidencialidade, Integridade e Disponibilidade), mas deve incluir autenticidade e veracidade. A falta de um conceito claro de privilégio entre IA e cliente pode resultar em consequências legais, onde informações pessoais podem ser acessadas por terceiros. Portanto, é essencial que as organizações desenvolvam sistemas de IA que respeitem a intenção por trás da privacidade e que sejam capazes de explicar suas ações. A necessidade de um novo contrato social que considere a agência da IA como uma categoria moral e legal é urgente, pois a privacidade se torna uma questão de reciprocidade e governança em um mundo onde humanos e máquinas interagem cada vez mais.&lt;/p></description></item></channel></rss>