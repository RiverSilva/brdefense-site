<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deepseek on BR Defense Center</title><link>https://brdefense.center/tags/deepseek/</link><description>Recent content in Deepseek on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Mon, 24 Nov 2025 12:58:45 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/deepseek/index.xml" rel="self" type="application/rss+xml"/><item><title>Modelo de IA DeepSeek-R1 gera vulnerabilidades em temas sensíveis</title><link>https://brdefense.center/news/modelo-de-ia-deepseek-r1-gera-vulnerabilidades-em/</link><pubDate>Mon, 24 Nov 2025 12:58:45 -0300</pubDate><guid>https://brdefense.center/news/modelo-de-ia-deepseek-r1-gera-vulnerabilidades-em/</guid><description>&lt;p>Uma pesquisa da CrowdStrike revelou que o modelo de inteligência artificial (IA) DeepSeek-R1, desenvolvido pela empresa chinesa DeepSeek, produz um número significativamente maior de vulnerabilidades de segurança quando recebe prompts relacionados a temas considerados politicamente sensíveis pela China. A análise indicou que a probabilidade de gerar código com vulnerabilidades graves aumenta em até 50% ao incluir tais tópicos. O modelo, que já enfrentou preocupações de segurança nacional e foi banido em vários países, também censura questões sensíveis, como a Grande Muralha da China e o status político de Taiwan. O Bureau de Segurança Nacional de Taiwan alertou os cidadãos sobre o uso de modelos de IA generativa chineses, que podem distorcer narrativas históricas e amplificar desinformação. A pesquisa da CrowdStrike destacou que, ao solicitar a criação de código para sistemas de controle industrial em regiões sensíveis, a qualidade do código gerado se deteriora, apresentando falhas de segurança significativas. Além disso, o modelo possui um &amp;lsquo;kill switch&amp;rsquo; intrínseco, recusando-se a gerar código para temas como o Falun Gong em 45% das tentativas. As descobertas ressaltam a necessidade de cautela ao utilizar ferramentas de IA que podem ser influenciadas por diretrizes políticas.&lt;/p></description></item><item><title>Vazamento de dados da DeepSeek expõe mais de 1 milhão de registros</title><link>https://brdefense.center/news/vazamento-de-dados-da-deepseek-expoe-mais-de-1-mil/</link><pubDate>Wed, 03 Sep 2025 12:57:36 -0300</pubDate><guid>https://brdefense.center/news/vazamento-de-dados-da-deepseek-expoe-mais-de-1-mil/</guid><description>&lt;p>Em janeiro de 2025, a empresa chinesa de inteligência artificial DeepSeek sofreu um vazamento de dados que comprometeu mais de 1 milhão de registros sensíveis. A Wiz Research identificou um banco de dados ClickHouse acessível publicamente, permitindo controle total sobre as operações do banco, incluindo acesso a dados internos como histórico de chats e chaves secretas. Embora a DeepSeek tenha rapidamente corrigido a exposição, o incidente destaca os riscos associados ao vazamento de dados, que podem ser intencionais, como ataques de phishing, ou não intencionais, como erros humanos. Os vetores comuns de vazamento incluem configurações inadequadas de armazenamento em nuvem, vulnerabilidades em dispositivos finais e falhas na comunicação por e-mail. As consequências de tais vazamentos podem ser devastadoras, incluindo multas severas por não conformidade com regulamentos como o GDPR e o CCPA, perda de propriedade intelectual e danos à reputação da empresa. Para mitigar esses riscos, as organizações devem implementar práticas como acesso de menor privilégio, prevenção de perda de dados (DLP), classificação de dados sensíveis, auditorias e treinamento adequado para funcionários.&lt;/p></description></item></channel></rss>