<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ia Generativa on BR Defense Center</title><link>https://brdefense.center/tags/ia-generativa/</link><description>Recent content in Ia Generativa on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Wed, 08 Oct 2025 13:00:24 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/ia-generativa/index.xml" rel="self" type="application/rss+xml"/><item><title>77 dos Funcionários Compartilham Segredos da Empresa no ChatGPT</title><link>https://brdefense.center/news/77-dos-funcionarios-compartilham-segredos-da-empre/</link><pubDate>Wed, 08 Oct 2025 13:00:24 -0300</pubDate><guid>https://brdefense.center/news/77-dos-funcionarios-compartilham-segredos-da-empre/</guid><description>&lt;p>Um novo relatório revela que 77% dos funcionários compartilham informações confidenciais da empresa em plataformas de inteligência artificial generativa, como o ChatGPT, resultando em violações de políticas de segurança. O estudo mostra que quase metade dos colaboradores interage regularmente com essas ferramentas, e 40% dos arquivos enviados contêm dados regulados, como informações pessoais identificáveis (PII) e dados de cartões de pagamento (PCI). Apesar das políticas de segurança que enfatizam o controle de arquivos, muitos funcionários estão copiando e colando informações sensíveis diretamente em campos de entrada de IA, o que dificulta a detecção por sistemas de auditoria de segurança. Além disso, 87% das atividades de chat observadas ocorrem em contas não gerenciadas, aumentando o risco de vazamentos de dados. O relatório sugere que as empresas precisam repensar suas estratégias de segurança, mudando o foco de controles tradicionais de prevenção de perda de dados (DLP) para monitoramento dinâmico de fluxos de dados baseados em navegador e atividades em sessões de SaaS não gerenciadas. Medidas como políticas de acesso adaptativas e análise comportamental em tempo real são essenciais para mitigar esses riscos emergentes.&lt;/p></description></item><item><title>Evolução da Prevenção de Vazamento de Dados para IA Generativa</title><link>https://brdefense.center/news/evolucao-da-prevencao-de-vazamento-de-dados-para-i/</link><pubDate>Fri, 29 Aug 2025 12:58:02 -0300</pubDate><guid>https://brdefense.center/news/evolucao-da-prevencao-de-vazamento-de-dados-para-i/</guid><description>&lt;p>As plataformas de IA generativa, como ChatGPT e Copilot, estão se tornando comuns nas organizações, trazendo eficiência, mas também novos desafios na prevenção de vazamentos de dados. Informações sensíveis podem ser expostas através de prompts de chat, arquivos enviados para resumo ou plugins de navegador que contornam controles de segurança. As soluções tradicionais de DLP (Data Loss Prevention) frequentemente não conseguem detectar esses eventos. Tecnologias como o Fidelis Network Detection and Response (NDR) oferecem uma abordagem baseada em rede para controlar a atividade de IA, permitindo que as equipes monitorem, apliquem políticas e auditem o uso de IA generativa.&lt;/p></description></item></channel></rss>