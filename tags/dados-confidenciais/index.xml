<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dados Confidenciais on BR Defense Center</title><link>https://brdefense.center/tags/dados-confidenciais/</link><description>Recent content in Dados Confidenciais on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Sat, 13 Dec 2025 12:57:33 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/dados-confidenciais/index.xml" rel="self" type="application/rss+xml"/><item><title>Seis perguntas para elaborar um plano de habilitação de IA</title><link>https://brdefense.center/news/seis-perguntas-para-elaborar-um-plano-de-habilitac/</link><pubDate>Sat, 13 Dec 2025 12:57:33 -0300</pubDate><guid>https://brdefense.center/news/seis-perguntas-para-elaborar-um-plano-de-habilitac/</guid><description>&lt;p>À medida que nos aproximamos do final de 2025, dois fatos sobre a inteligência artificial (IA) são cruciais para os diretores de segurança da informação (CISOs). Primeiro, a maioria dos funcionários já utiliza ferramentas de IA generativa em suas atividades, mesmo que a empresa não forneça acesso ou proíba seu uso. Segundo, muitos desses funcionários já compartilharam informações internas e confidenciais com essas ferramentas. Um estudo da Microsoft revela que 75% dos trabalhadores do conhecimento estavam usando IA generativa em 2024, e 78% deles utilizavam ferramentas pessoais. Isso gera um aumento no &amp;lsquo;Access-Trust Gap&amp;rsquo;, que é a diferença entre aplicativos de negócios confiáveis e aqueles não gerenciados que acessam dados corporativos. Para mitigar riscos, as empresas precisam desenvolver um plano de habilitação de IA que inclua governança e controle de acesso. O artigo propõe seis perguntas essenciais para guiar essa elaboração, como quais casos de uso de IA são prioritários e quais ferramentas devem ser adotadas. A falta de governança pode resultar em violações de políticas e consequências legais. Portanto, é fundamental que as empresas adotem uma abordagem proativa e contínua para a governança da IA, garantindo que os funcionários utilizem aplicativos confiáveis e monitorados.&lt;/p></description></item><item><title>Sites da Intel explorados em ataque a dados confidenciais de funcionários</title><link>https://brdefense.center/news/sites-da-intel-explorados-em-ataque-a-dados-confid/</link><pubDate>Tue, 19 Aug 2025 06:59:55 -0300</pubDate><guid>https://brdefense.center/news/sites-da-intel-explorados-em-ataque-a-dados-confid/</guid><description>&lt;p>Uma investigação de segurança revelou vulnerabilidades críticas em quatro sites internos da Intel, permitindo acesso não autorizado a informações detalhadas de mais de 270 mil funcionários globalmente. O pesquisador de segurança Eaton identificou técnicas de bypass de autenticação e credenciais hardcoded que possibilitaram acesso extensivo aos sistemas internos da Intel entre outubro de 2024 e fevereiro de 2025. As falhas de autenticação afetaram sistemas como o de pedidos de cartões de visita e o de gerenciamento de fornecedores, permitindo que atacantes manipulassem funções JavaScript para contornar proteções do Microsoft Azure Active Directory. O ataque mais significativo ocorreu no site de pedidos de cartões de visita da Intel na Índia, onde um endpoint de API não autenticado forneceu tokens de acesso sem verificação adequada, resultando na extração de um arquivo JSON de quase 1 GB com dados de funcionários, incluindo nomes, cargos e contatos. A resposta da Intel às divulgações de vulnerabilidades revelou desafios significativos em seu processo de segurança, com a empresa apenas reconhecendo automaticamente os relatórios enviados. Embora a Intel tenha expandido seu programa de recompensas por bugs, as questões de segurança em sites ainda não estão totalmente cobertas. Este incidente destaca a necessidade de revisões abrangentes de segurança em aplicações web internas, especialmente em grandes corporações de tecnologia.&lt;/p></description></item></channel></rss>