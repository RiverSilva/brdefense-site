<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Llms on BR Defense Center</title><link>https://brdefense.center/tags/llms/</link><description>Recent content in Llms on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Mon, 26 Jan 2026 13:05:07 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/llms/index.xml" rel="self" type="application/rss+xml"/><item><title>Hackers usam LLMs para criar novos ataques de phishing</title><link>https://brdefense.center/news/hackers-usam-llms-para-criar-novos-ataques-de-phis/</link><pubDate>Mon, 26 Jan 2026 13:05:07 -0300</pubDate><guid>https://brdefense.center/news/hackers-usam-llms-para-criar-novos-ataques-de-phis/</guid><description>&lt;p>Pesquisadores da Palo Alto Networks, através da unidade Unit 42, alertam que hackers estão utilizando Inteligência Artificial Generativa (GenAI) para desenvolver ataques de phishing mais sofisticados e personalizados. A técnica envolve a criação de páginas de phishing dinâmicas que se adaptam ao usuário, utilizando APIs de Modelos de Linguagem de Grande Escala (LLMs) para gerar códigos JavaScript únicos em tempo real. Isso dificulta a detecção por métodos tradicionais, pois o código malicioso não é entregue de forma estática, mas sim gerado na hora, tornando a análise prévia quase impossível. Embora ainda seja uma prova de conceito, a pesquisa indica que os fundamentos para esses ataques já estão sendo explorados, com um aumento no uso de malware e ransomware assistidos por LLMs. Os especialistas recomendam que as empresas restrinjam o uso de serviços LLM não autorizados e implementem medidas de segurança mais robustas para prevenir esses novos tipos de ataques.&lt;/p></description></item></channel></rss>