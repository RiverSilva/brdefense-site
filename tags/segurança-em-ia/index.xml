<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Segurança Em Ia on BR Defense Center</title><link>https://brdefense.center/tags/seguran%C3%A7a-em-ia/</link><description>Recent content in Segurança Em Ia on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Mon, 10 Nov 2025 13:00:04 -0300</lastBuildDate><atom:link href="https://brdefense.center/tags/seguran%C3%A7a-em-ia/index.xml" rel="self" type="application/rss+xml"/><item><title>Falha crítica de RCE em biblioteca npm ameaça aplicações de IA e NLP</title><link>https://brdefense.center/news/falha-critica-de-rce-em-biblioteca-npm-ameaca-apli/</link><pubDate>Mon, 10 Nov 2025 13:00:04 -0300</pubDate><guid>https://brdefense.center/news/falha-critica-de-rce-em-biblioteca-npm-ameaca-apli/</guid><description>&lt;p>Uma vulnerabilidade crítica de execução remota de código (RCE) foi identificada na biblioteca expr-eval, amplamente utilizada para avaliação de expressões matemáticas e processamento de linguagem natural (NLP). A falha, registrada como CVE-2025-12735, permite que atacantes executem comandos de sistema no ambiente do servidor, comprometendo a segurança de aplicações que processam entradas de usuários. Essa vulnerabilidade é especialmente preocupante para organizações que utilizam essa biblioteca em ambientes de produção, pois pode resultar em acesso não autorizado a recursos sensíveis e exfiltração de dados. A falha decorre de um erro de design no método evaluate() da classe Parser, permitindo que funções arbitrárias sejam definidas no contexto do parser. Para mitigar os riscos, as organizações devem auditar suas dependências e aplicar patches imediatamente. As opções incluem a aplicação de um patch específico ou a atualização para versões corrigidas da biblioteca. A rápida implementação dessas correções é crucial para evitar a exploração generalizada da vulnerabilidade. O pesquisador de segurança Jangwoo Choe divulgou a questão de forma responsável, colaborando com GitHub e npm para garantir um relato adequado e tempo suficiente para as correções.&lt;/p></description></item><item><title>Google Lança Ferramentas Avançadas para Proteger a Segurança em IA</title><link>https://brdefense.center/news/google-lanca-ferramentas-avancadas-para-proteger-a/</link><pubDate>Wed, 20 Aug 2025 12:59:10 -0300</pubDate><guid>https://brdefense.center/news/google-lanca-ferramentas-avancadas-para-proteger-a/</guid><description>&lt;p>No Google Cloud Security Summit 2025, a Google apresentou uma nova suíte de ferramentas de segurança impulsionadas por inteligência artificial, com o objetivo de proteger ecossistemas de IA e fortalecer as defesas organizacionais. As inovações abrangem três áreas principais: proteção de implementações de IA autônomas, suporte a centros de operações de segurança com agentes autônomos e ampliação dos controles de segurança em nuvem.&lt;/p>
&lt;p>Entre as novidades, destaca-se o Centro de Comando de Segurança, que agora possui capacidades expandidas para identificação de riscos e inventário de agentes de IA, permitindo a descoberta automatizada de vulnerabilidades. A proteção em tempo real contra ameaças, como injeção de comandos e vazamento de dados sensíveis, foi aprimorada com a extensão do Model Armor. Além disso, um novo agente de investigação de alertas foi introduzido, que realiza investigações dinâmicas para acelerar os tempos de resposta.&lt;/p></description></item></channel></rss>