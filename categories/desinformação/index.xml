<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Desinformação on BR Defense Center</title><link>https://brdefense.center/categories/desinforma%C3%A7%C3%A3o/</link><description>Recent content in Desinformação on BR Defense Center</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Mon, 03 Nov 2025 18:58:22 -0300</lastBuildDate><atom:link href="https://brdefense.center/categories/desinforma%C3%A7%C3%A3o/index.xml" rel="self" type="application/rss+xml"/><item><title>Campanhas de desinformação médica utilizam deepfakes de profissionais de saúde</title><link>https://brdefense.center/news/campanhas-de-desinformacao-medica-utilizam-deepfak/</link><pubDate>Mon, 03 Nov 2025 18:58:22 -0300</pubDate><guid>https://brdefense.center/news/campanhas-de-desinformacao-medica-utilizam-deepfak/</guid><description>&lt;p>No Fórum Latinoamericano de Cibersegurança da ESET, a pesquisadora Martina López destacou o uso crescente de deepfakes em campanhas de desinformação médica. A tecnologia, que simula rostos e vozes de forma convincente, tem sido utilizada para criar perfis falsos de médicos, alterando suas credenciais e especializações. Essas campanhas se espalham principalmente em redes sociais menos moderadas, como TikTok e Facebook, e em grupos de aplicativos de mensagens como Telegram e Discord, visando manipular principalmente leigos e pessoas com menor nível educacional. Para combater essa desinformação, iniciativas como o Ato de Inteligência Artificial da União Europeia buscam implementar marca d&amp;rsquo;água em conteúdos gerados por IA. A especialista recomenda que os usuários verifiquem a fonte das informações e utilizem ferramentas de busca reversa para identificar conteúdos falsos. A crescente sofisticação dos deepfakes exige uma vigilância redobrada, pois a tecnologia pode impactar a percepção pública e a saúde coletiva.&lt;/p></description></item></channel></rss>